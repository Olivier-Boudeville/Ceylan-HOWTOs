<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.21.2: https://docutils.sourceforge.io/" />
<title>Ceylan-HOWTOs: About 3D</title>
<script type="text/javascript" src="mathjax/tex-mml-chtml.js?config=TeX-AMS_CHTML"></script>
<link rel="stylesheet" href="pygments-default.css" type="text/css" />
<link rel="stylesheet" href="howtos.css" type="text/css" />
<link href="howtos-icon.png" rel="icon">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<div class="document" id="about-3d">
<span id="top"></span>
<h1 class="title">About 3D</h1>

<p><span class="raw-html"><a name="howtos_top"></a></span></p>
<p><span class="raw-html"><div class="banner"><p><em>Ceylan HOWTOs</em> <a href="http://howtos.esperide.org">browse latest</a> <a href="Ceylan-HOWTOs-english.pdf">get PDF</a> <a href="#howtos_top">go to top</a> <a href="#howtos_toc">go to toc</a> <a href="#howtos_bottom">go to bottom</a> <a href="Ceylan-HOWTOs-overview-english.html">go to HOWTOs</a> <a href="mailto:about(dash)ceylan-howtos(at)esperide(dot)com?subject=[Ceylan-HOWTOs]%20Remark%20about%203D">email us</a></p></div></span></p>
<p><span class="raw-html"><center><img src="howtos-title.png" id="responsive-image-ultrasmall"></img></span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Organisation:</th><td class="field-body">Copyright (C) 2021-2024 Olivier Boudeville</td>
</tr>
<tr class="field"><th class="field-name">Contact:</th><td class="field-body">about (dash) howtos (at) esperide (dot) com</td>
</tr>
<tr class="field"><th class="field-name">Creation date:</th><td class="field-body">Saturday, November 20, 2021</td>
</tr>
<tr class="field"><th class="field-name">Lastly updated:</th><td class="field-body">Monday, May 20, 2024</td>
</tr>
</tbody>
</table>
<p><span class="raw-html"><a name="howtos_toc"></a></span></p>
<div class="contents local topic" id="topic-1">
<span id="table-of-contents"></span><p class="topic-title"><a class="reference internal" href="#top"><strong>Table of Contents</strong></a></p>
<ul class="simple">
<li><a class="reference internal" href="#cross-platform-game-engines" id="toc-entry-1">Cross-Platform Game Engines</a><ul>
<li><a class="reference internal" href="#godot" id="toc-entry-2">Godot</a><ul>
<li><a class="reference internal" href="#installation" id="toc-entry-3">Installation</a></li>
<li><a class="reference internal" href="#use" id="toc-entry-4">Use</a></li>
<li><a class="reference internal" href="#assets" id="toc-entry-5">Assets</a></li>
<li><a class="reference internal" href="#sources-of-godot-related-information" id="toc-entry-6">Sources of Godot-related Information</a></li>
</ul>
</li>
<li><a class="reference internal" href="#unreal-engine" id="toc-entry-7">Unreal Engine</a><ul>
<li><a class="reference internal" href="#unreal-assets" id="toc-entry-8">Unreal Assets</a></li>
</ul>
</li>
<li><a class="reference internal" href="#unity3d" id="toc-entry-9">Unity3D</a><ul>
<li><a class="reference internal" href="#installation-1" id="toc-entry-10">Installation</a></li>
<li><a class="reference internal" href="#configuration" id="toc-entry-11">Configuration</a></li>
<li><a class="reference internal" href="#running-unity" id="toc-entry-12">Running Unity</a></li>
<li><a class="reference internal" href="#troubleshooting" id="toc-entry-13">Troubleshooting</a></li>
<li><a class="reference internal" href="#unity-assets-1" id="toc-entry-14">Unity Assets</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#d-data" id="toc-entry-15">3D Data</a><ul>
<li><a class="reference internal" href="#file-formats" id="toc-entry-16">File Formats</a><ul>
<li><a class="reference internal" href="#gltf" id="toc-entry-17">glTF</a></li>
<li><a class="reference internal" href="#collada" id="toc-entry-18">Collada</a></li>
<li><a class="reference internal" href="#fbx-obj-etc" id="toc-entry-19">FBX, OBJ, etc.</a></li>
<li><a class="reference internal" href="#in-general" id="toc-entry-20">In General</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conversions" id="toc-entry-21">Conversions</a><ul>
<li><a class="reference internal" href="#recommended-option-relying-on-blender" id="toc-entry-22">Recommended Option: Relying on Blender</a></li>
<li><a class="reference internal" href="#workaround-1-using-autodesk-fbx-converter" id="toc-entry-23">Workaround #1: Using Autodesk FBX Converter</a></li>
<li><a class="reference internal" href="#workaround-2-relying-on-unity" id="toc-entry-24">Workaround #2: Relying on Unity</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-of-3d-content" id="toc-entry-25">Examples of 3D Content</a></li>
<li><a class="reference internal" href="#engine-related-assets" id="toc-entry-26">Engine-related Assets</a></li>
<li><a class="reference internal" href="#asset-providers" id="toc-entry-27">Asset Providers</a></li>
</ul>
</li>
<li><a class="reference internal" href="#modelling-software" id="toc-entry-28">Modelling Software</a><ul>
<li><a class="reference internal" href="#blender" id="toc-entry-29">Blender</a></li>
<li><a class="reference internal" href="#wings3d" id="toc-entry-30">Wings3D</a></li>
</ul>
</li>
<li><a class="reference internal" href="#other-tools" id="toc-entry-31">Other Tools</a><ul>
<li><a class="reference internal" href="#draco" id="toc-entry-32">Draco</a></li>
<li><a class="reference internal" href="#the-compressonator" id="toc-entry-33">The Compressonator</a></li>
<li><a class="reference internal" href="#f3d" id="toc-entry-34">F3D</a></li>
<li><a class="reference internal" href="#mikktspace" id="toc-entry-35">Mikktspace</a></li>
<li><a class="reference internal" href="#mixamo" id="toc-entry-36">Mixamo</a></li>
</ul>
</li>
<li><a class="reference internal" href="#opengl-corner" id="toc-entry-37">OpenGL Corner</a><ul>
<li><a class="reference internal" href="#conventions" id="toc-entry-38">Conventions</a><ul>
<li><a class="reference internal" href="#basics" id="toc-entry-39">Basics</a></li>
<li><a class="reference internal" href="#steps-for-opengl-rendering" id="toc-entry-40">Steps for OpenGL Rendering</a></li>
<li><a class="reference internal" href="#transformations" id="toc-entry-41">Transformations</a></li>
<li><a class="reference internal" href="#camera" id="toc-entry-42">Camera</a></li>
<li><a class="reference internal" href="#opengl-hints" id="toc-entry-43">OpenGL Hints</a></li>
<li><a class="reference internal" href="#mini-opengl-glossary" id="toc-entry-44">Mini OpenGL Glossary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#coordinate-systems" id="toc-entry-45">Coordinate Systems</a><ul>
<li><a class="reference internal" href="#coordinate-systems-in-2d" id="toc-entry-46">Coordinate Systems In 2D</a></li>
<li><a class="reference internal" href="#coordinate-systems-in-3d" id="toc-entry-47">Coordinate Systems In 3D</a></li>
<li><a class="reference internal" href="#computing-transition-matrices" id="toc-entry-48">Computing Transition Matrices</a></li>
</ul>
</li>
<li><a class="reference internal" href="#main-matrices" id="toc-entry-49">Main Matrices</a></li>
<li><a class="reference internal" href="#shaders" id="toc-entry-50">Shaders</a><ul>
<li><a class="reference internal" href="#a-programmable-pipeline" id="toc-entry-51">A Programmable Pipeline</a></li>
<li><a class="reference internal" href="#parallelism-in-the-pipeline" id="toc-entry-52">Parallelism in the Pipeline</a></li>
<li><a class="reference internal" href="#six-types-of-glsl-shaders" id="toc-entry-53">Six Types of GLSL Shaders</a></li>
<li><a class="reference internal" href="#runtime-build" id="toc-entry-54">Runtime Build</a></li>
<li><a class="reference internal" href="#implementing-a-shader" id="toc-entry-55">Implementing a Shader</a></li>
<li><a class="reference internal" href="#communicating-with-shaders" id="toc-entry-56">Communicating with Shaders</a></li>
<li><a class="reference internal" href="#using-multiple-shaders-of-the-same-type" id="toc-entry-57">Using Multiple Shaders of the Same Type</a></li>
<li><a class="reference internal" href="#troubleshooting-shaders" id="toc-entry-58">Troubleshooting Shaders</a></li>
<li><a class="reference internal" href="#examples-of-shaders" id="toc-entry-59">Examples of Shaders</a></li>
<li><a class="reference internal" href="#managing-spatial-transformations" id="toc-entry-60">Managing Spatial Transformations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#more-advanced-topics" id="toc-entry-61">More Advanced Topics</a><ul>
<li><a class="reference internal" href="#shadows" id="toc-entry-62">Shadows</a></li>
<li><a class="reference internal" href="#reference-glsl-compiler" id="toc-entry-63">Reference GLSL Compiler</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sources-of-information" id="toc-entry-64">Sources of Information</a></li>
</ul>
</li>
<li><a class="reference internal" href="#operating-system-support-for-3d" id="toc-entry-65">Operating System Support for 3D</a><ul>
<li><a class="reference internal" href="#testing" id="toc-entry-66">Testing</a></li>
<li><a class="reference internal" href="#troubleshooting-1" id="toc-entry-67">Troubleshooting</a></li>
</ul>
</li>
<li><a class="reference internal" href="#minor-topics" id="toc-entry-68">Minor Topics</a><ul>
<li><a class="reference internal" href="#camera-navigation-conventions" id="toc-entry-69">Camera Navigation Conventions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#d-related-mini-glossary" id="toc-entry-70">3D-Related Mini-Glossary</a></li>
</ul>
</div>
<p><span class="raw-html"></center></span></p>
<p>As usual, these information pertain to a GNU/Linux perspective.</p>
<div class="section" id="cross-platform-game-engines">
<h1><a class="toc-backref" href="#toc-entry-1">Cross-Platform Game Engines</a></h1>
<p>The big three are <a class="reference external" href="https://en.wikipedia.org/wiki/Godot_(game_engine)">Godot</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Unreal_Engine">Unreal Engine</a> and <a class="reference internal" href="#unity3d">Unity3D</a> <a class="footnote-reference" href="#footnote-1" id="footnote-reference-1">[1]</a>.</p>
<table class="docutils footnote" frame="void" id="footnote-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-1">[1]</a></td><td>Others could be considered, like <a class="reference external" href="https://www.cocos.com/en/creator">Cocos Creator</a>, an open-source engine using TypeScript and WebGL.</td></tr>
</tbody>
</table>
<div class="section" id="godot">
<h2><a class="toc-backref" href="#toc-entry-2">Godot</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Godot_(game_engine)">Godot</a> is our personal favorite engine, notably because it is free software (<a class="reference external" href="https://godotengine.org/license">released under the very permissive MIT license</a>).</p>
<p>See its <a class="reference external" href="https://godotengine.org/">official website</a> and its <a class="reference external" href="https://godotengine.org/asset-library/asset">asset library</a>.</p>
<p>Godot (version 3.4.1) will not be able to load FBX files that reference formats like PSD or TIF and/or of older versions (e.g. FBX 6.1). See for that our section regarding <a class="reference internal" href="#format-conversions">format conversions</a>.</p>
<div class="section" id="installation">
<h3><a class="toc-backref" href="#toc-entry-3">Installation</a></h3>
<p>On Arch Linux, one may simply use <tt class="docutils literal">pacman <span class="pre">-Sy</span> godot</tt>.</p>
<p>Or just, for maximum control, one may instead directly download the GNU/Linux version <a class="reference external" href="https://godotengine.org/download/linux/">from the Godot official website</a>.</p>
<p>If planning to be able to develop in C# in addition to GDScript (refer to our <a class="reference internal" href="#scripting-language">Scripting Language</a> section), prefer the .NET version (as opposed to the Standard one), i.e. the &quot;<tt class="docutils literal">.NET (x86_64)</tt>&quot; version - provided that the support for .NET is already secured, either based on the <a class="reference external" href="https://dotnet.microsoft.com/download">Microsoft .NET SDK</a> or, possibly better, on the <a class="reference external" href="https://www.mono-project.com/download/stable/">Mono SDK</a>.</p>
<p>The installation procedure that we prefer can be done automatically thanks to our <a class="reference external" href="https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/install-godot.sh">install-godot.sh</a> script.</p>
</div>
<div class="section" id="use">
<h3><a class="toc-backref" href="#toc-entry-4">Use</a></h3>
<div class="section" id="scripting-language">
<h4>Scripting Language</h4>
<p>Users of the Godot API may develop notably in GDScript (extension: <tt class="docutils literal">*.gd</tt>) and/or in C# (extension: <tt class="docutils literal">*.cs</tt>) and/or in C++.</p>
<p>See <a class="reference external" href="https://docs.godotengine.org/en/stable/tutorials/scripting/c_sharp/c_sharp_differences.html">this comparison</a> - knowing that <a class="reference external" href="https://docs.godotengine.org/en/stable/tutorials/scripting/cross_language_scripting.html#doc-cross-language-scripting">languages can be mixed and matched</a>.</p>
<p>We prefer using C# to GDScript or C++, as:</p>
<ul class="simple">
<li>C# is statically typed (GDScript is dynamically typed, with implicit casts)</li>
<li>C# is widely-used / general-purpose (and Unity supports it as well), as opposed to GDScript</li>
<li>C# is C++-inspired (yet offers a safer model, notably in terms of life-cycle management), whereas GDScript is Python-inspired <a class="footnote-reference" href="#footnote-2" id="footnote-reference-2">[2]</a>; so for example C# does not rely on indentation to define clauses</li>
</ul>
<table class="docutils footnote" frame="void" id="footnote-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-2">[2]</a></td><td>With additionally quite many differences. For example, with GDScript, variables are typed, like in <tt class="docutils literal">var my_msg : String = 'Hello!'</tt>. So <tt class="docutils literal">my_msg = 7</tt> is to result in a (<em>runtime</em>) error. Python lists are Godot arrays. <tt class="docutils literal">None</tt> is <tt class="docutils literal">null</tt>. A switch-like operator (<tt class="docutils literal">match</tt>) exists, etc.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="development-hints">
<h4>Development Hints</h4>
<ul class="simple">
<li>all scripts are classes, which are by default anonymous</li>
</ul>
</div>
<div class="section" id="important-paths">
<h4>Important Paths</h4>
<p>A configuration tree lies in <tt class="docutils literal">.config/godot</tt>, a cache tree in <tt class="docutils literal"><span class="pre">~/.cache/godot</span></tt>.</p>
</div>
<div class="section" id="logs">
<h4>Logs</h4>
<p>Godot logs are stored per-project; e.g. <tt class="docutils literal"><span class="pre">~/.local/share/godot/app_userdata/my-test-project/logs/godot.log</span></tt>; past log files are kept once timestamped. They tend not to have interesting content.</p>
</div>
</div>
<div class="section" id="assets">
<h3><a class="toc-backref" href="#toc-entry-5">Assets</a></h3>
<p>The official <a class="reference external" href="https://godotengine.org/asset-library/asset">Godot Asset Library</a>, whose assets are at least mostly available through the rather permissive MIT licence, coexists with (probably too many) unofficial ones, like <a class="reference external" href="https://godotassetlibrary.com/">Godot A.L.</a> (AGPLv3 license), <a class="reference external" href="https://godotassetstore.org/">Godot Asset Store</a>, <a class="reference external" href="https://godotassets.io/">GodotAssets</a>, etc.</p>
<p>For obvious reasons, many of the current open source assets are of a significantly lower quality than their non-Godot commercial counterparts. We believe than, until Godot-related assets progress (either as open-source or commercial ones), as soon as a game is a bit ambitious, relying on the asset stores of the other engines (see <a class="reference internal" href="#engine-related-assets">Engine-related Assets</a>) and/or on <a class="reference internal" href="#asset-providers">asset providers</a> is a better option.</p>
</div>
<div class="section" id="sources-of-godot-related-information">
<h3><a class="toc-backref" href="#toc-entry-6">Sources of Godot-related Information</a></h3>
<ul class="simple">
<li>the official <a class="reference external" href="https://www.youtube.com/&#64;GodotEngineOfficial">Godot Engine</a> video channel</li>
<li>the <a class="reference external" href="https://www.youtube.com/&#64;Gdquest/">GDQuest channel</a>, offering a large number of Godot tutorials covering many topics</li>
</ul>
</div>
</div>
<div class="section" id="unreal-engine">
<h2><a class="toc-backref" href="#toc-entry-7">Unreal Engine</a></h2>
<p>Another contender is the <a class="reference external" href="https://en.wikipedia.org/wiki/Unreal_Engine">Unreal Engine</a>, a C++ game engine developed by Epic Games; we have not used it yet.</p>
<p>The Unreal Engine 5 brings new features that may be of interest, including a <a class="reference external" href="https://docs.unrealengine.com/5.0/en-US/lumen-global-illumination-and-reflections-in-unreal-engine/">fully dynamic global illumination and reflection system</a> (Lumen, not requiring baked lightmaps anymore), a <a class="reference external" href="https://docs.unrealengine.com/5.0/en-US/nanite-virtualized-geometry-in-unreal-engine/">virtualized geometry system</a> (Nanite, simplifying detailed geometries on the fly) and a <a class="reference external" href="https://www.unrealengine.com/en-US/features/quixel-megascans">quality 2D/3D asset library</a> (the Quixel Megascans library, obtained from real-world scans).</p>
<p>Unreal does not offer a scripting language anymore, user developments have to be done <a class="reference external" href="https://docs.unrealengine.com/5.0/en-US/unreal-engine-programming-and-scripting/">in C++</a> (beyond <em>Blueprints Visual Scripting</em>).</p>
<p>Its <a class="reference external" href="https://www.unrealengine.com/en-US/faq">licence</a> is meant to induce costs only when making large-enough profits; more precisely, a <em>5% royalty is due only if you are distributing an off-the-shelf product that incorporates Unreal Engine code (such as a game) and the lifetime gross revenue from that product exceeds $1 million USD</em> (the first $1 million remaining royalty-exempt); in case of large success, it may be a costlier licence than Unity.</p>
<p>With an Unreal user account, the sources of the engine (in its latest stable version, 5) <a class="reference external" href="https://www.unrealengine.com/en-US/ue-on-github">can be examined on Github</a> (so it is open source - yet not free software).</p>
<p>See its <a class="reference external" href="https://www.unrealengine.com">official website</a>.</p>
<div class="section" id="unreal-assets">
<h3><a class="toc-backref" href="#toc-entry-8">Unreal Assets</a></h3>
<p>Purchased assets from the <a class="reference external" href="https://www.unrealengine.com/marketplace/en-US/store">Unreal marketplace</a> may be used in one's own shipped products (<a class="reference external" href="https://marketplacehelp.epicgames.com/s/article/How-can-I-use-the-products-I-ve-purchased-from-the-Marketplace-or-Learn-Tab?language=en_US">source</a>) and apparently at least usually no restrictive terms apply.</p>
<p>Assets not created by Epic Games can be used in other engines unless otherwise specified (<a class="reference external" href="https://marketplacehelp.epicgames.com/s/article/Can-I-use-these-products-in-other-gaming-engines-like-Source-or-Unity?language=en_US">source</a>; see also <a class="reference external" href="https://www.reddit.com/r/godot/comments/bjsfoz/can_i_use_unreal_engine_assets_in_godot/">this thread</a>).</p>
<p>Note that parts of the content of assets will be Unreal-specific (<tt class="docutils literal">*.uasset</tt>, <tt class="docutils literal">*.umap</tt>, etc.), like scripts. Yet technically many can be adapted to other engines (see for example <a class="reference external" href="https://www.youtube.com/watch?v=fhv_cpYQIqc">Exporting from Unreal Engine to Godot</a>).</p>
</div>
</div>
<div class="section" id="unity3d">
<h2><a class="toc-backref" href="#toc-entry-9">Unity3D</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a> is most probably still the most popular cross-platform game engine, despite recent controversies.</p>
<p>Regarding the licensing of the engine, <a class="reference external" href="https://store.unity.com/#plans-individual">various plans</a> apply (warning: they may have changed since this writing), depending notably on whether one subscribes as an individual or a team, and on one's profile, revenue and funding; the general idea is not taking royalties, but <strong>flat</strong>, per seat yearly fees increasing with the organisation &quot;size&quot; (typically in the $400-$1800 range, per seat).</p>
<p>See its <a class="reference external" href="https://unity.com/">official website</a> and its <a class="reference external" href="https://assetstore.unity.com/">asset store</a>.</p>
<p id="unity-assets">Unity may be installed at least in order to access its asset store, knowing that apparently an asset purchased in this store may be used with any game engine of choice. Indeed, for the standard licence, it is stipulated in the <a class="reference external" href="https://unity3d.com/legal/as_terms">EULA legal terms</a> that:</p>
<p><em>Licensor grants to the END-USER a non-exclusive, worldwide, and perpetual license to the Asset to integrate Assets only as incorporated and embedded components of electronic games and interactive media and distribute such electronic game and interactive media.</em></p>
<p>So, in legal terms, an asset could be bought in the Unity Asset Store and used in Godot, for example - provided that its content can be used there technically without too much effort/constraints (this may happen due to prefabs, specific animations, materials or shaders, conventions in use, etc.).</p>
<div class="section" id="installation-1">
<h3><a class="toc-backref" href="#toc-entry-10">Installation</a></h3>
<p>Unity shall now be obtained thanks to the Unity Hub.</p>
<p>On Arch Linux it is <a class="reference external" href="https://aur.archlinux.org/packages/unityhub/">available through the AUR</a>, as an <a class="reference external" href="https://en.wikipedia.org/wiki/AppImage">AppImage</a>; one may thus use: <tt class="docutils literal">yay <span class="pre">-Sy</span> unityhub</tt>.</p>
<p>Then, when running (as a non-privileged user) <tt class="docutils literal">unityhub</tt>, a Unity account will be needed, then a licence, then a Unity release will have to be added in order to have it downloaded and installed for good, covering the selected target platforms (e.g. GNU/Linux and Windows &quot;Build Supports&quot;).</p>
<p>We rely here on the Unity version 2021.2.7f1.</p>
<p>Additional information: <a class="reference external" href="https://wiki.archlinux.org/title/Unity3D">Unity3D on Arch</a>.</p>
</div>
<div class="section" id="configuration">
<h3><a class="toc-backref" href="#toc-entry-11">Configuration</a></h3>
<p>Configuring Unity so that its interface (mouse, keyboard bindings) behave like, for example, the one of Blender, is not natively supported.</p>
</div>
<div class="section" id="running-unity">
<h3><a class="toc-backref" href="#toc-entry-12">Running Unity</a></h3>
<p>Just execute <tt class="docutils literal">unityhub</tt>, which requires signing up and activating a licence.</p>
</div>
<div class="section" id="troubleshooting">
<h3><a class="toc-backref" href="#toc-entry-13">Troubleshooting</a></h3>
<p>The log files are stored in <tt class="docutils literal"><span class="pre">~/.config/unity3d</span></tt>:</p>
<ul class="simple">
<li>Unity Editor: <tt class="docutils literal">Editor.log</tt> (the most interesting one)</li>
<li>Unity Package Manager: <tt class="docutils literal">upm.log</tt></li>
<li>Unity Licensing client: <tt class="docutils literal">Unity.Licensing.Client.log</tt></li>
</ul>
<p>If the editor is stuck (e.g. when importing an asset), one may use as a last resort <a class="reference external" href="https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/kill-unity3d.sh">kill-unity3d.sh</a>.</p>
<p>In term of persistent state, beyond the project trees themselves, there are:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">~/.config/UnityHub/</span></tt> and <tt class="docutils literal"><span class="pre">~/.local/share/UnityHub/</span></tt></li>
<li><tt class="docutils literal"><span class="pre">~/.config/unity3d/</span></tt> and <tt class="docutils literal"><span class="pre">~/.local/share/unity3d/</span></tt></li>
</ul>
<p>(nothing in <tt class="docutils literal"><span class="pre">~/.cache</span></tt> apparently)</p>
</div>
<div class="section" id="unity-assets-1">
<h3><a class="toc-backref" href="#toc-entry-14">Unity Assets</a></h3>
<p>Once ordered through the Unity Asset Store, assets can be downloaded through the <tt class="docutils literal">Window <span class="pre">-&gt;</span> Package Manager</tt> menu, by replacing, in the top <tt class="docutils literal">Packages</tt> drop-down, the <tt class="docutils literal">In Project</tt> entry by the <tt class="docutils literal">My Assets</tt> one. After having selected an asset, use the <tt class="docutils literal">Download</tt> button at the bottom-right of the screen.</p>
<p>Then, to gain access to such downloaded assets, of course the simplest approach is to use the Unity editor; this is done by creating a project (e.g. <tt class="docutils literal">MyProject</tt>), selecting the aforementioned menu option (just above), then clicking on <tt class="docutils literal">Import</tt> and selecting the relevant content that will end up in clear form in your project, i.e. in the filesystem of the operating system with their actual name and content, for example in <tt class="docutils literal">MyProject/Assets/CorrespondingAssetProvider/AssetName</tt>. Unfortunately we experienced reproducible freezes when importing some resources.</p>
<p>Yet such Unity packages, once downloaded (whether or not they have been imported in projects afterwards) are just files that are stored typically in the <tt class="docutils literal"><span class="pre">~/.local/share/unity3d/Asset</span> <span class="pre">Store-5.x</span></tt> directory and whose extension is <tt class="docutils literal">.unitypackage</tt>.</p>
<p>Such files are actually <tt class="docutils literal">.tar.gz</tt> archives, and thus their content can be listed thanks to:</p>
<pre class="code bash literal-block">
$<span class="w"> </span>tar<span class="w"> </span>tvzf<span class="w"> </span>Foobar.unitypackage
</pre>
<p>Inside such archives, each individual package resource is located in a directory whose name is probably akin to the checksum of this resource (e.g. <tt class="docutils literal">167e85f3d750117459ff6199b79166fd</tt>) <a class="footnote-reference" href="#footnote-3" id="footnote-reference-3">[3]</a>; such directory generally contains at least 3 files:</p>
<ul class="simple">
<li><tt class="docutils literal">asset</tt>: the resource itself, renamed to that unique checksum name, yet containing its exact original content (e.g. the one of a Targa image)</li>
<li><tt class="docutils literal">asset.meta</tt>: the metadata about that asset (file format, identifier, timestamp, type-specific settings, etc.), as an ASCII, YAML-like, text</li>
<li><tt class="docutils literal">pathname</tt>: the path of that asset in the package &quot;virtual&quot; tree (e.g. <tt class="docutils literal">Assets/Foo/Textures/baz.tga</tt>)</li>
</ul>
<p>When applicable, a <tt class="docutils literal">preview.png</tt> file may also exist.</p>
<table class="docutils footnote" frame="void" id="footnote-3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-3">[3]</a></td><td>Yet no checksum tool among <tt class="docutils literal">md5sum</tt>, <tt class="docutils literal">sha1sum</tt>, <tt class="docutils literal">sha256sum</tt>, <tt class="docutils literal">sha512sum</tt>, <tt class="docutils literal">shasum</tt>, <tt class="docutils literal">sha224sum</tt>, <tt class="docutils literal">sha384sum</tt> seems to correspond; it must a be a different, possibly custom, checksum.</td></tr>
</tbody>
</table>
<p>Some types of content are Unity-specific and thus may not transpose (at least directly) to another game engine. This is the case for example for materials or prefabs (whose file format is relatively simple, based on <a class="reference external" href="https://en.wikipedia.org/wiki/YAML">YAML</a> 1.1).</p>
<p>Tools like <a class="reference external" href="https://github.com/Perfare/AssetStudio">AssetStudio</a> (probably Windows-only) strive to automate most of the process of exploring, extracting and exporting Unity assets.</p>
<p>Meshes are typically in the <a class="reference external" href="https://en.wikipedia.org/wiki/FBX">FBX</a> (proprietary) file format, that can nevertheless be imported in <a class="reference internal" href="#blender">Blender</a> and converted to other file formats (e.g. glTF 2.0); see <a class="reference internal" href="#blender-import">blender import</a> and <a class="reference internal" href="#blender-convert">blender convert</a> for that.</p>
</div>
</div>
</div>
<div class="section" id="d-data">
<h1><a class="toc-backref" href="#toc-entry-15">3D Data</a></h1>
<div class="section" id="file-formats">
<h2><a class="toc-backref" href="#toc-entry-16">File Formats</a></h2>
<p>They are designed to store 3D content (scenes, nodes, vertices, normals, meshes, textures, materials, animations, skins, cameras, lights, etc.).</p>
<div class="section" id="gltf">
<h3><a class="toc-backref" href="#toc-entry-17">glTF</a></h3>
<p>We prefer relying on the open, well-specified, modern <a class="reference external" href="https://en.wikipedia.org/wiki/GlTF">glTF 2.0 format</a> in order to perform import/export operations.</p>
<p>It comes in two forms:</p>
<ul class="simple">
<li>either as <tt class="docutils literal">*.gltf</tt> when JSON-based, possibly embedding the actual data (vertices, normals, textures, etc.) as ASCII <a class="reference external" href="https://en.wikipedia.org/wiki/Base64">base64-encoded</a> content, or referencing external files</li>
<li>or as <tt class="docutils literal">*.glb</tt> when binary; this is the most compact form, and the one that we recommend for actual releases</li>
</ul>
<p>See also the <a class="reference external" href="https://www.khronos.org/files/gltf20-reference-guide.pdf">glTF 2.0 quick reference guide</a>, the <a class="reference external" href="https://docs.godotengine.org/en/stable/getting_started/workflow/assets/importing_scenes.html">related section of Godot</a> and <a class="reference external" href="https://github.khronos.org/glTF-Sample-Viewer-Release/">this standard viewer of predefined glTF samples</a>.</p>
<p>This (generic) <a class="reference external" href="https://gltf-viewer.donmccurdy.com/">online glTF viewer</a> proved lightweight and convenient, notably because it displays errors, warnings and information regarding the glTF data that it decodes.</p>
</div>
<div class="section" id="collada">
<h3><a class="toc-backref" href="#toc-entry-18">Collada</a></h3>
<p>The second best choice that we see is <a class="reference external" href="https://en.wikipedia.org/wiki/COLLADA">Collada</a> (<tt class="docutils literal">*.dae</tt> files), an XML-based counterpart (open as well, yet older and with less validating facilities) to glTF.</p>
</div>
<div class="section" id="fbx-obj-etc">
<h3><a class="toc-backref" href="#toc-entry-19">FBX, OBJ, etc.</a></h3>
<p>Often, assets can be found as <a class="reference external" href="https://en.wikipedia.org/wiki/FBX">FBX</a> of <a class="reference external" href="https://en.wikipedia.org/wiki/Wavefront_.obj_file">OBJ</a> files and thus may have to be converted (typically to glTF), which is never a riskless task. FBX comes in two flavours: text-based (ASCII) or binary; see <a class="reference external" href="https://code.blender.org/2013/08/fbx-binary-file-format-specification/">this retro-specification</a> for more information.</p>
</div>
<div class="section" id="in-general">
<h3><a class="toc-backref" href="#toc-entry-20">In General</a></h3>
<p>Refer to <a class="reference internal" href="#blender-import">blender import</a> in order to handle the most common 3D file formats, and the next section about conversions.</p>
<p>The <tt class="docutils literal">file</tt> command is able to report the version of at least some formats; for example:</p>
<pre class="code bash literal-block">
<span class="c1"># Means FBX 7.3:
</span>$<span class="w"> </span>file<span class="w"> </span>foobar.fbx<span class="w">
</span>foobar.fbx:<span class="w"> </span>Kaydara<span class="w"> </span>FBX<span class="w"> </span>model,<span class="w"> </span>version<span class="w"> </span><span class="m">7300</span>
</pre>
<p>Too often, some tool will not be able to load a file and will fail to properly report why. When suspecting that a binary file (e.g. a FBX one) references external content either missing or in an unsupported format (e.g. PSD or TIFF?), one may peek at their content without any dedicated tool, directly from a terminal, like in:</p>
<pre class="code bash literal-block">
$<span class="w"> </span>strings<span class="w"> </span>my_asset.fbx<span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span><span class="p">|</span><span class="w"> </span>uniq<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span><span class="s1">'\.'</span>
</pre>
<p>This should list, among other elements, the paths that such a binary file is embedding.</p>
</div>
</div>
<div class="section" id="conversions">
<span id="format-conversions"></span><h2><a class="toc-backref" href="#toc-entry-21">Conversions</a></h2>
<p>Due to the larger number of 3D file formats and the role of commercial software, interoperability regarding 3D content is poor and depends on many versions (of tools and formats).</p>
<div class="section" id="recommended-option-relying-on-blender">
<h3><a class="toc-backref" href="#toc-entry-22">Recommended Option: Relying on Blender</a></h3>
<p>Using <a class="reference internal" href="#blender-import">blender import</a> is the primary solution that we see: a content, once imported in Blender, can be exported in any of the supported formats.</p>
<p>Yet this operation may fail, for example on &quot;older&quot; FBX files, whose FBX version (e.g. 6.1) is not supported by Blender (&quot;<em>Version 6100 unsupported, must be 7100 or later</em>&quot;) or by other tools such as Godot. See also the <a class="reference external" href="https://docs.blender.org/manual/en/latest/files/media/index.html">Media Formats</a> supported by Blender.</p>
<p>Another option of interest is to use Godot's <a class="reference external" href="https://github.com/godotengine/FBX2glTF">FBX2glTF</a> command-line tool.</p>
</div>
<div class="section" id="workaround-1-using-autodesk-fbx-converter">
<span id="autodesk-converter"></span><h3><a class="toc-backref" href="#toc-entry-23">Workaround #1: Using Autodesk FBX Converter</a></h3>
<p>The simpler approach seems to download the (free) <a class="reference external" href="https://images.autodesk.com/adsk/files/fbx20133_converter_win_x64.exe">Autodesk FBX Converter</a> and to use <a class="reference external" href="GNULinux.html#wine">wine</a> to run it on GNU/Linux. Just install then this converter with: <tt class="docutils literal">wine fbx20133_converter_win_x64.exe</tt>.</p>
<p>A convenient alias (based on default settings, typically to be put in one's <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt>) can then be defined to run it:</p>
<pre class="code bash literal-block">
$<span class="w"> </span><span class="nb">alias</span><span class="w"> </span>fbx-converter-ui<span class="o">=</span><span class="s2">&quot;</span><span class="nv">$HOME</span><span class="s2">/.wine/drive_c/Program\ Files/Autodesk/FBX/FBX\ Converter/2013.3/FBXConverterUI.exe 2&gt;/dev/null &amp;&quot;</span>
</pre>
<p>Conversions may take place from, for example, FBX 6.1 (also: 3DS, DAE, DXF, OBJ) to a FBX version in: 2006, 2009, 2010, 2011, 2013 (i.e. 7.3 - of course the most interesting one here), but also DXF, OBJ and Collada, with various settings (embedded media, binary/ASCII mode, etc.).</p>
<p>An even better option is to use directly the command-line tool <tt class="docutils literal">bin/FbxConverter.exe</tt>, which the previous user interface actually executes. Use its <tt class="docutils literal">/?</tt> option to get help, with interesting information.</p>
<p>For example, to update a file in a presumably older FBX into a 7.3 one (that Blender can import):</p>
<pre class="code bash literal-block">
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>~/.wine/drive_c/Program<span class="se">\ </span>Files/Autodesk/FBX/FBX<span class="se">\ </span>Converter/2013.3/bin<span class="w">
</span>$<span class="w"> </span>FbxConverter.exe<span class="w"> </span>My-legacy.FBX<span class="w"> </span>newer.fbx<span class="w"> </span>/v<span class="w"> </span>/sffFBX<span class="w"> </span>/dffFBX<span class="w"> </span>/e<span class="w"> </span>/f201300
</pre>
<p>We devised the <a class="reference external" href="https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/update-fbx.sh">update-fbx.sh</a> script to automate such an in-place FBX update.</p>
<p>Unfortunately, at least on one FBX sample taken from a Unity package, if the mesh could be imported in Blender, textures and materials were not (having checked <tt class="docutils literal">Embed media</tt> in the converter or not).</p>
</div>
<div class="section" id="workaround-2-relying-on-unity">
<h3><a class="toc-backref" href="#toc-entry-24">Workaround #2: Relying on Unity</a></h3>
<p>Here the principle is to import a content in Unity (the same could probably be done with Godot), and to export it from there.</p>
<p>Unity does not allow to export for example FBX natively, however a package for that is provided. It shall be installed first, once per project.</p>
<p>One shall select in the menu <tt class="docutils literal">Window <span class="pre">-&gt;</span> Package Manager</tt>, ensure that the entry <tt class="docutils literal">Packages:</tt> points to <tt class="docutils literal">Unity Registry</tt>, and search for <tt class="docutils literal">FBX Exporter</tt>, then install it (bottom right button).</p>
<p>Afterwards, in the <tt class="docutils literal">GameObject</tt> menu, an <tt class="docutils literal">Export to FBX</tt> option will be available. Select the <tt class="docutils literal">Binary</tt> export format (not <tt class="docutils literal">ASCII</tt>) if wanting to be compliant with Blender.</p>
</div>
</div>
<div class="section" id="examples-of-3d-content">
<h2><a class="toc-backref" href="#toc-entry-25">Examples of 3D Content</a></h2>
<p>Here are a few samples of 3D content (useful for testing):</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/KhronosGroup/glTF-Sample-Models">glTF</a>, notably <a class="reference external" href="https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0">glTF 2.0</a>; direct: <a class="reference external" href="https://github.com/KhronosGroup/glTF-Sample-Models/raw/master/2.0/Buggy/glTF-Embedded/Buggy.gltf">.gltf Buggy example</a>, <a class="reference external" href="https://github.com/KhronosGroup/glTF-Sample-Models/raw/master/2.0/BarramundiFish/glTF-Binary/BarramundiFish.glb">.glb Fish example</a> (also: a <a class="reference external" href="http://paulbourke.net/dataformats/glTF/cube.txt">simple cube</a>)</li>
<li><a class="reference external" href="https://github.com/assimp/assimp/tree/master/test/models/Collada">DAE</a>; direct: <a class="reference external" href="https://github.com/assimp/assimp/raw/master/test/models/Collada/duck.dae">Duck example</a> (also: a <a class="reference external" href="https://gist.github.com/wtsnz/bfa11c40e04594b260255b5dc7956f26">simple cube</a>)</li>
<li><a class="reference external" href="https://free3d.com/dl-files.php?p=5671208f26be8b5e7b8b4567&amp;f=4">FBX</a>; direct: <a class="reference external" href="https://github.com/armory3d/armorpaint_samples/raw/master/sample.fbx">Stylized character</a></li>
<li><a class="reference external" href="https://free3d.com/dl-files.php?p=51a50c9b46e0daad6a99bb49&amp;f=0">OBJ</a></li>
<li><a class="reference external" href="https://github.com/andrewisen/bim-whale-ifc-samples">IFC</a>; direct: <a class="reference external" href="https://github.com/andrewisen/bim-whale-ifc-samples/raw/main/BasicHouse/IFC/BasicHouse.ifc">Basic house</a> (requires the <a class="reference external" href="https://blenderbim.org/download.html">BlenderBIM</a> add-on for BIM support in Blender)</li>
</ul>
</div>
<div class="section" id="engine-related-assets">
<h2><a class="toc-backref" href="#toc-entry-26">Engine-related Assets</a></h2>
<p>Technically, and also legally, assets obtained in the context of any of these engines can be at least partially exported and adapted for re-use in other engines.</p>
<p>Textures may be exported as PNG, animations in the <a class="reference external" href="https://en.wikipedia.org/wiki/FBX">FBX</a> (proprietary) file format, that can nevertheless be imported in <a class="reference internal" href="#blender">Blender</a> and converted to other file formats (e.g. glTF 2.0); see <a class="reference internal" href="#blender-import">blender import</a> and <a class="reference internal" href="#blender-convert">blender convert</a> for that.</p>
<p>Scripts and alike (Nodes, Prefabs, Blueprints) are engine-specific, yet may be recreated or at least translated to some extent.</p>
</div>
<div class="section" id="asset-providers">
<h2><a class="toc-backref" href="#toc-entry-27">Asset Providers</a></h2>
<p>Usually, for one's creation, much multimedia artwork has to be secured: typically graphical assets (e.g. 2D/3D geometries, animations, textures) and/or audio ones (e.g. music, sounds, speech syntheses, special effects).</p>
<p>Instead of creating such content by oneself (not enough time/interest/skill?), it may be more relevant to rely on specialised third-parties.</p>
<p><strong>Hiring a professional or a freelance</strong> is then an option. This is of course relatively expensive, involves more efforts (to define requirements and review the results), longer, but it is supposed to provide exactly the artwork that one would like.</p>
<p>Another option is to rely on specialised third-party providers who <strong>sell non-exclusive licences for the content that they offer</strong>.</p>
<p>These providers can be either direct <strong>content producers</strong> (companies with staffs of modellers), or <strong>asset aggregators</strong> (marketplaces that federate the offers of many producers of any size) that are often created in link to a given multimedia engine. An interesting point is that assets purchased in these stores generally can be used in any technical context, hence are not meant to be bound to the corresponding engine.</p>
<p>Nowadays, much content is available, in terms of theme/setting (e.g. Medieval, Science-Fiction), of nature (e.g. characters, environments, vehicles), etc. and the overall quality/price ratio seems rather good.</p>
<p>The main advantages of these marketplaces is that:</p>
<ul class="simple">
<li>they favor the competition between content providers: the clients can easily compare assets and share their opinion about them</li>
<li>they generalised simple, standard, unobtrusive licensing terms; e.g. royalty free, allowing content to be used as they are or in a modified form, not limited by types of usage, number of distributed copies, duration of use, number of countries addressed, etc.; the general rule is that much freedom is left to the asset purchasers provided that they use such assets for their own projects (rather than for example selling the artwork as they are)</li>
</ul>
<p>The main content aggregators that we spotted are (roughly by decreasing order of interest, based on our limited experience):</p>
<ul class="simple">
<li>the <a class="reference external" href="https://assetstore.unity.com/">Unity Asset Store</a>, already discussed in the <a class="reference internal" href="#unity-assets">Unity Assets</a> section; websites like <a class="reference external" href="https://www.gameassetdeals.com/">this one</a> allow to track the significant discounts that are regularly made on assets</li>
<li>the <a class="reference external" href="https://www.unrealengine.com/marketplace/en-US/store">UE Marketplace</a>, i.e. the store associated to the Unreal Engine; in terms of licensing and uses (see also <a class="reference external" href="#unreal-assets">this section</a>):<ul>
<li><a class="reference external" href="https://marketplacehelp.epicgames.com/s/article/What-is-the-customer-getting-when-they-purchase-my-product?language=en_US">this article</a> states that <em>When customers purchase Marketplace products, they get a non-exclusive, worldwide, perpetual license to download, use, copy, post, modify, promote, license, sell, publicly perform, publicly display, digitally perform, distribute, or transmit your product’s content for personal, promotional, and/or commercial purposes. Distribution of products via the Marketplace is not a sale of the content but the granting of digital rights to the customer.</em></li>
<li><a class="reference external" href="https://marketplacehelp.epicgames.com/s/article/Can-I-use-these-products-in-other-gaming-engines-like-Source-or-Unity?language=en_US">this one</a> states that <em>Any Marketplace products that have not been created by Epic Games can be used in other engines unless otherwise specified.</em></li>
<li><a class="reference external" href="https://marketplacehelp.epicgames.com/s/article/What-can-a-customer-do-with-my-product?language=en_US">this one</a> states that <em>All products sold on the Marketplace are licensed to the customer (who may be either an individual or company) for the lifetime right to use the content in developing an unlimited number of products and in shipping those products. The customer is also licensed to make the content available to employees and contractors for the sole purpose of contributing to products controlled by the customer.</em></li>
</ul>
</li>
<li><a class="reference external" href="https://itch.io/game-assets">itch.io</a></li>
<li><a class="reference external" href="https://www.turbosquid.com/Search/3D-Models">Turbosquid</a></li>
<li><a class="reference external" href="https://free3d.com/3d-models/">Free3D</a></li>
<li><a class="reference external" href="https://www.cgtrader.com/">CGtrader</a></li>
<li><a class="reference external" href="https://www.artstation.com/marketplace/game-dev/assets">ArtStation</a></li>
<li><a class="reference external" href="https://sketchfab.com/tags/asset-store">Sketchfab</a></li>
<li><a class="reference external" href="https://3drt.com/store/">3DRT</a></li>
<li><a class="reference external" href="https://marketplace.reallusion.com/">Reallusion</a></li>
<li><a class="reference external" href="https://arteria3d.myshopify.com/">Arteria3D</a></li>
<li>the <a class="reference external" href="https://www.gamedevmarket.net/">GameDev Market</a> (GDM)</li>
<li>the <a class="reference external" href="https://tgcstore.net/">Game Creator Store</a></li>
</ul>
<p>Many asset providers organise interesting discount offers (at least -50% on a selection of assets, sometimes even more for limited quantities) for the Black Friday (hence end of November) or for Christmas (hence mid-December till the first days of January).</p>
</div>
</div>
<div class="section" id="modelling-software">
<h1><a class="toc-backref" href="#toc-entry-28">Modelling Software</a></h1>
<div class="section" id="blender">
<h2><a class="toc-backref" href="#toc-entry-29">Blender</a></h2>
<p>Blender is a very powerful <a class="reference external" href="https://en.wikipedia.org/wiki/Blender_(software)">free software 3D toolset</a>.</p>
<p>Blender (version 3.0.0) can import FBX files of version at least 7.1 (&quot;7100&quot;). See for that our section regarding <a class="reference internal" href="#format-conversions">format conversions</a>.</p>
<p id="blender-convert"><span id="blender-import"></span>We recommend the use of our <a class="reference external" href="http://hull.esperide.org#blender">Blender shell scripts</a> in order to:</p>
<ul class="simple">
<li>import conveniently various file formats in Blender, with <tt class="docutils literal"><span class="pre">blender-import.sh</span></tt></li>
<li>convert directly on the command-line various file formats (still thanks to a non-interactive Blender), with <tt class="docutils literal"><span class="pre">blender-convert.sh</span></tt></li>
</ul>
</div>
<div class="section" id="wings3d">
<h2><a class="toc-backref" href="#toc-entry-30">Wings3D</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Wings_3D">Wings3D</a> is a nice, Erlang-based, free software, advanced subdivision <em>modeler</em> <a class="footnote-reference" href="#footnote-4" id="footnote-reference-4">[4]</a>, available for GNU/Linux, Windows and Mac OS X. Wings3D relies on OpenGL.</p>
<table class="docutils footnote" frame="void" id="footnote-4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-4">[4]</a></td><td>As opposed to <em>renderer</em>; yet Wings3D integrates an OpenCL renderer as well, deriving from <a class="reference external" href="https://luxcorerender.org/">LuxCoreRender</a>, an open-source Physically Based Renderer (it simulates the flow of light according to physical equations, thus producing realistic images of photographic quality).</td></tr>
</tbody>
</table>
<p>It can be installed on Arch Linux, from the AUR, as <tt class="docutils literal">wings3d</tt>; one can also rely on our <a class="reference external" href="https://hull.esperide.org/#wings3d">Wings3D shell scripts</a> in order to install and/or execute it.</p>
<p>We prefer using the <a class="reference external" href="#blender-conventions">Blender-like camera navigation conventions</a>, which can be set in Wings3D by selecting <tt class="docutils literal">Edit <span class="pre">-&gt;</span> Preferences <span class="pre">-&gt;</span> Camera <span class="pre">-&gt;</span> Camera Mode</tt> to <tt class="docutils literal">Blender</tt>.</p>
<p>See also:</p>
<ul class="simple">
<li>its <a class="reference external" href="http://www.wings3d.com/">official website</a></li>
<li>its <a class="reference external" href="https://github.com/dgud/wings">development project</a></li>
<li>its <a class="reference external" href="https://github.com/dgud/wings/blob/master/BUILD.unix">build instructions for UNIX-like systems</a></li>
</ul>
</div>
</div>
<div class="section" id="other-tools">
<h1><a class="toc-backref" href="#toc-entry-31">Other Tools</a></h1>
<div class="section" id="draco">
<h2><a class="toc-backref" href="#toc-entry-32">Draco</a></h2>
<p><a class="reference external" href="https://google.github.io/draco/">Draco</a> is an open-source library for compressing and decompressing 3D geometric meshes and point clouds.</p>
<p>It is intended to improve the storage and transmission of 3D graphics; it can be used <a class="reference external" href="https://github.com/google/draco#gltf-transcoding-tool">with glTF</a>, with Blender,  with <a class="reference external" href="https://github.com/GPUOpen-Tools/Compressonator">Compressonator</a>, or <a class="reference external" href="https://aur.archlinux.org/packages/draco-git/">separately</a>.</p>
<p>A <tt class="docutils literal">draco</tt> AUR package exists, and results notably in creating the <tt class="docutils literal">/usr/lib/libdraco.so</tt> shared library file.</p>
<p>Even once this package is installed, when Blender exports a mesh, a message like the following is displayed:</p>
<pre class="code bash literal-block">
<span class="s1">'/usr/bin/3.0/python/lib/python3.10/site-packages/libextern_draco.so'</span><span class="w"> </span>does<span class="w">
</span>not<span class="w"> </span>exist,<span class="w"> </span>draco<span class="w"> </span>mesh<span class="w"> </span>compression<span class="w"> </span>not<span class="w"> </span>available,<span class="w"> </span>please<span class="w"> </span>add<span class="w"> </span>it<span class="w"> </span>or<span class="w"> </span>create<span class="w">
</span>environment<span class="w"> </span>variable<span class="w"> </span>BLENDER_EXTERN_DRACO_LIBRARY_PATH<span class="w"> </span>pointing<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>folder
</pre>
<p>Setting the environment prior to running Blender is necessary (and done by our <tt class="docutils literal"><span class="pre">blender-*.sh</span></tt> scripts):</p>
<pre class="code bash literal-block">
$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">BLENDER_EXTERN_DRACO_LIBRARY_PATH</span><span class="o">=</span>/usr/lib
</pre>
<p>but not sufficient, as the built library does not bear the expected name.</p>
<p>So, as root, one shall fix that once for all:</p>
<pre class="code bash literal-block">
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>/usr/lib<span class="w">
</span>$<span class="w"> </span>ln<span class="w"> </span>-s<span class="w"> </span>libdraco.so<span class="w"> </span>libextern_draco.so
</pre>
<p>Then the log message will become:</p>
<pre class="code bash literal-block">
<span class="s1">'/usr/lib/libextern_draco.so'</span><span class="w"> </span>exists,<span class="w"> </span>draco<span class="w"> </span>mesh<span class="w"> </span>compression<span class="w"> </span>is<span class="w"> </span>available
</pre>
</div>
<div class="section" id="the-compressonator">
<h2><a class="toc-backref" href="#toc-entry-33">The Compressonator</a></h2>
<p>The <a class="reference external" href="https://gpuopen.com/compressonator/">Compressonator</a> is an AMD tool (as a GUI, a command-line executable and a SDK) designed to compress textures (e.g. in DXT1, DXT3 or DXT5 formats; typically resulting in a <tt class="docutils literal">.dds</tt> extension) and to generate mipmaps ahead of time, so that it does not have to be done at runtime.</p>
</div>
<div class="section" id="f3d">
<h2><a class="toc-backref" href="#toc-entry-34">F3D</a></h2>
<p><a class="reference external" href="https://github.com/f3d-app/f3d">f3d</a> (installable from the AUR) is a fast and minimalist VTK-based 3D viewer.</p>
<p>Such a viewer is especially interesting to investigate whether a tool failed to properly export a content or whether it is the next tool that actually failed to properly import, and to gain another chance of accessing to relevant error messages.</p>
</div>
<div class="section" id="mikktspace">
<h2><a class="toc-backref" href="#toc-entry-35">Mikktspace</a></h2>
<p>This tool (<a class="reference external" href="http://www.mikktspace.com/">official website</a>), created by Morten S. Mikkelsen, is a de facto (free) standard in terms of normal map baker: it generates <em>Tangent Space Normal Maps</em> (tangents), and helps ensuring consistency between 3D applications (such as Blender).</p>
<p>These fields of normals may be seen as an encoding - explaining why conventions like the ones enforced by this tool (which became an implementation standard) help performing a suitable, robust reciprocal decoding.</p>
</div>
<div class="section" id="mixamo">
<h2><a class="toc-backref" href="#toc-entry-36">Mixamo</a></h2>
<p><a class="reference external" href="https://www.mixamo.com/#/">Mixamo</a> is a website that allows to download and use for free a large number of rather high-quality 3D characters (about 110 of them; all being textured and rigged) and animations (about 2500 of them; full-body character animations, captured from professional motion actors), which can be arbitrarily mixed and matched.</p>
<p>This website allows also to rig one's (humanoid) character (see <tt class="docutils literal">Upload character</tt>).</p>
<p>The <a class="reference external" href="https://helpx.adobe.com/creative-cloud/faq/mixamo-faq.html">licence attached to Mixamo</a> is rather permissive; notably:</p>
<pre class="literal-block">
You can use both characters and animations royalty free for personal, commercial, and non-profit projects including:
   Incorporate characters into illustrations and graphic art.
   3D print characters.
   Create films.
   Create video games.
</pre>
</div>
</div>
<div class="section" id="opengl-corner">
<h1><a class="toc-backref" href="#toc-entry-37">OpenGL Corner</a></h1>
<div class="section" id="conventions">
<h2><a class="toc-backref" href="#toc-entry-38">Conventions</a></h2>
<p>Refer to our <a class="reference internal" href="#mini-opengl-glossary">Mini OpenGL Glossary</a> for most of the terms used in these sections.</p>
<p>Code snippets will correspond to the OpenGL/GLU APIs as they are exposed in Erlang, in the <a class="reference external" href="https://www.erlang.org/doc/man/gl.html">gl</a> and <a class="reference external" href="https://www.erlang.org/doc/man/glu.html">glu</a> modules respectively.</p>
<p>These translate easily for instance in the vanilla C GL/GLU implementations. As an example, <a class="reference external" href="https://www.erlang.org/doc/man/gl.html#ortho-6">gl:ortho/6</a> (<tt class="docutils literal">6</tt> designating here the arity of that function, i.e. the number of the arguments that it takes) corresponds to its C counterpart, <a class="reference external" href="https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/glOrtho.xml">glOrtho</a>.</p>
<p>The reference pages for OpenGL (in version 4.x) can be <a class="reference external" href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/">browsed here</a>.</p>
<p>Note that initially the information in this page related to older versions of OpenGL (1.1, 2.1, etc.; see <a class="reference external" href="https://www.khronos.org/opengl/wiki/History_of_OpenGL">history</a>) that relied on a fixed pipeline (no shader support) - whereas, starting from OpenGL 3.0, many of the corresponding features were marked as deprecated, and actually removed as a whole in 3.1. However, thanks to the <em>compatibility context</em> (whose support is not mandatory - but that all major implementations of OpenGL provide), these features can still be used.</p>
<p>Yet nowadays relying on at least the OpenGL 3 <em>core</em> context (not using the <em>compatibility</em> context) would be preferable (source: <a class="reference external" href="https://erlangforums.com/t/no-gl-get-1/1035">this thread</a>). Still better options would be to rely on OpenGL 4 Core or OpenGL ES 2+, or libraries on top of <a class="reference external" href="https://en.wikipedia.org/wiki/Vulkan">Vulkan</a>, like <a class="reference external" href="https://github.com/gfx-rs/wgpu">wgpu</a>. Specific libraries also exist for rendering for the web and for mobile, like <a class="reference external" href="https://www.w3.org/TR/webgpu/">WebGPU</a>.</p>
<p>As of 2023, the current OpenGL version is 4.6; we will try to stick to the latest ones (4.x) only (e.g. skipping intermediate changes in 3.2); even though in this document reminiscences of older OpenGL versions remain, the current minimum that we target is the <strong>Core Profile of OpenGL 3.3</strong>, which is &quot;modern OpenGL&quot; and introduced most features that still apply; it will halt on error if any deprecated functionality is used.</p>
<p>For more general-purpose computations (as opposed to rendering operations) to be offset to a GPU/GPGU, one may rely on <a class="reference external" href="Erlang.html#opencl">OpenCL</a> instead.</p>
<p>The mentioned tests will be <a class="reference external" href="http://myriad.esperide.org">Ceylan-Myriad</a> ones, typically located <a class="reference external" href="https://github.com/Olivier-Boudeville/Ceylan-Myriad/tree/master/test/user-interface/graphical/opengl">here</a>.</p>
<div class="section" id="basics">
<h3><a class="toc-backref" href="#toc-entry-39">Basics</a></h3>
<ul class="simple">
<li>OpenGL is a <strong>software interface to graphics hardware</strong>, i.e. the <em>specification</em> of an API (of around 150 functions in its older version 1.1), developed and maintained by the <a class="reference external" href="https://www.khronos.org/">Khronos Group</a></li>
<li>a video card will run an <em>implementation</em> of that specification, generally developed by the manufacturer of that card; a good rule of thumb is to always update one's video card drivers to their <strong>latest stable version</strong>, as OpenGL implementations are constantly improved (bug-fixing) and updated (with regard to newer OpenGL versions)</li>
<li>OpenGL concentrates on <strong>hardware-independent 2D/3D rendering</strong>; no commands for performing window-related tasks or obtaining user input are included; for example frame buffer configuration is done outside of OpenGL, in conjunction with the windowing system</li>
<li>OpenGL offers only <strong>low-level primitives</strong> organised through a <a class="reference external" href="https://www.glprogramming.com/blue/ch02.html#id57691">pipeline</a> in which vertices are assembled into primitives, then to fragments, and finally to pixels in the frame buffer; as such, OpenGL is a building-block for higher-level engines (e.g. like <a class="reference external" href="https://en.wikipedia.org/wiki/Godot_(game_engine)">Godot</a>)</li>
<li>OpenGL is a <strong>procedural</strong> (function-based, not object-oriented) <strong>state machine</strong> comprising a larger number of variables defined within a given OpenGL state (named an <em>OpenGL context</em>; comprising vertex coordinates, textures, frame buffer, etc.); said otherwise, all OpenGL state variables behave like &quot;global&quot; variables, more precisely they are actually relative to an OpenGL context that is often implicit; when a parameter is set, it applies and lasts as long as it is not modified (if still using the same OpenGL context); the effect of an OpenGL command may vary depending on whether certain modes are enabled (i.e. whether some state variables are set to a given value)</li>
<li>so the <strong>currently processed element</strong> (e.g. a vertex) <strong>inherits (implicitly) the current settings of the context</strong> (e.g. color, normal, texture coordinate, etc.); this is the only reasonable mode of operation, knowing that a host of parameters apply whenever performing a rendering operation (specifying all these parameters would not be a realistic option); as a result, any specific parameter shall be set first (prior to triggering such an operation), and is to last afterwards (being &quot;implicitly inherited&quot;), until possibly being reassigned in some later point in time</li>
<li>OpenGL respects a <strong>client/server execution model</strong>: an application (a specific client, running on a CPU) issues commands to a rendering server (on the same host or not - see GLX; generally the server can be seen as running on a local graphic card), that executes them <strong>sequentially and in-order</strong>; as such, most of the calls performed by user programs are <strong>asynchronous</strong>: they are triggered by the (client) program through OpenGL, and return almost immediately, whereas they have not been executed (by the server) yet: they have just be queued; indeed OpenGL implementations are almost always pipelined, so the rendering must be thought as primarily taking place in a background process; additional facilities like <em>Display Lists</em> allow to pipeline operations (as opposed to the default <em>immediate mode</em>), which are accumulated for processing at a later time, as fast as the graphic card can then process them</li>
<li>state variables are mostly server-side, yet some of them are client-side; in both cases, they can be gathered in <em>attribute groups</em>, which can be pushed on, and popped from, their respective server or client attribute stacks</li>
<li>OpenGL manages two types of data, handled by mostly different paths of its rendering pipeline, yet that are ultimately integrated in the framebuffer through fragment-yielding rasterization:<ul>
<li>geometric data (vertices, lines, and polygons)</li>
<li>pixel data (pixels, images, and bitmaps)</li>
</ul>
</li>
<li>vertices and normals are transformed by the <strong>model-view</strong> and <strong>projection</strong> matrices (that can be each set and transformed on a stack of their own), before being used to produce an image in the frame buffer; as for texture coordinates, they are transformed by the <strong>texture</strong> matrix</li>
<li>textures may reside in the main, general-purpose, client, <strong>CPU-side memory</strong> (large, but slow to access for the rendering) and/or in any auxiliary, dedicated, server-side <strong>GPU memory</strong> (more constrained, hence prioritized thanks to <em>texture objects</em>; and, rendering-wise, of significantly higher performance)</li>
<li>OpenGL has to apply varied kinds of transformations - &quot;linear&quot; (e.g. rotation, scaling) or not (e.g. translation, perspective) - to geometries, for example in order to perform coordinate system changes or rendering; each of these transformations can be represented as a 4x4 <a class="reference external" href="https://en.wikipedia.org/wiki/Homogeneous_coordinates">homogeneous matrix</a>, with floating-point (homogeneous) coordinates <a class="footnote-reference" href="#footnote-5" id="footnote-reference-5">[5]</a>; a series of transformations can then simply be represented as a single of such matrices, corresponding to the product (of course in a right order) of the involved transformation matrices</li>
</ul>
<table class="docutils footnote" frame="void" id="footnote-5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-5">[5]</a></td><td><p class="first">So a 3D point is specified based on 4 coordinates: <span class="math">\(P = \begin{pmatrix} x \\ y \\ z \\ w \end{pmatrix}\)</span>, with <tt class="docutils literal">w</tt> being usually equal to <tt class="docutils literal">1.0</tt> (otherwise the point can be normalised by dividing each of its coordinates by <tt class="docutils literal">w</tt>, provided of course that <tt class="docutils literal">w</tt> is not null - otherwise these coordinates do not specify a point but a direction).</p>
<p class="last">Thus summing (like vectors) two 4D points actually returns their mid-point (center of segment), as <tt class="docutils literal">w</tt> will be normalised: <span class="math">\(P1 + P2 = \begin{pmatrix} x1 \\ y1 \\ z1 \\ 1.0 \end{pmatrix} + \begin{pmatrix} x2 \\ y2 \\ z2 \\ 1.0 \end{pmatrix} = \begin{pmatrix} x1+x2 \\ y1+y1 \\ z1+z2 \\ 2.0 \end{pmatrix} = \begin{pmatrix} (x1+x2)/2.0 \\ (y1+y2)/2.0 \\ (z1+z2)/2.0 \\ 1.0 \end{pmatrix}\)</span></p>
</td></tr>
</tbody>
</table>
<ul>
<li><p class="first">while this will not change <em>anything</em> regarding the actual OpenGL library and the computations that it performs, the conventions adopted by the OpenGL <em>documentation</em> regarding matrices are the following ones:</p>
<ul class="simple">
<li>their <a class="reference external" href="https://www.opengl.org//archives/resources/faq/technical/transformations.htm">in-memory representation</a> is <a class="reference external" href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major order</a> (even if it is unusual, at least in C; this corresponds to Fortran-like conventions), meaning that it enumerates their coordinates first per column rather than per row (and for them a vector is a <em>row</em> of coordinates), whereas tools following the row-major counterpart order, <a class="reference external" href="http://myriad.esperide.org/#matrix-conventions">including Myriad</a>, do the opposite (and for them vectors are <em>columns</em> of coordinates); more clearly, a matrix like <span class="math">\(M = \begin{bmatrix} a11 &amp; a12 &amp; ... &amp; a1n \\ a21 &amp; a22 &amp; ... &amp; a2n \\ ... &amp; ... &amp; ... &amp; ... \\ am1 &amp; am2 &amp; ... &amp; amn \\ \end{bmatrix}\)</span><ul>
<li>will be stored with row-major conventions (e.g. Myriad) as: <tt class="docutils literal">a11, a12, ... a1n, a21, a22, ... a2n, am1, am2, ... amn</tt> (or, more precisely, as <tt class="docutils literal">[[a11, a12, ... a1n], [a21, a22, ... a2n], <span class="pre">...,</span> [am1, am2, ... amn]]</tt>)</li>
<li>whereas, with the conventions discussed, OpenGL will expect it to be stored in-memory in this order: <tt class="docutils literal">a11, a21, <span class="pre">...,</span> am1, a21, a22, <span class="pre">...,</span> am2, <span class="pre">...,</span> a1n, a2n, <span class="pre">...,</span> amn</tt>, i.e. as the transpose of the previous matrix</li>
</ul>
</li>
<li>these <a class="reference external" href="http://steve.hollasch.net/cgindex/math/matrix/column-vec.html">OpenGL storage conventions</a> do not tell how matrices are to be multiplied (knowing of course that the matrix product is not commutative); if following the aforementioned OpenGL <em>documentation</em> conventions, one should consider that OpenGL relies on the usual multiplication order, that is <strong>post-multiplication</strong>, i.e. <em>multiplication on the right</em>; this means that, if applying on a given matrix <span class="math">\(M\)</span> a transformation <span class="math">\(O\)</span> (e.g. rotation, translation, scaling, etc.) represented by a matrix <span class="math">\(M_O\)</span>, the resulting matrix will be <span class="math">\(M' = M.M_O\)</span> (and not <span class="math">\(M' = M_O.M\)</span>); a series of operations <span class="math">\(O_1\)</span>, then <span class="math">\(O_2\)</span>, ..., then <span class="math">\(O_n\)</span> will therefore correspond to a matrix <span class="math">\(M' = M_{O1}.M_{O2}.[...].M_{On}\)</span>; applying a vector <span class="math">\(\vec{V}\)</span> to a  matrix <span class="math">\(M\)</span> will result in <span class="math">\(\vec{V'} = M.\vec{V}\)</span></li>
<li>so when an OpenGL program performs calls implementing first a rotation (r), then a scaling (s) and finally a translation (t):</li>
</ul>
<pre class="code C literal-block">
<span class="n">glRotatef</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w">
</span><span class="n">glScalef</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">1.1</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w">
</span><span class="n">glTranslatef</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">);</span>
</pre>
<p>the current matrix <span class="math">\(M\)</span> ends up being multiplied (on the right) by <span class="math">\(M' = M_r.M_s.M_t\)</span>; when applied to a vector <span class="math">\(\vec{V}\)</span>, still multiplying on the right results in <span class="math">\(\vec{V'} = M.\vec{V} = M.M_r.M_s.M_t.\vec{V}'\)</span>; so the input vector <span class="math">\(\vec{V}\)</span> is first translated, then the result is scaled, then rotated, then transformed by the previous matrix <span class="math">\(M\)</span>; as a result: <strong>operations happen in the opposite order of their specification as calls</strong>; said differently: one shall specify the calls corresponding to one's target series of transformations <em>backwards</em></p>
<ul class="simple">
<li>considering that the OpenGL storage is done in a surprising column-major order was actually a trick so that OpenGL could rely on the (modern, math-originating) vector-as-column convention while being still compliant with its GL ancestor - which relied on the (now unusual) vector-as-row convention and on <em>pre-multiplication</em> (where we would have <span class="math">\(M' = M_O.M\)</span>); indeed, knowing that, when transposing matrices, <span class="math">\((A.B)^\top = B^\top.A^\top\)</span>, one may consider that OpenGL actually always operates on transpose elements, and thus that: (1) matrices are actually specified in row-order and (2) they are multiplied on the left (e.g. <span class="math">\(M' = M_t.M_s.M_r.M\)</span>); note that switching convention does not affect at all the computations, and that the same operations are always performed in reverse call order</li>
</ul>
</li>
</ul>
<ul class="simple">
<li>OpenGL can operate on three mutually exclusive <strong>modes</strong>:<ul>
<li><em>rendering</em>: is the default, most common mode, discussed here</li>
<li><em>feedback</em>: allows to capture the primitives generated by the vertex processing, i.e. to establish the primitives that would be displayed after the transformation and clipping steps; often used in order to resubmit this data multiple times</li>
<li><em>selection</em>: determines which primitives would be drawn into some region of a window (like in <em>feedback</em> mode), yet based on stacks of only user-specified &quot;names&quot; (so that the actual data of the corresponding primitives is not returned, just their name identifier); a special case of selection is <em>picking</em>, allowing to determine what are the primitives rendered at a given point of the viewport (typically the onscreen position of the mouse cursor, to enable corresponding interactions)</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="steps-for-opengl-rendering">
<h3><a class="toc-backref" href="#toc-entry-40">Steps for OpenGL Rendering</a></h3>
<p>The usual analogy to describe them is the process of <strong>producing a photography</strong>:</p>
<ol class="arabic simple">
<li>a set of elements (3D objects) can be placed (in terms of position and orientation) as wanted in order to compose one's scene of interest (<strong>modelling transformations</strong>, based on <em>world</em> coordinates)</li>
<li>the photographer may similarly place as wanted at least one camera (<strong>viewing transformations</strong>, based on <em>camera</em> coordinates)</li>
<li>the settings of the camera can be adjusted, for example regarding its lens / zoom factor (<strong>projection transformations</strong>, based on <em>window</em> coordinates)</li>
<li>the snapshots that it takes can be further adapted before being printed, for example in terms of scaling (<strong>viewport transformations</strong>, based on <em>screen</em> coordinates)</li>
</ol>
<p>One can see that the first two steps are reciprocal; for example, moving all objects in a direction or moving the camera in the opposite direction is basically the same operation. These two operations, being the two sides of the same coin, can thus be managed by a single matrix, the <em>model-view</em> one.</p>
<p>Finally, as mentioned in the section about storage conventions, in OpenGL, operations are to be defined in reverse order. If naming <span class="math">\(M_s\)</span> the matrix implementing a given step S, the previous process would be implemented by an overall matrix, based on the previous bullet numbers: <span class="math">\(M = M_4.M_3.M_2.M_1\)</span>, so that applying a vector <span class="math">\(\vec{V}\)</span> to <span class="math">\(M\)</span> results in <span class="math">\(\vec{V'} = M.\vec{V} = M_4.M_3.M_2.M_1.\vec{V} = M_4.(M_3.(M_2.(M_1.\vec{V})))\)</span>.</p>
</div>
<div class="section" id="transformations">
<h3><a class="toc-backref" href="#toc-entry-41">Transformations</a></h3>
<p>In this context - except notably the projections - most transformations are invertible, and a composition of invertible transformations, in any combination and sequence, is itself invertible.</p>
<p>As mentioned, they can all be expressed as 4x4 homogeneous matrices, and their composition translates into the (orderly) product of their matrices.</p>
<p>Coordinate system transitions are discussed further in this document, in the <a class="reference internal" href="#d-coordinate-systems">3D coordinate systems</a> section.</p>
<div class="section" id="translations-rotations-scalings-shearings">
<h4>Translations / Rotations / Scalings / Shearings</h4>
<ul class="simple">
<li>the inverse of a <strong>translation</strong> of a vector <span class="math">\(\vec{T}\)</span> is a translation of vector <span class="math">\(\vec{-T}\)</span>, thus: <span class="math">\((Mt_\vec{T})^{-1} = Mt_{-\vec{T}}\)</span></li>
<li>the inverse of a <strong>rotation</strong> of an angle <span class="math">\(\theta\)</span> along a vector <span class="math">\(\vec{U}\)</span> is a rotation of an angle <span class="math">\(-\theta\)</span> along the same vector, thus: <span class="math">\((Mr_(\vec{u},\theta))^{-1} = Mr_(\vec{u},-\theta)\)</span></li>
<li>the inverse of a (uniform) <strong>scaling</strong> of a (non-null) factor <span class="math">\(f\)</span> is a scaling of factor <span class="math">\(1/f\)</span>, thus: <span class="math">\((Ms_f)^{-1} = Ms_{1/f}\)</span>; the same applies for each factor when performing a shear mapping</li>
</ul>
</div>
<div class="section" id="reflections">
<h4>Reflections</h4>
<p>Symmetries with respect to an axis correspond to a scaling factor of <span class="math">\(-1\)</span> along this axis, and <span class="math">\(1\)</span> along the other axes.</p>
</div>
<div class="section" id="affine-transformations">
<h4>Affine Transformations</h4>
<p>An <a class="reference external" href="https://en.wikipedia.org/wiki/Affine_transformation">affine transformation</a> designates all geometric transformations that preserve lines and parallelism (but not necessarily distances and angles).</p>
<p>They are compositions of a linear transformation and a translation of their argument.</p>
<p>For them <span class="math">\(f(\lambda.x+y) = \lambda.f(x) + f(y)\)</span>.</p>
</div>
<div class="section" id="projections">
<h4>Projections</h4>
<p>In OpenGL, the projection matrix (<tt class="docutils literal">GL_PROJECTION</tt>) transforms eye coordinates to clip coordinates (not viewport coordinates).</p>
<p>A projection defines 6 clipping planes (and at least 6 additional ones can be defined).</p>
<p>A 3D plane is defined by including a given (3D) point and comprising all vectors orthogonal to a given vector; it can be defined thanks to 4 coordinates (e.g. <tt class="docutils literal">(a, b, c, d)</tt>); and a given point <span class="math">\(P = \begin{pmatrix} x \\ y \\ z \end{pmatrix}\)</span> will belong to such a plane iff <span class="math">\(a.x + b.y + c.z + d = 0\)</span>.</p>
<p>Two kinds of projections are considered below: orthographic and perspective; for extra information, refer to <a class="reference external" href="http://www.songho.ca/opengl/gl_projectionmatrix.html">this OpenGL Projection Matrix page</a>.</p>
<div class="section" id="orthographic-projections">
<h5>Orthographic Projections</h5>
<p>Their viewing volume is a parallelepiped, precisely a rectangular cuboid.</p>
<p>With such projections, parallel lines remain parallel; see <tt class="docutils literal">gl:ortho/6</tt> and <tt class="docutils literal">glu:ortho2D/4</tt>.</p>
</div>
<div class="section" id="perspective-projections">
<h5>Perspective Projections</h5>
<p>Their viewing volume is a truncated pyramid.</p>
<p>They are defined based on a field of view and an aspect ratio; see <tt class="docutils literal">gl:frustum/6</tt> and <tt class="docutils literal">glu:perspective/4</tt>.</p>
</div>
</div>
<div class="section" id="viewport-transformations">
<h4>Viewport Transformations</h4>
<p>As for the viewport, it is generally defined with <tt class="docutils literal">gl:viewport/4</tt> so that its size corresponds to the widget in which the rendering is to take place.</p>
<p>To avoid distortion, its aspect ratio must be the same as the one of the projection transformation.</p>
</div>
</div>
<div class="section" id="camera">
<h3><a class="toc-backref" href="#toc-entry-42">Camera</a></h3>
<p>The default model-view matrix is an identity; the camera (or eye) is located at the origin, points down the negative Z-axis, and has an up-vector of <tt class="docutils literal">(0, 1, 0)</tt>.</p>
<p>With Z-up conventions (like in Myriad ones), this corresponds to a camera pointing downward (see <a class="reference internal" href="#coordinate-systems-in-3d">Coordinate Systems In 3D</a> to picture it).</p>
<p>Calling <tt class="docutils literal">glu:lookAt/9</tt> allows to set arbitrarily one's camera position and orientation.</p>
<p>In order to switch from (OpenGL) Y-up conventions to Z-up ones, another option is to rotate the initial (identity) model-view matrix along the X axis of an angle of <span class="math">\(-\pi/2\)</span>, or to (post-)multiply the model-view matrix with:</p>
<div class="math">
\begin{equation*}
M_{camera} = P_{zup{\rightarrow}yup} = \begin{bmatrix}
       1 &amp;  0 &amp; 0 &amp; 0 \\
       0 &amp;  0 &amp; 1 &amp; 0 \\
       0 &amp; -1 &amp; 0 &amp; 0 \\
       0 &amp;   0 &amp;   0 &amp;  1 \\
    \end{bmatrix}
\end{equation*}
</div>
<p>For example, if we want that this camera sees, in the (Z-up) MyriadGUI coordinate system, a point <tt class="docutils literal">P</tt> at coordinates <span class="math">\(P_{zup}=\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}\)</span> (thus a point in its Y axis), then the coordinates of the same point P this time in the base OpenGL (Y-up) coordinate system must be <span class="math">\(P_{yup} = P_{zup{\rightarrow}yup}.P_{zup} = \begin{bmatrix} 0 \\ 0 \\ -1 \end{bmatrix}\)</span>; refer to the <a class="reference internal" href="#computing-transition-matrices">Computing Transition Matrices</a> section for more information.</p>
</div>
<div class="section" id="opengl-hints">
<h3><a class="toc-backref" href="#toc-entry-43">OpenGL Hints</a></h3>
<ul class="simple" id="gl-bindings">
<li>a frequent pattern is, for some type of OpenGL element (let's name it <tt class="docutils literal">Foo</tt>; it could designate for example <tt class="docutils literal">Texture</tt>, <tt class="docutils literal">Buffer</tt> or <tt class="docutils literal">VertexArray</tt>) is to call first (here in C) <tt class="docutils literal">glGenObjects(1, &amp;fooId);</tt> (note the plural), then <tt class="docutils literal">glBindObject(GL_SOME_TARGET, fooId);</tt><ul>
<li>it must be understood that <tt class="docutils literal">glGenObjects</tt> is the actual creator of (at least) one new (blank) instance of <tt class="docutils literal">Foo</tt>, whose address is kept by OpenGL behind the scenes; the user program will be able to access this instance only once bound thanks to an additional level of indirection, its (GL) identifier (<tt class="docutils literal">fooId</tt> here); &quot;integer pointers/identifiers&quot; are thus used</li>
<li>as for <tt class="docutils literal">glBindObject</tt>, its role is to register the <tt class="docutils literal">Foo</tt> pointer corresponding to the specified identifier <tt class="docutils literal">fooId</tt> in the C-like struct that corresponds to the current context (i.e. the current state of OpenGL), in the field designated here by <tt class="docutils literal">GL_SOME_TARGET</tt>, like in: <tt class="docutils literal"><span class="pre">current_gl_context-&gt;gl_some_target</span> = foo_pointer_for(fooId)</tt>; this operation is thus mostly a (quick) assignment</li>
<li>once bound, this <tt class="docutils literal">Foo</tt> instance can be accessed implicitly (through the current context) by calls such as <tt class="docutils literal">glSetFooOption(GL_SOME_TARGET, GL_OPTION_FOO_WIDTH, 800);</tt> (where neither its identifier nor any pointer for it is specified); once done, this instance can be unbound with <tt class="docutils literal">glBindObject(GL_SOME_TARGET, 0);</tt>; rebinding that identifier later will restore the corresponding options; as a result, several instances can be created, corresponding to as many sets of predefined options, and when a given one shall apply, it just has to be bound</li>
</ul>
</li>
<li>in OpenGL:<ul>
<li>3D coordinates are processed iff they are <em>Normalized Device Coordinates</em> (see <a class="reference internal" href="#ndc">NDC</a>), for all 3 dimensions</li>
<li>the <strong>alpha</strong> color coordinate encodes <strong>opacity</strong> (as usual); thus 1.0 means fully opaque, whereas 0.0 means fully transparent</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="mini-opengl-glossary">
<h3><a class="toc-backref" href="#toc-entry-44">Mini OpenGL Glossary</a></h3>
<p>Terms that are more or less specific to OpenGL:</p>
<ul class="simple">
<li><tt class="docutils literal">Accumulation buffer</tt>: a buffer that may be used for scene antialiasing; the scene is rendered several times, each time jittered less than one pixel, and the images are accumulated and then averaged</li>
<li><tt class="docutils literal">Alpha Test</tt>: to reject fragments based on their alpha coordinate; useful to reduce the number of fragments rendered through transparent surfaces</li>
<li><tt class="docutils literal">Context</tt>: a rendering context corresponds to the OpenGL state and the connection between OpenGL and the system; in order to perform a rendering, a suitable context must be current (i.e. bound, active for the OpenGL commands); it is possible to have multiple rendering contexts share buffer data and textures, which is specially useful when the application uses multiple threads for updating data into the memory of the graphics card</li>
<li><tt class="docutils literal">DDS</tt>: a file format suitable for texture compression that can be directly read by the GPU</li>
<li><tt class="docutils literal">Display list</tt>: a series of OpenGL commands, identified by an integer, to be stored, server-side, for subsequent execution; it is defined so that it can be sent and processed more efficiently, and probably multiple times, by the graphic card (compared to doing the same in immediate mode)</li>
<li><tt class="docutils literal">EBO</tt>: a (GLSL) <em>Element Buffer Object</em>, a buffer storing the index of each vertex that OpenGL shall draw (rather than the vertex itself), relatively to a corresponding VBO; defining faces based on indices rather than on vertices allows to avoid vertex duplication (as by design a vertex is common to multiple faces; it should be best specified only once, and referenced as many times as needed); <a class="reference external" href="https://learnopengl.com/Getting-started/Hello-Triangle">more information</a></li>
<li>(pixel) <tt class="docutils literal">fragment</tt>: two-dimensional description of elements (point, line segment, or polygon) produced by the rasterization step, before being stored as pixels in the frame buffer; also defined as: &quot;a point and its associated information&quot;; a fragment translates to a pixel after a process involving in turn: texture mapping, fog effect, antialiasing, tests (scissor, alpha, stencil, depth), blending, dithering, and logical operations on fragments (and, or, xor, not, etc.)</li>
<li><tt class="docutils literal">Evaluator</tt>: the part of the pipeline to perform polynomial mapping (basis functions) and transform higher-level primitives (such as NURBS) into actual ones (vertices, normals, texture coordinates and colors)</li>
<li><tt class="docutils literal">Frame buffer</tt>: the &quot;server-side&quot; pixel buffer, filled, after rasterization took place, by combinations (notably blending) of the selected fragments; it is actually made of a set of logical buffers of bitplanes: the color (itself comprising multiple buffers), depth (for hidden-surface removal), accumulation, and stencil buffers</li>
<li><tt class="docutils literal">GL</tt>: <em>Graphics Library</em> (also a shorthand for <em>OpenGL</em>, which is an open implementation thereof)</li>
<li><tt class="docutils literal">GLU</tt>: <em>OpenGL Utility Library</em>, a standard part of every OpenGL implementation, providing auxiliary features (e.g. image scaling, automatic mipmapping, setting up matrices for specific viewing orientations and projections, performing polygon tessellation, rendering surfaces, supporting quadrics routines that create spheres, cylinders, cones, etc.); see <a class="reference external" href="https://www.glprogramming.com/blue/ch02.html#id24847">this page</a> for more information</li>
<li><tt class="docutils literal">GLUT</tt>, <em>OpenGL Utility Toolkit</em>, a system-independent window toolkit hiding the complexities of differing window system APIs and more complicated three-dimensional objects such as a sphere, a torus, and a teapot; its main interest was when learning OpenGL, it is less used nowadays</li>
<li><tt class="docutils literal">GLX</tt>: the X extension of the OpenGL interface, i.e. a solution to integrate OpenGL to X servers; see <a class="reference external" href="https://www.glprogramming.com/blue/ch02.html#id86751">this page</a> for more information</li>
<li><tt class="docutils literal">GLSL</tt>: <a class="reference external" href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">OpenGL Shading Language</a>, a C-like language with which the transformation and fragment shading stages of the pipeline can be programmed; introduced in OpenGL 2.0; see <a class="reference external" href="#glsl">our GLSL section</a></li>
</ul>
<span id="ndc"></span><ul class="simple" id="ndcs">
<li><tt class="docutils literal">NDC</tt>: <em>Normalized Device Coordinate</em>; such a coordinate is, in OpenGL, in <span class="math">\([-1.0, 1.0]\)</span>, defining a cube (see <a class="reference external" href="https://learnopengl.com/img/getting-started/ndc.png">this example</a>, which does not represents the Z axis); only the points ultimately within this cube will be rendered, by being transformed to screen-space (viewport) coordinates and then fragments sent to the fragment shader; the conventions for texture coordinates (<a class="reference internal" href="#texels">texels</a>) are different</li>
<li><tt class="docutils literal">OpenCL</tt>: <a class="reference external" href="https://en.wikipedia.org/wiki/OpenCL">Open Computing Language</a>, a framework for writing programs that execute across heterogeneous platforms: central processing units (CPUs), graphics processing units (GPUs), digital signal processors (DSPs), field-programmable gate arrays (FPGAs) and other processors or hardware accelerators; in practice OpenCL defines programming languages, deriving from C and C++, for these devices, and APIs to control the platform and execute programs on the compute devices; OpenGL defines a standard interface for parallel computing using task-based and data-based parallelism; see also <a class="reference external" href="Erlang.html#opencl">our Erlang-related section</a></li>
<li><tt class="docutils literal">OpenGL ES</tt>: <a class="reference external" href="https://en.wikipedia.org/wiki/OpenGL_ES">OpenGL for Embedded Systems</a> is a subset of the OpenGL API, designed for embedded systems (like smartphones, tablet computers, video game consoles and PDAs)</li>
<li><tt class="docutils literal">Pixel</tt>: <em>Picture Element</em></li>
<li><tt class="docutils literal">Primitive</tt>: points, lines, polygons, images and bitmaps</li>
<li>(geometric) <tt class="docutils literal">Primitives</tt>: they are (exactly) points, lines and polygons</li>
<li><tt class="docutils literal">Rasterization</tt>: the process by which a primitive is converted to a two-dimensional image</li>
<li><tt class="docutils literal">Scissor Test</tt>: an arbitrary screen-aligned rectangle outside of which fragments will be discarded; useful to clear or update only a part of the viewport</li>
<li><tt class="docutils literal">Shader</tt>: a user-defined program providing the code for some programmable stages of the rendering pipeline; they can also be used in a slightly more limited form for general, on-GPU computation (<a class="reference external" href="https://www.khronos.org/opengl/wiki/Shader">source</a>)</li>
<li><tt class="docutils literal">Stencil Test</tt>: conditionally discards a fragment based on the outcome of a selected comparison between the value in the stencil buffer and a reference value; useful to perform non-rectangular clipping</li>
</ul>
<ul class="simple" id="texels">
<li><tt class="docutils literal">Texel</tt>: <em>Texture Element</em> ; it corresponds to a <tt class="docutils literal">(s,t)</tt> pair of coordinates in <tt class="docutils literal">[0,1]</tt> designating a point in a texture (see <a class="reference external" href="https://learnopengl.com/img/getting-started/tex_coords.png">this example</a>; <a class="reference internal" href="#ndcs">NDCs</a> span different ranges)</li>
<li><tt class="docutils literal">Vertex Array</tt>: these in-memory client-side arrays may aggregate 6 types of data (vertex coordinates, RGBA colors, color indices, surface normals, texture coordinates, polygon edge flags), possibly interleaved; such arrays allow to reduce the number of calls to OpenGL functions, and also to share elements (e.g. vertices pertaining to multiple faces should preferably be defined only once); in a non-networked setting, the GPU just dereferences the corresponding pointers</li>
<li><tt class="docutils literal">Viewport</tt>: the (rectangular) part (defined based on its lower left corner and its width and height, in pixels) within the current window in which OpenGL is to perform its rendering; so multiple viewports may be used in turn in order to offer multiple, composite views of the scene of interest in a given window; the ultimately processed 2D coordinates in OpenGL are both in <tt class="docutils literal"><span class="pre">[-1.0,</span> 1.0]</tt> before they are finally mapped to the current viewport dimensions (e.g. abscissa in <tt class="docutils literal">[0,800]</tt>, ordinate in <tt class="docutils literal">[0,600]</tt>, in pixels)</li>
<li><tt class="docutils literal">Vulkan</tt>: a low-overhead, cross-platform API, open standard for 3D graphics and computing; it is intended to offer higher performance and more balanced CPU and GPU usage than the OpenGL or Direct3D 11 APIs; it is lower-level than OpenGL, and not backwards compatible with it (<a class="reference external" href="https://en.wikipedia.org/wiki/Vulkan">source</a>)</li>
<li><tt class="docutils literal">VAO</tt>: a (GLSL) <em>Vertex Array Object</em> (OpenGL 4.x), able to store multiple VBOs (up to one for vertices, the others for per-vertex attributes); a VAO corresponds to an homogeneous chunk of data, sent from the CPU-space in order to be stored in the GPU-space; <a class="reference external" href="http://www.swiftless.com/tutorials/opengl4/4-opengl-4-vao.html">more information</a></li>
<li><tt class="docutils literal">VBO</tt>: a (GLSL) <em>Vertex Buffer Object</em>, a buffer storing a piece of information (vertex coordinates, or normal, or colors, or texture coordinates, etc.) for each element of a series of vertices; <a class="reference external" href="https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Buffer_Object">more information</a></li>
</ul>
<p>Refer to the <a class="reference external" href="https://www.glprogramming.com/blue/ch02.html#id57691">description of the pipeline</a> for further details.</p>
</div>
</div>
<div class="section" id="coordinate-systems">
<h2><a class="toc-backref" href="#toc-entry-45">Coordinate Systems</a></h2>
<div class="section" id="coordinate-systems-in-2d">
<h3><a class="toc-backref" href="#toc-entry-46">Coordinate Systems In 2D</a></h3>
<p>A popular convention, for example detailed in <a class="reference external" href="https://www.glprogramming.com/red/chapter02.html#name10">this section</a> of the (OpenGL) Red book, is to consider that the ordinates increase when going from the <em>bottom of the viewport to its top</em>; then for example the on-screen lower-left corner of the OpenGL canvas is <tt class="docutils literal">(0,0)</tt>, and its upper-right corner is <tt class="docutils literal">(Width,Height)</tt>.</p>
<p>As for us, we prefer the <a class="reference external" href="https://myriad.esperide.org/#2d-coordinate-system">MyriadGUI 2D conventions</a>, in which ordinates increase when going from the <em>top of the viewport to its bottom</em>, as depicted in the following figure:</p>
<p><span class="raw-html"><center><img src="myriad-2D-coordinate-system.png" id="responsive-image-xsmall"></img></center></span>
</p>
<p>Such a setting can be obtained thanks to (with Erlang conventions):</p>
<pre class="code erlang literal-block">
<span class="nn">gl</span><span class="p">:</span><span class="nf">matrixMode</span><span class="p">(</span><span class="o">?</span><span class="nv">GL_PROJECTION</span><span class="p">),</span><span class="w">
</span><span class="nn">gl</span><span class="p">:</span><span class="nf">loadIdentity</span><span class="p">(),</span><span class="w">

</span><span class="c">% Like glu:ortho2D/4:</span><span class="w">
</span><span class="nn">gl</span><span class="p">:</span><span class="nf">ortho</span><span class="p">(_</span><span class="nv">Left</span><span class="o">=</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Right</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="nv">CanvasWidth</span><span class="p">),</span><span class="w">
  </span><span class="p">_</span><span class="nv">Bottom</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="nv">CanvasHeight</span><span class="p">),</span><span class="w"> </span><span class="p">_</span><span class="nv">Top</span><span class="o">=</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Near</span><span class="o">=-</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Far</span><span class="o">=</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span>
</pre>
<p>In this case, the viewport can be addressed like a <strong>usual (2D) framebuffer</strong> (like provided by any classical 2D backend such as <a class="reference external" href="https://www.libsdl.org/">SDL</a>) obeying the coordinate system just described: if the width of the OpenGL canvas is 800 pixels and its height is 600 pixels, then its top-left on-screen corner is <tt class="docutils literal">(0,0)</tt> and its bottom-right one is <tt class="docutils literal">(799,599)</tt>, and any pixel-level operation can be directly performed there &quot;as usual&quot;. One may refer, in Myriad, to <tt class="docutils literal">gui_opengl_2D_test.erl</tt> for a full example thereof, in which line-based letters are drawn to demonstrate these conventions.</p>
<p>Each time the OpenGL canvas is resized, this projection matrix has to be updated, with the same procedure, yet based on the new dimensions.</p>
<p>Another option - still with axes respecting the Myriad 2D conventions - is to operate this time based on <strong>normalised, definition-independent coordinates</strong> (see <a class="reference internal" href="#ndc">NDC</a>), ranging in <tt class="docutils literal">[0.0, 1.0]</tt>, like in:</p>
<pre class="code erlang literal-block">
<span class="nn">gl</span><span class="p">:</span><span class="nf">matrixMode</span><span class="p">(</span><span class="o">?</span><span class="nv">GL_PROJECTION</span><span class="p">),</span><span class="w">
</span><span class="nn">gl</span><span class="p">:</span><span class="nf">loadIdentity</span><span class="p">(),</span><span class="w">

</span><span class="nn">gl</span><span class="p">:</span><span class="nf">ortho</span><span class="p">(_</span><span class="nv">Left</span><span class="o">=</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Right</span><span class="o">=</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Bottom</span><span class="o">=</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Top</span><span class="o">=</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Near</span><span class="o">=-</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">_</span><span class="nv">Far</span><span class="o">=</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span>
</pre>
<p>Using &quot;stable&quot;, device-independent floats - instead of integers directly accounting for pixels - is generally more convenient. For example a resizing of the viewport will then not require an update of the projection matrix. One may refer to <tt class="docutils literal">gui_opengl_minimal_test.erl</tt> for a full example thereof.</p>
</div>
<div class="section" id="coordinate-systems-in-3d">
<span id="d-coordinate-systems"></span><h3><a class="toc-backref" href="#toc-entry-47">Coordinate Systems In 3D</a></h3>
<p>We will rely here as well on the Myriad conventions, <a class="reference external" href="https://myriad.esperide.org/#3d-coordinate-system">this time for 3D</a> (not taking specifically time into account in this section, which anyway cannot be shown properly there):</p>
<p><span class="raw-html"><center><img src="myriad-space-time-coordinate-system.png" id="responsive-image-tiny"></img></center></span>
</p>
<p>These are thus Z-up conventions (the Z axis being vertical and designating altitudes), like modelling software such as Blender.</p>
<p>Note that perhaps the most popular convention is different, it is Y-up, for which X is horizontal, Y is up and Z is depth (hence Z-buffer) - this axis pointing then to the user.</p>
<div class="section" id="a-tree-of-coordinate-systems">
<h4>A Tree of Coordinate Systems</h4>
<p>In the general case, either in 2D or (more often of interest here) in 3D, a given scene (a model) is made of a set of elements (e.g. the model of a street may comprise a car, two bikes, a few people) that will have to be rendered from a given viewpoint (e.g. a window on the second floor of a given building) onto the (flat) user screen (with suitable clipping, perspective division and projection on the viewport). Let's start from the intended result and unwind the process.</p>
<p>The rendering objective requires to have ultimately one's scene transformed as a whole in <strong>eye coordinates</strong> (to obtain coordinates along the aforementioned 2D screen coordinate system, along the X and Y axes - the Z one serving to sort out depth, as per our 2D conventions).</p>
<p>For that, a prerequisite is to have the target scene correctly composed, with all its elements defined in the same, <strong>scene-global</strong>, space, in their respective position and orientation (then only the viewpoint, i.e. the virtual camera, can take into account the scene as a whole, to transform it ultimately to eye coordinates).</p>
<p>As each individual type of model (e.g. a bike model) is natively defined in an abstract, local coordinate system (an orthonormal basis) of its own, each actual model instance (e.g. the first bike, the second bike) has to be specifically placed in the coordinate system of the overall scene. This placement is either directly defined in that target space (e.g. bike A is at this absolute position and orientation in the scene global coordinate system) or relatively to a <em>series</em> of parent coordinate systems (e.g. this character rides bike B - and thus is defined relatively to it, knowing that for example the bike is placed relatively to the car, and that the car itself is placed relatively to the scene).</p>
<p>So in the general case, coordinate systems are nested (recursively defined relatively to their parent) and form a tree <a class="footnote-reference" href="#footnote-6" id="footnote-reference-6">[6]</a> whose root corresponds to the (possibly absolute) coordinate system of the overall scene, like in (<tt class="docutils literal">R</tt> standing here for <em>reference frame</em>, a concept that we deem a bit more general than <em>coordinate system</em>):</p>
<p><span class="raw-html"><center><img src="reference-frame-tree.png" id="responsive-image-medium"></img></center></span>
</p>
<table class="docutils footnote" frame="void" id="footnote-6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-6">[6]</a></td><td><p class="first">This is actually named a <em>scene graph</em> rather than a <em>scene tree</em>, as if we consider the leaves of that &quot;tree&quot; to contain actual geometries (e.g. of an abstract bike), as soon as a given geometry is instantiated more than once (e.g. if having 2 of such bikes in the scene), this geometry will have multiple parents and thus the corresponding scene will be a graph.</p>
<p class="last">As for us, we consider <em>reference frame trees</em> (no geometry involved) - a given 3D object being possibly associated to (1) a reference frame and (2) a geometry (independently). This is as expressive, and most probably clearer.</p>
</td></tr>
</tbody>
</table>
<p>A series of model transformations has thus to be operated in order to express all models in the scene reference frame:</p>
<pre class="literal-block">
(local reference frame of model Rh) -&gt; (parent reference frame Rf) -&gt; (parent reference frame Ra) -&gt; (scene reference frame Rs)
</pre>
<p>For example the hand of a character may be defined in <span class="math">\(R_h\)</span>, itself defined relatively to its associated forearm in <span class="math">\(R_f\)</span> up to the overall reference frame <span class="math">\(R_a\)</span> of that character, defined relatively to the reference frame of the whole scene, <span class="math">\(R_s\)</span>. This reference frame may have no explicit parent defined, meaning implicitly that it is defined in the canonical, global, &quot;world&quot; reference frame.</p>
<p>Once the <strong>model</strong> is expressed as a whole in the scene-global reference frame, the next transformations have to be conducted : <strong>view</strong> and projection. The view transformation involves at least an extra reference frame, the one of the camera in charge of the rendering, which is <span class="math">\(R_c\)</span>, possibly defined relatively to <span class="math">\(R_s\)</span> (or any other reference frame).</p>
<p>So a geometry (e.g. a part of the hand, defined in <span class="math">\(R_f\)</span>) has to be transformed upward in the reference frame tree in order to be expressed in the common, &quot;global&quot; scene reference frame <span class="math">\(R_s\)</span>, before being transformed last in the camera one, <span class="math">\(R_c\)</span> .</p>
<p>In practice, all these operations can be done thanks to the multiplication of homogeneous 4x4 matrices, each able to express any combination of rotations, scalings/reflections/shearings, translations <a class="footnote-reference" href="#footnote-7" id="footnote-reference-7">[7]</a>, which thus include the transformation of one reference frame into another. Their product can be computed once, and then applying a vector (e.g. corresponding to a vertex) to the resulting matrix allows to perform in one go the full composition thereof, encoding all model-view transformations (and even the projection) as well.</p>
<table class="docutils footnote" frame="void" id="footnote-7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-7">[7]</a></td><td>In practice the recommended order of the operations are: scaling, then rotation, then translation, otherwise they will become coupled and would interfere negatively (e.g. a translation vector would be scaled as well).</td></tr>
</tbody>
</table>
<p>Noting <span class="math">\(P_{a{\rightarrow}b}\)</span> the transition matrix transforming a vector <span class="math">\(\vec{V_a}\)</span> expressed in <span class="math">\(R_a\)</span> into its representation <span class="math">\(\vec{V_b}\)</span> in <span class="math">\(R_b\)</span>, we have:</p>
<div class="math">
\begin{equation*}
\vec{V_b} = P_{a{\rightarrow}b}.\vec{V_a}
\end{equation*}
</div>
<p>Thus, to express the geometry of said hand (natively defined in <span class="math">\(R_h\)</span>) in camera space (hence in <span class="math">\(R_c\)</span>), the following composition of reference frame changes <a class="footnote-reference" href="#footnote-8" id="footnote-reference-8">[8]</a> shall be applied:</p>
<div class="math">
\begin{equation*}
P_{h{\rightarrow}c} = P_{s{\rightarrow}c}.P_{a{\rightarrow}s}.P_{f{\rightarrow}a}.P_{h{\rightarrow}f}.
\end{equation*}
</div>
<table class="docutils footnote" frame="void" id="footnote-8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-8">[8]</a></td><td>Thus transformation matrices, knowing that the product of such matrices is in turn a transformation matrix.</td></tr>
</tbody>
</table>
<p>So a whole series of transformations can be done by applying a single matrix - whose coordinates are determined now.</p>
</div>
</div>
<div class="section" id="computing-transition-matrices">
<h3><a class="toc-backref" href="#toc-entry-48">Computing Transition Matrices</a></h3>
<p>For that, let's consider that an homogeneous 4x4 matrix is in the form of:</p>
<div class="math">
\begin{equation*}
M = \begin{bmatrix}
       r_{11} &amp; r_{12} &amp; r_{13} &amp; t_1 \\
       r_{21} &amp; r_{22} &amp; r_{23} &amp; t_2 \\
       r_{31} &amp; r_{32} &amp; r_{33} &amp; t_3 \\
         0 &amp;   0 &amp;   0 &amp;  1 \\
    \end{bmatrix}
\end{equation*}
</div>
<p>It can be interpreted as a matrix comprising two blocks of interest, <span class="math">\(R\)</span> and <span class="math">\(\vec{T}\)</span>:</p>
<div class="math">
\begin{equation*}
M = P_{1\rightarrow2}
      = \begin{bmatrix}
         R &amp; \vec{T} \\
         0 &amp;  1      \\
        \end{bmatrix}
\end{equation*}
</div>
<p>with:</p>
<ul class="simple">
<li><span class="math">\(\matrix{R}\)</span>, which accounts for a 3D rotation submatrix:</li>
</ul>
<div class="math">
\begin{equation*}
R = \begin{bmatrix}
       r_{11} &amp; r_{12} &amp; r_{13} \\
       r_{21} &amp; r_{22} &amp; r_{23} \\
       r_{31} &amp; r_{32} &amp; r_{33} \\
    \end{bmatrix}
\end{equation*}
</div>
<ul class="simple">
<li><span class="math">\(\vec{T}\)</span>, which accounts for a 3D translation vector:</li>
</ul>
<p><span class="math">\(\vec{T} = \begin{bmatrix} t1 \\ t2 \\ t3 \end{bmatrix}\)</span></p>
<p>Applying a (4x4 homogeneous) point <span class="math">\(P = \begin{Bmatrix} x \\ y \\ z \\ 1 \end{Bmatrix}\)</span> to <span class="math">\(M\)</span> yields <span class="math">\(P' = M.P\)</span> where <span class="math">\(P'\)</span> corresponds to <span class="math">\(P\)</span> once it has been (1) rotated by <span class="math">\(\matrix{R}\)</span> and then (2) translated by <span class="math">\(\vec{T}\)</span> (the order matters).</p>
<p>Let's consider now:</p>
<p><span class="raw-html"><center><img src="change-of-coordinate-system.png" id="responsive-image-small"></img></center></span>
</p>
<ul class="simple">
<li>two coordinate systems (defined as orthonormal bases), <span class="math">\(R_1\)</span> and <span class="math">\(R_2\)</span>; <span class="math">\(R_2\)</span> may for example be defined relatively to <span class="math">\(R_1\)</span>; for a given point or vector <span class="math">\(U\)</span>, <span class="math">\(U_1\)</span> will designate its coordinates in <span class="math">\(R_1\)</span>, and <span class="math">\(U_2\)</span> its coordinates in <span class="math">\(R_2\)</span></li>
<li><span class="math">\(P_{2\rightarrow1}\)</span> the (homogeneous 4x4) <a class="reference external" href="https://en.wikipedia.org/wiki/Change_of_basis">transition matrix</a> from <span class="math">\(R_2\)</span> to <span class="math">\(R_1\)</span>, specified first by blocks then by coordinates as:</li>
</ul>
<div class="math">
\begin{equation*}
P_{2\rightarrow1}
    = \begin{bmatrix}
       R  &amp; \vec{T} \\
       0  &amp;       1 \\
      \end{bmatrix}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
    = \begin{bmatrix}
       r_{11} &amp; r_{12} &amp; r_{13} &amp; t_1 \\
       r_{21} &amp; r_{22} &amp; r_{23} &amp; t_2 \\
       r_{31} &amp; r_{32} &amp; r_{33} &amp; t_3 \\
         0 &amp;   0 &amp;   0 &amp;  1 \\
    \end{bmatrix}
\end{equation*}
</div>
<ul class="simple">
<li>any (4D) point <span class="math">\(P\)</span>, whose coordinates are <span class="math">\(P_1\)</span> in <span class="math">\(R_1\)</span>, and <span class="math">\(P_2\)</span> in <span class="math">\(R_2\)</span></li>
</ul>
<p>The objective is to determine <span class="math">\(P_{2\rightarrow1}\)</span>, i.e. <span class="math">\(R\)</span> and <span class="math">\(\vec{T}\)</span>.</p>
<p>By definition of a transition matrix, for any point <span class="math">\(P\)</span>, we have: <span class="math">\(P_1 = P_{2\rightarrow1}.P_2 \qquad (1)\)</span></p>
<p>Let's study <span class="math">\(P_{2\rightarrow1}\)</span> by first choosing a point <span class="math">\(P\)</span> equal to the origin of <span class="math">\(R_2\)</span> (shown as <tt class="docutils literal">Ob</tt> in the figure).</p>
<p>By design, in homogeneous coordinates, <span class="math">\(P_2 = Ob_2 = \begin{Bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{Bmatrix}\)</span>, and applying it on <span class="math">\((1)\)</span> gives us: <span class="math">\(P_1 = Ob_1 = \begin{Bmatrix} t1 \\ t2 \\ t3 \\ 1 \end{Bmatrix}\)</span>.</p>
<p>So if <span class="math">\(Ob_1 = \begin{Bmatrix} XOb_1 \\ YOb_1 \\ ZOb_1 \\ 1 \end{Bmatrix}\)</span>, we have: <span class="math">\(\vec{T} = \vec{T_{2\rightarrow1}} = \begin{bmatrix} XOb_1 \\ YOb_1 \\ ZOb_1 \end{bmatrix}\)</span>.</p>
<p>Let's now determine the <span class="math">\(r_{xy}\)</span> coordinates.</p>
<p>Let <span class="math">\(R_{2\rightarrow1}\)</span> be the (3x3) rotation matrix transforming any vector expressed in <span class="math">\(R_2\)</span> in its representation in <span class="math">\(R_1\)</span>: for any (3D) vector <span class="math">\(\vec{V}\)</span>, we have <span class="math">\(\vec{V_1} = R_{2\rightarrow1}.\vec{V_2}  \qquad (2)\)</span></p>
<p>(we are dealing with vectors, not points, hence the origins are not involved here).</p>
<p>By choosing <span class="math">\(\vec{V}\)</span> equal to the <span class="math">\(\vec{Ib}\)</span> (abscissa) axis of <span class="math">\(R_2\)</span> (shown as <tt class="docutils literal">Ib</tt> in the figure), we have <span class="math">\(\vec{Ib_1} = R_{2\rightarrow1}.\vec{Ib_2}\)</span></p>
<p>Knowing that by design <span class="math">\(\vec{Ib_2} = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\)</span>, <span class="math">\((2)\)</span> gives us:</p>
<div class="math">
\begin{equation*}
\vec{Ib_1} = \begin{bmatrix} r_{11} \\ r_{21} \\ r_{31} \end{bmatrix}
          = \begin{bmatrix} XIb_{1} \\ YIb_{1} \\ ZIb_{1} \end{bmatrix}
\end{equation*}
</div>
<p>So the first column of the <span class="math">\(R\)</span> matrix is <span class="math">\(\vec{Ib_1}\)</span> , i.e. the first axis of <span class="math">\(R_2\)</span> as expressed in <span class="math">\(R_1\)</span>.</p>
<p>Using in the same way the two other axes of <span class="math">\(R_2\)</span> (shown as <tt class="docutils literal">Jb</tt> and <tt class="docutils literal">Kb</tt> in the figure), we see that:</p>
<div class="math">
\begin{equation*}
R = R_{2\rightarrow1}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
  = \begin{bmatrix}
       XIb_{1} &amp; XJb_{1} &amp; XKb_{1} \\
       YIb_{1} &amp; YJb_{1} &amp; YKb_{1} \\
       ZIb_{1} &amp; ZJb_{1} &amp; ZKb_{1} \\
    \end{bmatrix}
\end{equation*}
</div>
<p>So the transition matrix from <span class="math">\(R_2\)</span> to <span class="math">\(R_1\)</span> is:</p>
<div class="math">
\begin{equation*}
P_{2\rightarrow1}
    = \begin{bmatrix}
       R_{2\rightarrow1}  &amp; \vec{T_{2\rightarrow1}} \\
       0                  &amp;                       1 \\
      \end{bmatrix}
    = \begin{bmatrix}
       XIb_1 &amp; XJb_1 &amp; XKb_1 &amp; XOb_1 \\
       YIb_1 &amp; YJb_1 &amp; YKb_1 &amp; YOb_1 \\
       ZIb_1 &amp; ZJb_1 &amp; ZKb_1 &amp; ZOb_1 \\
           0 &amp;     0 &amp;     0 &amp;     1 \\
      \end{bmatrix}
\end{equation*}
</div>
<p>where:</p>
<ul class="simple">
<li><span class="math">\(R_{2\rightarrow1}\)</span> is the 3x3 rotation matrix converting vectors of <span class="math">\(R_2\)</span> in <span class="math">\(R_1\)</span>, i.e. whose columns are the axes of <span class="math">\(R_2\)</span> expressed in <span class="math">\(R_1\)</span></li>
<li><span class="math">\(\vec{T_{2\rightarrow1}} = Ob_1\)</span> is the 3D vector of the coordinates of the origin of <span class="math">\(R_2\)</span> as expressed in <span class="math">\(R_1\)</span></li>
</ul>
<p>This also corresponds to a matrix obtained by describing the <span class="math">\(R_2\)</span> coordinate system in <span class="math">\(R_1\)</span>, by listing first the three (4D) vector axes of <span class="math">\(R_2\)</span> then its (4D) origin, i.e. <span class="math">\(P_{2\rightarrow1} = \begin{bmatrix} \vec{Ib_1} &amp;&amp; \vec{Jb_1} &amp;&amp; \vec{Kb_1} &amp;&amp; Ob_1 \end{bmatrix}\)</span>.</p>
<p>Often, transformations have to be used both ways, like in the case of a scene-to-camera transformation; as a consequence, transition matrices may have to be inversed, knowing that <span class="math">\((P_{2\rightarrow1})^{-1} = P_{1\rightarrow2}\)</span> (since by definition <span class="math">\(P_{2\rightarrow1}.P_{1\rightarrow2} = Id\)</span>).</p>
<p>An option to determine <span class="math">\(P_{1\rightarrow2}\)</span> from <span class="math">\(P_{2\rightarrow1}\)</span> could be to compute its inverse directly, as <span class="math">\(P_{1\rightarrow2} = (P_{2\rightarrow1})^{-1}\)</span>, yet <span class="math">\(P_{1\rightarrow2}\)</span> may be determined in a simpler manner.</p>
<p>Indeed, for a given point <span class="math">\(P\)</span>, whose representation is <span class="math">\(P_1\)</span> in <span class="math">\(R_1\)</span> and <span class="math">\(P_2\)</span> in <span class="math">\(R_2\)</span>, we obtain <span class="math">\(P_1 =  P_{2\rightarrow1}.P_2\)</span> by - through the way (4x4) matrices are multiplied - first applying a (3x3) rotation <span class="math">\(Rot_3\)</span> to <span class="math">\(P_2\)</span> and then a (3D) translation <span class="math">\(T_r\)</span>: <span class="math">\(P_1 = Rot_3.P_2 + T_r\)</span> (in 3D; thus leaving out any fourth homogeneous coordinate); therefore <span class="math">\(P_2 = (Rot_3)^{-1}.(P_1 - T_r)\)</span>. Knowing that the inverse of an orthogonal matrix is its transpose, and that rotation matrices are orthogonal, <span class="math">\((Rot_3)^{-1} = (Rot_3)^\top\)</span>, and thus <span class="math">\(P_2 = (Rot_3)^\top.(P_1 - T_r) = (Rot_3)^\top.P_1 - (Rot_3)^\top.T_r\)</span>.</p>
<p>So if:</p>
<div class="math">
\begin{equation*}
P_{2\rightarrow1}
    = \begin{bmatrix}
       R_{2\rightarrow1}  &amp; \vec{T_{2\rightarrow1}} \\
       0                  &amp;                       1 \\
      \end{bmatrix}
\end{equation*}
</div>
<p>then:</p>
<div class="math">
\begin{equation*}
P_{1\rightarrow2}
    = \begin{bmatrix}
       (R_{2\rightarrow1})^\top  &amp; -(R_{2\rightarrow1})^\top.\vec{T_{2\rightarrow1}} \\
       0                         &amp;                                                 1 \\
      \end{bmatrix}
    = \begin{bmatrix}
       XIb_1 &amp; YIb_1 &amp; ZIb_1 &amp; -(XIb_1.XOb_1 + YIb_1.YOb_1 + ZIb_1.ZOb_1) \\
       XJb_1 &amp; YJb_1 &amp; ZJb_1 &amp; -(XJb_1.XOb_1 + YJb_1.YOb_1 + ZJb_1.ZOb_1) \\
       XKb_1 &amp; YKb_1 &amp; ZKb_1 &amp; -(XKb_1.XOb_1 + YKb_1.YOb_1 + ZKb_1.ZOb_1) \\
           0 &amp;     0 &amp;     0 &amp;                                          1 \\
      \end{bmatrix}
\end{equation*}
</div>
<div class="admonition note" id="summary">
<p class="first admonition-title">Note</p>
<p>Therefore, in a nutshell, the transition matrix from a coordinate system <span class="math">\(R_\alpha\)</span> to a coordinate system <span class="math">\(R_\beta\)</span> is:</p>
<div class="math">
\begin{equation*}
P_{\alpha\rightarrow\beta}
   = \begin{bmatrix}
      Rot_{\alpha\rightarrow\beta}  &amp; \vec{Tr_{\alpha\rightarrow\beta}} \\
      0                             &amp;                                 1 \\
     \end{bmatrix}
   = \begin{bmatrix}
      XIb_\beta &amp; XJb_\beta &amp; XKb_\beta &amp; XOb_\beta \\
      YIb_\beta &amp; YJb_\beta &amp; YKb_\beta &amp; YOb_\beta \\
      ZIb_\beta &amp; ZJb_\beta &amp; ZKb_\beta &amp; ZOb_\beta \\
              0 &amp;         0 &amp;         0 &amp;        1  \\
     \end{bmatrix}
\end{equation*}
</div>
<p>where:</p>
<ul class="simple">
<li><span class="math">\(Rot_{\alpha\rightarrow\beta}\)</span> is the 3x3 rotation matrix converting vectors of <span class="math">\(R_\alpha\)</span> in <span class="math">\(R_\beta\)</span>, i.e. whose columns are the axes of <span class="math">\(R_\alpha\)</span> expressed in <span class="math">\(R_\beta\)</span></li>
<li><span class="math">\(\vec{Tr_{\alpha\rightarrow\beta}} = Ob_\beta\)</span> is the 3D vector of the coordinates of the origin of <span class="math">\(R_\alpha\)</span> as expressed in <span class="math">\(R_\beta\)</span></li>
</ul>
<p>This also corresponds to a matrix obtained by describing the <span class="math">\(R_\alpha\)</span> coordinate system in <span class="math">\(R_\beta\)</span>, by listing first the three (4D) vector axes of <span class="math">\(R_\alpha\)</span> then its (4D) origin, i.e. <span class="math">\(P_{\alpha\rightarrow\beta} = \begin{bmatrix} \vec{Ib_\beta} &amp;&amp; \vec{Jb_\beta} &amp;&amp; \vec{Kb_\beta} &amp;&amp; Ob_\beta \end{bmatrix}\)</span>.</p>
<p>Its reciprocal (inverse transformation) is then:</p>
<div class="math last">
\begin{equation*}
P_{\beta\rightarrow\alpha}
   = \begin{bmatrix}
      (Rot_{\alpha\rightarrow\beta})^\top  &amp; -(Rot_{\alpha\rightarrow\beta})^\top.\vec{Tr_{\alpha\rightarrow\beta}} \\
                                    0  &amp;                                                                1 \\
     \end{bmatrix}
   = \begin{bmatrix}
      XIb_\beta &amp; YIb_\beta &amp; ZIb_\beta &amp; -(XIb_\beta.XOb_\beta + YIb_\beta.YOb_\beta + ZIb_\beta.ZOb_\beta) \\
      XJb_\beta &amp; YJb_\beta &amp; ZJb_\beta &amp; -(XJb_\beta.XOb_\beta + YJb_\beta.YOb_\beta + ZJb_\beta.ZOb_\beta) \\
      XKb_\beta &amp; YKb_\beta &amp; ZKb_\beta &amp; -(XKb_\beta.XOb_\beta + YKb_\beta.YOb_\beta + ZKb_\beta.ZOb_\beta) \\
          0 &amp;     0 &amp;     0 &amp;                                          1 \\
     \end{bmatrix}
\end{equation*}
</div>
</div>
<p>As a result, from the definition of a tree of coordinate systems, we are able to compute the transition matrix transforming the representation of a vector expressed in any of them to its representation in any of the other coordinate systems.</p>
<p>A special case of interest is, for the sake of rendering, to transform, through that tree, a local coordinate system in which a geometry is defined into the one of the camera, defining where it is positioned and aimed <a class="footnote-reference" href="#footnote-9" id="footnote-reference-9">[9]</a>; in OpenGL parlance, this corresponds to the <em>model-view</em> matrix (for &quot;modelling and viewing transformations&quot;) that we designate here as <span class="math last">\(M_{mv}\)</span> and which corresponds to <span class="math last">\(P_{local{\rightarrow}camera}\)</span>.</p>
<table class="docutils footnote" frame="void" id="footnote-9" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-9">[9]</a></td><td><tt class="docutils literal">gluLookAt</tt> can define such a viewing transformation matrix, when given (1) the position of the camera, (2) a point at which it shall look, and (3) a vector specifying its up direction (i.e. where is the upward direction for the camera - as otherwise all directions orthogonal to its line of sight defined by (1) and (2) could be chosen).</td></tr>
</tbody>
</table>
<p>Taking into account the last rendering step, the <em>projection</em> (comprising clipping, projection division and viewport transformation), which can be implemented as well thanks to a 4x4 (non-invertible) matrix designated here as <span class="math last">\(M_p\)</span>, we see that a single combined overall matrix <span class="math last">\(M_o = M_p.M_{mv}\)</span> is sufficient <a class="footnote-reference" href="#footnote-10" id="footnote-reference-10">[10]</a> to convey in one go all the transformations that shall be applied to a given geometry for its rendering.</p>
<table class="docutils footnote" frame="void" id="footnote-10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-10">[10]</a></td><td>In practice, for more flexibility, in older (pre-shader) OpenGL the management of the viewport, of the projection and of the model-view transformations was done separately (for example, respectively, with: <tt class="docutils literal">glViewport</tt>, <tt class="docutils literal">glMatrixMode(GL_MODELVIEW)</tt> and <tt class="docutils literal">glMatrixMode(GL_PROJECTION)</tt>; so, in compatibility mode, there is a matrix stack corresponding to <tt class="docutils literal">GL_MODELVIEW</tt> and another one to <tt class="docutils literal">GL_PROJECTION</tt>.</td></tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="main-matrices">
<h2><a class="toc-backref" href="#toc-entry-49">Main Matrices</a></h2>
<p>These matrices account for the main processing steps of a rendering.</p>
<p>Three types of coordinate systems can be considered:</p>
<ul class="simple">
<li><strong>world</strong> coordinate system: the absolute, overall coordinate system where 3D scenes are to be assembled</li>
<li><strong>local</strong> coordinate system: the coordinate system in which a given model is defined (generally placed at its origin)</li>
<li><strong>camera</strong> coordinate system: a coordinate system where a camera is at the origin, looking down on the negative Z axis</li>
</ul>
<p>The <strong>clip space</strong> can also be considered; this is the post-projection space, where the view frustum is transformed into a cube, centered in the origin, and going from -1 to 1 in every axis.</p>
<p>The transformations between coordinate systems can be represented by 4×4 transition matrices:</p>
<ul class="simple">
<li><strong>model matrix</strong> (<span class="math last">\(M_M\)</span>): to transform from local to world coordinate system</li>
<li><strong>view matrix</strong> (<span class="math last">\(M_V\)</span>): to transform from world to camera coordinate system</li>
<li><strong>projection matrix</strong> (<span class="math last">\(M_P\)</span>): to transform from camera coordinate system to clip space</li>
</ul>
<p>Finally, two composite matrices are especially useful (note the aforementioned reverse multiplication order) and are typically passed through uniform variables in shaders:</p>
<ul class="simple">
<li>ModelView: <span class="math last">\(M_{MV} = M_V.M_M\)</span></li>
<li>ModelViewProj: <span class="math last">\(M_{MVP} = M_P.M_{MV} =  M_P.M_V.M_M\)</span></li>
</ul>
</div>
<div class="section" id="shaders">
<h2><a class="toc-backref" href="#toc-entry-50">Shaders</a></h2>
<p>They are covered in-depth in <a class="reference external" href="https://www.khronos.org/opengl/wiki/Shader">the Khronos wiki</a>.</p>
<div class="section" id="a-programmable-pipeline">
<h3><a class="toc-backref" href="#toc-entry-51">A Programmable Pipeline</a></h3>
<p>Shaders are the basic rendering building blocks of applications using modern OpenGL (e.g. 3.x/4.0 versions).</p>
<p>Such an application will indeed program its own shaders, instead of calling functions like <tt class="docutils literal"><span class="pre">glBegin()/glEnd()</span></tt> as it was done with OpenGL 1.x-2.x and its fixed-pipeline immediate mode.</p>
<p>This mode of operation, albeit more complex, offers more control and enables increased performances.</p>
</div>
<div class="section" id="parallelism-in-the-pipeline">
<h3><a class="toc-backref" href="#toc-entry-52">Parallelism in the Pipeline</a></h3>
<p>The key is to write programs that can be executed in a <em>Single Instruction, Multiple Data</em> (SIMD) setting, in order to take advantage of the vectorization typically supported by GPUs.</p>
<p>A goal is to avoid conditional branching based on values that may differ from a shader invocation to another (see <a class="reference external" href="https://www.khronos.org/opengl/wiki/Shader#Execution_model_and_divergence">this explanation</a>).</p>
<p>If having to take into account two dynamically-uniform (i.e. non-statically predictable, yet having the same value for every shader invocation within that group) branches performing simple computations, it is likely that the compiler will generate code evaluating both expressions, until dropping the result of the one finally not happening.</p>
</div>
<div class="section" id="six-types-of-glsl-shaders">
<h3><a class="toc-backref" href="#toc-entry-53">Six Types of GLSL Shaders</a></h3>
<p>Shaders are written in the <strong>GLSL</strong> language, i.e. the <a class="reference external" href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">OpenGL Shading Language</a>.</p>
<p>They are portions of C-like code that can be inserted in the rendering pipeline implemented by the OpenGL driver of a GPU card. Six different kinds of shaders can be defined, depending on the processing step that they implement and on their purpose: vertex, tessellation for control or for evaluation, geometry, fragment or compute shaders.</p>
<p>Except this last type (compute shader), all types are mostly dedicated to <em>rendering</em>. If wanting to perform on one's GPU more general-purpose processing, <a class="reference external" href="https://en.wikipedia.org/wiki/OpenCL">OpenCL</a> shall be preferred to GLSL.</p>
<p>Each shader is to receive data to process that is appropriate to its type; for example each vertex shader instance will receive a vertex (multiple of such instances will process each their own vertex in parallel) whereas each fragment shader will operate on data specific to a pixel.</p>
<p>So shader instances will vary in terms of role (e.g. in charge of the processing of a vertex or a fragment), data types (input and output ones) and multiplicities (number of instances). Indeed, if considering a triangle whose vertices are each pure green, red or blue, only 3 vertices will be processed by the vertex shaders, whereas all the numerous pixels of the triangle will be the result of the evaluation of as many fragment shaders, each input of which is computed by interpolating the attributes of said 3 vertices - which ultimately results in a smooth gradient over the whole triangle.</p>
</div>
<div class="section" id="runtime-build">
<h3><a class="toc-backref" href="#toc-entry-54">Runtime Build</a></h3>
<p>Shaders are compiled at (application) runtime <a class="footnote-reference" href="#footnote-11" id="footnote-reference-11">[11]</a> (to target exactly the actual hardware), then linked and attached to a separate program running on the GPU. This is fairly low-level, black-box direct programming, in sharp contrast with the reliance on APIs that used to be the norm with OpenGL 1.x.</p>
<table class="docutils footnote" frame="void" id="footnote-11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-11">[11]</a></td><td>So each shader is built each time the application is started, and the operation may fail (e.g. with <tt class="docutils literal">0(40) : error C1503: undefined variable &quot;foobar&quot;</tt>).</td></tr>
</tbody>
</table>
<p>Yet offline compilers exist as well, as well as debuggers (like the NVIDIA NsightShader Debugger).</p>
</div>
<div class="section" id="implementing-a-shader">
<h3><a class="toc-backref" href="#toc-entry-55">Implementing a Shader</a></h3>
<p>A shader is quite similar to a C program, yet based on <a class="reference external" href="https://www.khronos.org/opengl/wiki/Core_Language_(GLSL)">a specific, core language</a> that enables the definition of relevant data types and functions.</p>
<p>Data types are usually based on elementary types (<tt class="docutils literal">float</tt>, <tt class="docutils literal">double</tt>, <tt class="docutils literal">bool</tt>, <tt class="docutils literal">int</tt> and <tt class="docutils literal">uint</tt>), and composed in larger structures, like <tt class="docutils literal"><span class="pre">{vec,mat}{2,3,4}</span></tt>, <tt class="docutils literal">mat2x3</tt>, arrays and structures, possibly <tt class="docutils literal">const</tt>; see <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/data-types/">this page</a> for further details.</p>
<p>Similarly, <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/statements-and-functions/">control flow statements and (non-recursive) functions</a> can be defined; every shader must have a <tt class="docutils literal">main</tt> function, and can define other auxiliary functions as well, in a way similar to a C program. Function parameters may have the <tt class="docutils literal">in</tt> (which is the default), <tt class="docutils literal">out</tt> or <tt class="docutils literal">inout</tt> qualifiers specified. Additionally a function may return a result, thanks to <tt class="docutils literal">return</tt>.</p>
<p>So, regarding output, for example a fragment shader must return the color that it computed: <tt class="docutils literal">out vec3 my_color;</tt> declares this; and the shader code may be as simple as returning a constant color in all cases, like in:</p>
<pre class="code glsl literal-block">
<span class="cp">#version 330 core</span><span class="w">
</span><span class="k">out</span><span class="w"> </span><span class="kt">vec3</span><span class="w"> </span><span class="n">my_color</span><span class="p">;</span><span class="w">

</span><span class="kt">void</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w">
</span><span class="p">{</span><span class="w">
   </span><span class="c1">// Same color returned for all fragments:</span><span class="w">
   </span><span class="n">my_color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">vec3</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span><span class="w"> </span><span class="mf">0.2</span><span class="p">,</span><span class="w"> </span><span class="mf">0.67</span><span class="p">);</span><span class="w">
</span><span class="p">}</span>
</pre>
</div>
<div class="section" id="communicating-with-shaders">
<h3><a class="toc-backref" href="#toc-entry-56">Communicating with Shaders</a></h3>
<p>Of course the application must have a way of supplying information to its shaders (the other way round does not really happen, except for compute shaders), and a given shader must be able to pass information to (only) any next shader in the pipeline.</p>
<p>Two options exist for shaders to have inputs and outputs, from/to the CPU and/or <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/inter-shader-communication/">other shaders</a>:</p>
<ul class="simple">
<li>basically each shader is fed with a stream of vertices <a class="footnote-reference" href="#footnote-12" id="footnote-reference-12">[12]</a> with associated data, named <strong>vertex attributes</strong>; these attributes are either <em>user-defined</em> or <em>built-in</em> (each type of shader having its own set of built-in input attributes)</li>
<li>global, read-only data can also be defined, as <strong>uniform</strong> variables</li>
</ul>
<table class="docutils footnote" frame="void" id="footnote-12" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-12">[12]</a></td><td>Then the user-defined <em>primitives</em>, applied later in the pipeline, will allow OpenGL to interpret such a series of vertices in terms of a sequence of triangles, or points, or lines, etc.</td></tr>
</tbody>
</table>
<p>These communication options are discussed more in-depth next.</p>
<div class="section" id="vertex-attributes">
<h4>Vertex Attributes</h4>
<div class="section" id="defining-attributes">
<h5>Defining Attributes</h5>
<p>A vertex attribute, whether user-defined or built-in, may store any kind of data - notably positions, texture coordinates and normals.</p>
<p>Either a given attribute is a single, <em>standalone</em> one (then a unique value will be read and will apply to all vertices), or is <em>per-vertex</em>, in which case it is read from a buffer, each element of it being bound accordingly when its associated vertex is processed by the shader. Such arrays are either used in-order, or according to any indices defined (then themselves defined thanks to an array as well) <a class="footnote-reference" href="#footnote-13" id="footnote-reference-13">[13]</a>.</p>
<table class="docutils footnote" frame="void" id="footnote-13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-13">[13]</a></td><td>This is the preferred method, as it prevents vertex duplication, and allows to process each of them once: there is a vertex cache that stores the outputs of the last processed vertices, so that if a vertex is mentioned multiple times (e.g. being included in a triangle fan or strip), the corresponding output may be directly re-used (provided it is still in the cache) instead of having to be computed again.</td></tr>
</tbody>
</table>
<p>Said differently, for each attribute used by a shader, either a single value or an array thereof must be specified.</p>
</div>
<div class="section" id="referencing-attributes">
<h5>Referencing Attributes</h5>
<p>In order that attributes can be defined in a place (program or shader) and referenced later by at least one shader, they must be matched:</p>
<ul class="simple">
<li>by (attribute) <em>name</em>: then they must bear exactly the same name in the main program and in the shader(s) using them, knowing that any name beginning with <tt class="docutils literal">gl_</tt> is reserved</li>
<li>or by (attribute) <em>location</em> (i.e. a positive integer): their common location is specified, and a per-shader variable name is associated - which is more flexible</li>
<li>or by <em>block</em>, like for the uniform variables, discussed below</li>
</ul>
<p>In the two last cases, the layout of variables must match on either side (for example in the main program and a given shader); for instance, with &quot;<tt class="docutils literal">layout(location = 0) in vec3 input_vertex;</tt>&quot; in its code, a vertex shader will expect a (single) vector of 3 (floating-point) coordinates (<tt class="docutils literal">vec3</tt>) to be found at index 0 (<tt class="docutils literal">location = 0</tt>) as input (<tt class="docutils literal">in</tt>); the application will need to specify a corresponding <em>Vertex Buffer Object</em> (VBO) for that.</p>
<p>So that they can be fetched for a given vertex, attributes have to be appropriately located in buffers. For each attribute, either the developer defines, prior to linking, a specific location (as an index starting at zero) with <tt class="docutils literal">glBindAttribLocation</tt>, or he lets OpenGL choose it, and queries it afterwards, with <tt class="docutils literal">glGetAttribLocation</tt>; refer to <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/attribute-variables/">this page</a> for further details.</p>
<p>If a given program is linked with two shaders, a vertex one and a fragment one, the former one will probably have to pass its outputs as inputs of the latter one; this requires as many variables defined on either side, with relevant out/in specifications, and a matching name and type; for example the vertex shader may declare <tt class="docutils literal">out vec3 my_color;</tt> whereas the fragment shader will declare <tt class="docutils literal">in vec3 my_color;</tt>.</p>
</div>
<div class="section" id="providing-attribute-data-vao-and-vbo">
<h5>Providing Attribute Data : VAO and VBO</h5>
<p>Vertex data is provided thanks to a (single current) <a class="reference external" href="https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Array_Object">Vertex Array Object</a> (VAO).</p>
<p>A VAO references (rather than storing directly) the format of the vertex data, as well as the buffers (VBOs, see below) holding that data.</p>
<p>A vertex attribute is identified by a number (in <tt class="docutils literal"><span class="pre">[0;GL_MAX_VERTEX_ATTRIBS-1]</span></tt>), and by default is accessed as a single value (as opposed to as an array).</p>
<p>A <a class="reference external" href="https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Buffer_Object">Vertex Buffer Object</a> (VBO) is a data array, typically referenced by a VAO. A VBO defines its internal structure and where the corresponding data can be found.</p>
<p>So, in practice, each homogeneous chunk of data (vertices, normals, colors) to be sent from the CPU-space to the GPU-space (hence from the client side to the server one) is stored in an array corresponding to a <em>Vertex Buffer Object</em> (VBO), itself referenced by a <em>Vertex Array Object</em> (VAO). A VAO may gather vertex data and colour data in separate VBOs, and store them on the graphics card for any later use (as opposed to streaming vertices through to the graphics card when they become needed). A VAO is only meant to hold one (VBO) array of vertices, each other VBO being used then for per-vertex attributes.</p>
</div>
</div>
<div class="section" id="uniform-variables-are-read-only-and-global">
<span id="uniform-variables"></span><h4>Uniform Variables are Read-Only and Global</h4>
<p>Instead of relying on attributes, an alternate way of passing information, provided that it may change relatively infrequently, is to use <em>uniform variables</em>, which behave, for a shader and in the course of a draw call, as read-only, constant global variables for all vertices (hence their <em>uniform</em> naming). Any shader can access every uniform variable (they are global), as long as it declares that variable, and these variables hold as long as they are not reset or updated.</p>
<p>Examples of uniform variables could be the position of a light, transformation matrices, fog settings, variables such as gravity and speed, etc.</p>
<p>Uniform variables may be defined individually, or be grouped in <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/uniform-blocks/">named blocks</a>, for a more effective data setup (to share uniform variables between programs) and transfer from the application to the shader (setting multiple values at once).</p>
<p>Uniform variables are declared at the program-level (as opposed to a per-vertex level) thanks to:</p>
<ul class="simple">
<li>the <tt class="docutils literal">uniform</tt> qualifier on the shader-side, like in <tt class="docutils literal">uniform mat4 MyMatrix;</tt></li>
<li>a <tt class="docutils literal">glGetUniformLocation</tt> call on the application-side, to create a location associated to a variable name (e.g. <tt class="docutils literal">my_matrix</tt>) in a shader, and to associate it to a given value, like, in C:</li>
</ul>
<pre class="code c literal-block">
<span class="n">mat4</span><span class="w"> </span><span class="n">some_matrix</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[...];</span><span class="w">

</span><span class="n">GLuint</span><span class="w"> </span><span class="n">location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">glGetUniformLocation</span><span class="p">(</span><span class="n">programId</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;my_matrix&quot;</span><span class="p">);</span><span class="w">

</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">location</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w">
</span><span class="p">{</span><span class="w">
   </span><span class="c1">// Defining a single matrix (1), not to transpose (GL_FALSE):
</span><span class="w">   </span><span class="n">glUniformMatrix4fv</span><span class="p">(</span><span class="n">location</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">GL_FALSE</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">some_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]);</span><span class="w">
   </span><span class="p">[...]</span>
</pre>
<p>Individual variables may be used as uniform, as well as arrays and structs.</p>
<p>From the point of view of a shader, these named input variables may be initialised when declared, but then are read-only; otherwise the application may choose to set them.</p>
</div>
<div class="section" id="built-in-variables-are-defined-by-each-shader-type">
<h4>Built-in Variables are Defined by Each Shader Type</h4>
<p>Finally, depending on the type of a shader, some predefined, built-in variables (&quot;intrinsic attributes&quot;) may be set; they are <a class="reference external" href="https://www.khronos.org/opengl/wiki/Built-in_Variable_(GLSL)">specified here</a>.</p>
<p>For example, for a vertex shader, following output variables are predefined:</p>
<ul class="simple">
<li><tt class="docutils literal">vec4 gl_Position</tt> corresponding to the clip-space (homogeneous) position of the output vertex</li>
<li><tt class="docutils literal">float gl_PointSize</tt></li>
<li><tt class="docutils literal">float gl_ClipDistance[]</tt></li>
</ul>
</div>
</div>
<div class="section" id="using-multiple-shaders-of-the-same-type">
<h3><a class="toc-backref" href="#toc-entry-57">Using Multiple Shaders of the Same Type</a></h3>
<p>One may want to use different shaders of the same type (e.g. to have a choice in terms of fragment shaders) in the same scene (e.g. one fragment shader dealing with solid colors, another one with textures).</p>
<p>At any time, up to one shader of a given type may be bound (active), but any number of shader objects (i.e. shaders loaded into memory and compiled) can be defined and available.</p>
<p>One approach is to switch shaders (with <tt class="docutils literal">glUseProgram</tt>) between draw calls: set a shader, draw a model, set another shader, draw another model. However switching shaders incurs some overhead, so a better course of action may be to group models/materials according to the shader they are to rely on, and to iterate on these shaders, bound one after the other, each only once per frame.</p>
<p>Other approaches are to render to textures, to rely on a Framebuffer Object with Renderbuffers Objects attached, or to use deferred shading or GLSL subroutines.</p>
<p>A last approach, perhaps the simplest and overall best, is to define a &quot;macro-shader&quot; per shader type (e.g. a macro-fragment shader) that regroups the code of each of the shaders of interest, and that may apply one or multiple of these effects based on conditions (variables); no switching will be needed then.</p>
<p>Refer to <a class="reference external" href="https://gamedev.stackexchange.com/questions/22216/using-multiple-shaders">this thread</a> for more details.</p>
</div>
<div class="section" id="troubleshooting-shaders">
<h3><a class="toc-backref" href="#toc-entry-58">Troubleshooting Shaders</a></h3>
<p>Once a shader builds correctly, it may misbehave at runtime.</p>
<p>One may refer to the &quot;Debugging shader output&quot; section of <a class="reference external" href="https://learnopengl.com/In-Practice/Debugging">this page</a>.</p>
</div>
<div class="section" id="examples-of-shaders">
<h3><a class="toc-backref" href="#toc-entry-59">Examples of Shaders</a></h3>
<p>See the <a class="reference external" href="https://github.com/dgud/wings/tree/master/shaders">ones of Wings3D</a> (in GLSL &quot;1.2&quot; apparently, presumably for maximum backward compatibility; note that some elements, with the <tt class="docutils literal">*.cl</tt> extension, are OpenCL ones), or <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/geometry-shader-examples/">these ones</a>.</p>
</div>
<div class="section" id="managing-spatial-transformations">
<h3><a class="toc-backref" href="#toc-entry-60">Managing Spatial Transformations</a></h3>
<p>Modern OpenGL (and GLU) implementations basically dropped the direct matrix support (the so-called immediate mode does not exist anymore, except in a compatibility context). So no more calls to <tt class="docutils literal">glTranslate</tt>, <tt class="docutils literal">glRotate</tt>, <tt class="docutils literal">glLoadIdentity</tt> or <tt class="docutils literal">gluPerspective</tt> shall be done; now the application has to compute such matrices (for model, view, texture, normal, projection, etc.) <em>by itself</em> (on the CPU), and the result thereof can be send on the GPU, as input to its GLSL shaders (typically thanks to <a class="reference internal" href="#uniform-variables">uniform variables</a>).</p>
<p>For that, applications may use dedicated, separate libraries, such as, in C/C++, GLM, i.e. <a class="reference external" href="https://github.com/g-truc/glm">OpenGL Mathematics</a> <a class="footnote-reference" href="#footnote-14" id="footnote-reference-14">[14]</a> (Myriad's <a class="reference external" href="http://myriad.esperide.org/#spatial-support">linear support</a> aims to provide, in Erlang, a relevant subset of these operations - albeit admittedly in a simplified form).</p>
<table class="docutils footnote" frame="void" id="footnote-14" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#footnote-reference-14">[14]</a></td><td>GLM is a free software header-only, template-based C++ library. See <a class="reference external" href="https://github.com/g-truc/glm/blob/master/manual.md">its manual</a> and for example <a class="reference external" href="https://github.com/g-truc/glm/blob/master/glm/detail/type_mat4x4.inl">its implementation of 4x4 float-based matrices</a> (and their corresponding <a class="reference external" href="https://github.com/g-truc/glm/blob/master/glm/ext/matrix_float4x4.hpp">type definition</a>). Note that, as GLM is targeted at OpenGL, by default it adopts column-major internal conventions, leading to a somehow unfamiliar mode of operation.</td></tr>
</tbody>
</table>
<p>The <a class="reference external" href="https://en.wikibooks.org/wiki/GLSL_Programming/Applying_Matrix_Transformations">matrices that correspond to the transformations</a> to be applied are then typically shared with the shaders thanks to uniform variables.</p>
<p>This is especially the case for the vertex shader, in charge of <a class="reference external" href="https://en.wikibooks.org/wiki/GLSL_Programming/Vertex_Transformations">transforming coordinates expressed in a local coordinate system into screen coordinates</a>.</p>
<p>More precisely, the modeling (object-space to absolute, world-space), viewing (world-space to camera-space) and projection (camera-space to clip-space) transformations are applied in the vertex shader, whereas the final perspective division and the viewport transformation are applied in the fixed-function stage after the vertex shader.</p>
<p>So a vertex shader is usually given two 4x4 homogeneous, uniform matrices:</p>
<ul class="simple">
<li>a modelview matrix, combining modeling and viewing, to transform object-space to camera-space in one go</li>
<li>a projection matrix</li>
</ul>
</div>
</div>
<div class="section" id="more-advanced-topics">
<h2><a class="toc-backref" href="#toc-entry-61">More Advanced Topics</a></h2>
<div class="section" id="shadows">
<h3><a class="toc-backref" href="#toc-entry-62">Shadows</a></h3>
<p>Determining the shadow of an arbitrary object on an arbitrary plane (representing typically the ground - or other objects) from an arbitrary light source (possibly at infinity) corresponds to performing a specific <strong>projection</strong>. For that, a relevant 4x4 (based on homogeneous coordinates) matrix (singular, i.e. non-invertible matrix) can be defined.</p>
<p>This matrix can be multiplied with the top of the model-view matrix stack, before drawing the object of interest in the shadow color (a shade of black generally).</p>
<p>Refer to <a class="reference external" href="https://www.glprogramming.com/red/chapter14.html#name15">this page</a> for more information.</p>
</div>
<div class="section" id="reference-glsl-compiler">
<h3><a class="toc-backref" href="#toc-entry-63">Reference GLSL Compiler</a></h3>
<p>As always, different compilers (corresponding to different brands of graphical cards) will not implement exactly the same way the (OpenGL GLSL, here) specification; and a shader may work correctly on one type of card and not on another.</p>
<p>Testing shader code with the <a class="reference external" href="https://www.khronos.org/opengles/sdk/tools/Reference-Compiler/">OpenGL / OpenGL ES Reference Compiler</a>, a.k.a. <tt class="docutils literal">glslang</tt> (installed on Arch Linux thanks to <tt class="docutils literal">pacman <span class="pre">-Sy</span> glslang</tt>, to be run as <tt class="docutils literal">glslangValidator</tt>) may report interesting information.</p>
<p>See the <em>OpenGL GLSL reference compiler</em> section of <a class="reference external" href="https://learnopengl.com/In-Practice/Debugging">this page</a> for more information.</p>
</div>
</div>
<div class="section" id="sources-of-information">
<h2><a class="toc-backref" href="#toc-entry-64">Sources of Information</a></h2>
<p>The reference pages for the various versions of OpenGL are <a class="reference external" href="https://www.khronos.org/registry/OpenGL-Refpages/">available on the Khronos official OpenGL Registry</a>.</p>
<p>Two very well-written books, strongly recommended, that are still relevant for 3D graphics despite their old age (circa 1996; for OpenGL 1.1) are:</p>
<ul class="simple">
<li><em>The Official Guide to Learning OpenGL</em>: the <a class="reference external" href="https://www.glprogramming.com/red/index.html">OpenGL Red book</a></li>
<li><em>The OpenGL Reference Manual</em>: the <a class="reference external" href="https://www.glprogramming.com/blue/index.html">OpenGL Blue book</a></li>
</ul>
<p>More modern tutorials (applying to OpenGL 3.3 and later) are:</p>
<ul class="simple">
<li><a class="reference external" href="http://www.opengl-tutorial.org/">Opengl-tutorial</a></li>
<li><a class="reference external" href="https://learnopengl.com/">Learn OpenGL</a></li>
<li>regarding GLSL shaders: <a class="reference external" href="https://www.lighthouse3d.com/tutorials/glsl-tutorial/">lighthouse3d</a></li>
</ul>
<p>Other elements of interest:</p>
<ul class="simple">
<li>the <a class="reference external" href="https://www.opengl.org/registry/doc/glspec33.core.20100311.withchanges.pdf">OpenGL 3.3 Specification (Core Profile)</a> (the 425-page reference PDF)</li>
<li>FAQ for <a class="reference external" href="https://www.khronos.org/opengl/wiki/FAQ">OpenGL</a> and <a class="reference external" href="https://www.opengl.org/resources/libraries/glut/faq/">GLUT</a></li>
<li>the (archived) <a class="reference external" href="https://www.opengl.org/archives/resources/faq/technical/">OpenGL FAQ and Troubleshooting Guide</a>, containing much valuable information, including regarding <a class="reference external" href="https://www.opengl.org/archives/resources/faq/technical/transformations.htm">transformations</a></li>
<li>About <a class="reference external" href="https://www.khronos.org/opengl/wiki/Performance">OpenGL Performance</a></li>
</ul>
<ul class="simple">
<li>in French: <a class="reference external" href="http://interaction.lille.inria.fr/~roussel/">Introduction à OpenGL et GLUT</a>, by Nicolas Roussel</li>
<li>any textbook on linear algebra</li>
</ul>
</div>
</div>
<div class="section" id="operating-system-support-for-3d">
<span id="os-support"></span><h1><a class="toc-backref" href="#toc-entry-65">Operating System Support for 3D</a></h1>
<p>Benefiting from a proper 2D/3D hardware acceleration on GNU/Linux is unfortunately not always straightforward, and sometimes brittle.</p>
<p>The very first step is to <strong>update's one's video drivers to their latest, official stable version</strong> according to your OS/distribution of choice (even if it implies using closed-source binaries...) and to check that they are in use (probably rebooting is then needed; note that updating one's kernel may also make the hardware acceleration be lost until the next reboot).</p>
<div class="section" id="testing">
<h2><a class="toc-backref" href="#toc-entry-66">Testing</a></h2>
<p>First, one may check whether such acceleration is already available by running, from the command-line and as the current, non-privileged user, the <tt class="docutils literal">glxinfo</tt> executable (to be obtained on Arch Linux thanks to the <tt class="docutils literal"><span class="pre">mesa-utils</span></tt> package), and hope to see, among the many displayed lines, <tt class="docutils literal">direct rendering: Yes</tt>.</p>
<p>One may also run our <a class="reference external" href="https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/display-opengl-information.sh">display-opengl-information.sh</a> script to report relevant information.</p>
<p>A final validation might be to run the <tt class="docutils literal">glxgears</tt> executable (still obtained through the <tt class="docutils literal"><span class="pre">mesa-utils</span></tt> package), and to ensure that a window appears, showing three gears properly rotating.</p>
</div>
<div class="section" id="troubleshooting-1">
<h2><a class="toc-backref" href="#toc-entry-67">Troubleshooting</a></h2>
<p>If it is not the case (no direct rendering, or a GLX error being returned - typically involving any <tt class="docutils literal">X Error of failed request:&nbsp; BadValue</tt> for a <tt class="docutils literal">X_GLXCreateNewContext</tt>), one should investigate one's configuration (with <tt class="docutils literal">lspci | grep VGA</tt>, <tt class="docutils literal">lsmod</tt>, etc.), update one's video driver on par with the current kernel, sacrifice a chicken, reboot, etc.</p>
<p>If using a NVidia graphic card, consider reading this <a class="reference external" href="https://wiki.archlinux.org/title/NVIDIA">Arch Linux wiki page</a> first.</p>
<p>In our case, relevant installations could be done with <tt class="docutils literal">pacman <span class="pre">-Sy</span> nvidia <span class="pre">nvidia-utils</span></tt> but required a reboot.</p>
<p>Despite package dependencies and a not-so-successful attempt of using DKMS in order to link kernel updates with graphic controller updates, too often a proper 3D support was lost, either from the boot or afterwards. Refer to our <a class="reference external" href="GNULinux.html#software-update">software update section</a> for hints in order to secure the durable use of proper drivers.</p>
</div>
</div>
<div class="section" id="minor-topics">
<h1><a class="toc-backref" href="#toc-entry-68">Minor Topics</a></h1>
<div class="section" id="camera-navigation-conventions">
<h2><a class="toc-backref" href="#toc-entry-69">Camera Navigation Conventions</a></h2>
<p>Multiple tools introduced conventions in order to navigate, with mouse and keyboard, in a 3D world.</p>
<p id="blender-conventions">We prefer the way Blender manages the observer viewpoint (current camera), as <a class="reference external" href="https://docs.blender.org/manual/en/latest/editors/3dview/navigate/navigation.html">described here</a>; notably, supposing a three-button mouse with a scrollwheel, basic navigation will be <strong>based on the middle button</strong>:</p>
<ul class="simple">
<li><tt class="docutils literal">orbit the view around the currently selected object</tt> (or <tt class="docutils literal">Tumble</tt>) by <strong>holding the middle button down</strong> and moving the mouse</li>
<li><tt class="docutils literal">pan</tt> (moving the view up, down, left and right) by holding down <strong>Shift and the middle button</strong>, and moving the mouse</li>
<li><tt class="docutils literal">zoom in/out</tt> with the <strong>scrollwheel</strong>; a variation of it, <tt class="docutils literal">Dolly</tt>, can be obtained by holding down <strong>Ctrl and the middle button</strong>, and moving the mouse</li>
</ul>
</div>
</div>
<div class="section" id="d-related-mini-glossary">
<h1><a class="toc-backref" href="#toc-entry-70">3D-Related Mini-Glossary</a></h1>
<ul class="simple">
<li><strong>HDRP</strong>: <em>High Definition Render Pipeline</em>, a <a class="reference external" href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition&#64;13.1/manual/index.html">high-fidelity scriptable render pipeline</a>, made by Unity to target <strong>modern</strong> (Compute Shader compatible) platforms (so HDRP is the high-end counterpart of URP)</li>
<li><strong>IK</strong>: <em>Inverse Kinematics</em>, the <strong>computation of intermediary joint parameters</strong> so that the end of the kinematic chain is at a given position and orientation; typically, if one wants the hand of a character to grasp the top of a chair, IK is used in order to determine the parameters of the character's wrist, arm, elbow, etc. that may be retained so that the hand is ultimately correctly placed on the chair (<a class="reference external" href="https://en.wikipedia.org/wiki/Inverse_kinematics">more information</a>)</li>
<li><strong>Material</strong>: controls the optical properties of an object, i.e. how a 3D object appears on the screen, that is: the color of each point of the object (generally thanks to multiple texture maps, like diffusion, normal, specular, glow, etc.) and how reflective or dull its surface appears; designates, with OpenGL, a set of coefficients that define <strong>how the lighting model interacts with the surface</strong>; in particular, ambient, diffuse, and specular coefficients for each color component (R,G,B) are defined and applied to a surface and effectively multiplied by the amount of light of each kind/color that strikes the surface; a final emissivity coefficient is then added to each color component so that objects can also be light emitters</li>
<li><strong>NURBS</strong>: <em>Non-Uniform Rational B-Spline</em>, a mathematical model using <a class="reference external" href="https://en.wikipedia.org/wiki/B-spline">basis splines</a> (B-splines) that is commonly used in computer graphics for representing <strong>curves and surfaces</strong>, whose shape is determined by control points (<a class="reference external" href="https://en.wikipedia.org/wiki/Non-uniform_rational_B-spline">more information</a>)</li>
<li><strong>PBR</strong>: <em>Physically-Based Rendering</em> designates approaches to render images in a way that <strong>models the flow of light in the real world</strong>, for example thanks to photogrammetry; many PBR pipelines aim to achieve photorealism; in practice they often rely on the <strong>micro-facet theory</strong>, with specific materials (generally based on texture maps) and shaders (is also called PBS, for <em>Physically-Based Shading</em>); PBR is slowly becoming the standard for all materials</li>
<li><strong>PSD</strong>: <em>Photoshop Document</em>, a <a class="reference external" href="https://docs.fileformat.com/image/psd/">proprietary format for graphics</a> with layers, masks, etc. used by Adobe Photoshop (a commercial counterpart to <a class="reference external" href="https://www.gimp.org/">Gimp</a>, <a class="reference external" href="https://krita.org">Krita</a>, etc.) often used to store textures that may still be edited as templates by the user - provided that they are using Photoshop as well; however, at least to some extent, <a class="reference external" href="https://wiki.gimp.org/wiki/PSD_support">Gimp is able to edit PSD files</a> and <a class="reference external" href="https://docs.krita.org/en/general_concepts/file_formats/file_psd.html">Krita too</a></li>
<li><strong>Rigging</strong> (or <em>Skeletal Animation</em>) consists in <strong>controlling the deformation of a mesh</strong> (a.k.a. a <em>skin</em>, the surface of a body) of an articulated object (typically a character) <strong>based on a virtual inner armature</strong> (a hierarchical set of interconnected parts, called <em>bones</em>, collectively forming the skeleton or <em>rig</em>) in order to animate that mesh (<a class="reference external" href="https://en.wikipedia.org/wiki/Skeletal_animation">more information</a>)</li>
<li><strong>Textures</strong>: bitmaps (images) used to <strong>skin 3D objects</strong>, by defining the color of each point on the surface of the object in terms of texture coordinates; besides such 2D textures, 1D, 3D and 4D ones exist</li>
<li><strong>Texture Atlas</strong>: a texture (an image) containing a <strong>set of separate, elementary graphic elements</strong>, meant to be extracted based on texture coordinates, akin to a sprite sheet; doing so is useful to reduce the overhead that would be induced by the management of many smaller textures (<a class="reference external" href="https://en.wikipedia.org/wiki/Texture_atlas">more information</a>)</li>
<li><strong>URP</strong>: <em>Universal Render Pipeline</em>, a prebuilt <a class="reference external" href="https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal&#64;13.1/manual/">scriptable render pipeline</a>, made by Unity, which implements workflows across a range of platforms, from mobile to high-end consoles and PC (in practice URP is the low-end counterpart of HDRP)</li>
</ul>
<p>See also the Wikipedia's <a class="reference external" href="https://en.wikipedia.org/wiki/Glossary_of_computer_graphics">glossary of computer graphics</a>.</p>
<p><span class="raw-html"><a name="howtos_bottom"></a></span></p>
</div>
</div>
</body>
</html>
