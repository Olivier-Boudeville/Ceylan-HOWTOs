.. _Top:


.. title:: Ceylan-HOWTOs: About 3D


========
About 3D
========


.. role:: raw-html(raw)
   :format: html

.. role:: raw-latex(raw)
   :format: latex


:raw-html:`<a name="howtos_top"></a>`

:raw-html:`<div class="banner"><p><em>Ceylan HOWTOs</em> <a href="http://howtos.esperide.org">browse latest</a> <a href="Ceylan-HOWTOs-english.pdf">get PDF</a> <a href="#howtos_top">go to top</a> <a href="#howtos_toc">go to toc</a> <a href="#howtos_bottom">go to bottom</a> <a href="Ceylan-HOWTOs-overview-english.html">go to HOWTOs</a> <a href="mailto:about(dash)ceylan-howtos(at)esperide(dot)com?subject=[Ceylan-HOWTOs]%20Remark%20about%203D">email us</a></p></div>`


:raw-html:`<center><img src="howtos-title.png" id="responsive-image-ultrasmall"></img>`


:Organisation: Copyright (C) 2021-GENERATION_YEAR_TAG Olivier Boudeville
:Contact: about (dash) howtos (at) esperide (dot) com
:Creation date: Saturday, November 20, 2021
:Lastly updated: GENERATION_DATE_TAG


:raw-html:`<a name="howtos_toc"></a>`

.. _`table of contents`:


.. contents:: **Table of Contents**
  :local:
  :depth: 3

:raw-html:`</center>`


As usual, these information pertain to a GNU/Linux perspective.



---------------------------
Cross-Platform Game Engines
---------------------------

The big three are Godot_, `Unreal Engine`_ and Unity3D_.


Godot
=====

`Godot <https://en.wikipedia.org/wiki/Godot_(game_engine)>`_ is our personal favorite engine, notably because it is free software (`released under the very permissive MIT license <https://godotengine.org/license>`_).

See its `official website <https://godotengine.org/>`_ and its `asset library <https://godotengine.org/asset-library/asset>`_.

Godot (version 3.4.1) will not be able to load FBX files that reference formats like PSD or TIF and/or of older versions (ex: FBX 6.1). See for that our section regarding `format conversions`_.



Installation
------------

On Arch Linux: ``pacman -Sy godot``.


Use
---

Godot logs are stored per-project; ex: ``~/.local/share/godot/app_userdata/my-test-project/logs/godot.log``; past log files are kept once timestamped. They tend not to have interesting content.

A configuration tree lies in ``.config/godot``, a cache tree in ``~/.cache/godot``.



Unreal Engine
=============

Another contender is the `Unreal Engine <https://en.wikipedia.org/wiki/Unreal_Engine>`_, a C++ game engine developed by Epic Games; we have not used it yet.

Its `licence <https://www.unrealengine.com/en-US/faq>`_ is meant to induce costs only when making large-enough profits.

See its `official website <https://www.unrealengine.com>`_ and its `marketplace <https://www.unrealengine.com/marketplace/en-US/store>`_.


Assets
------

Purchased assets may be used in one's own shipped products (`source <https://marketplacehelp.epicgames.com/s/article/How-can-I-use-the-products-I-ve-purchased-from-the-Marketplace-or-Learn-Tab?language=en_US>`_) and apparently at least usually no restrictive terms apply.

Assets not created by Epic Games can be used in other engines unless otherwise specified (`source <https://marketplacehelp.epicgames.com/s/article/Can-I-use-these-products-in-other-gaming-engines-like-Source-or-Unity?language=en_US>`_).




Unity3D
=======

`Unity <https://en.wikipedia.org/wiki/Unity_(game_engine)>`_ is most probably the cross-platform game engine that is the most popular.

Regarding the licensing of the engine, `various plans <https://store.unity.com/#plans-individual>`_ apply, depending notably on whether one subscribes as an individual or a team, and on one's profile, revenue and funding.

See its `official website <https://unity.com/>`_ and its `asset store <https://assetstore.unity.com/>`_.

.. _`Unity Assets`:

Unity may be installed at least in order to access its asset store, knowing that apparently an asset purchased in this store may be used with any game engine of choice. Indeed, for the standard licence, it is stipulated in the `EULA legal terms <https://unity3d.com/legal/as_terms>`_ that:

*Licensor grants to the END-USER a non-exclusive, worldwide, and perpetual license to the Asset to integrate Assets only as incorporated and embedded components of electronic games and interactive media and distribute such electronic game and interactive media.*

So, in legal terms, an asset could be bought in the Unity Asset Store and used in Godot, for example - provided that its content can be used there technically without too much effort/constraints (this may happen with prefabs, specific animations, materials or shaders, conventions in use, etc.).



Installation
------------

Unity shall now be obtained thanks to the Unity Hub.

On Arch Linux it is `available through the AUR <https://aur.archlinux.org/packages/unityhub/>`_, as an `AppImage <https://en.wikipedia.org/wiki/AppImage>`_; one may thus use: ``yay -Sy unityhub``.

Then, when running (as a non-priviledged user) ``unityhub``, a Unity account will be needed, then a licence, then a Unity release will have to be added in order to have it downloaded and installed for good, covering the selected target platforms (ex: Linux and Windows "Build Supports").

We rely here on the Unity version 2021.2.7f1.

Additional information: `Unity3D on Arch <https://wiki.archlinux.org/title/Unity3D>`_.



Configuration
-------------

Configuring Unity so that its interface (mouse, keyboard bindings) behave like, for example, the one of Blender, is not natively supported.



Running Unity
-------------

Just execute ``unityhub``, which requires signing up and activating a licence.



Troubleshooting
---------------

The log files are stored in ``~/.config/unity3d``:

- Unity Editor: ``Editor.log`` (the most interesting one)
- Unity Package Manager: ``upm.log``
- Unity Licensing client: ``Unity.Licensing.Client.log``

If the editor is stuck (ex: when importing an asset), one may use as a last resort `kill-unity3d.sh <https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/kill-unity3d.sh>`_.

In term of persistent state, beyond the project trees themselves, there are:

- ``~/.config/UnityHub/`` and ``~/.local/share/UnityHub/``
- ``~/.config/unity3d/`` and ``~/.local/share/unity3d/``

(nothing in ``~/.cache`` apparently)



Unity Assets
------------

Once ordered through the Unity Asset Store, assets can be downloaded through the ``Window -> Package Manager`` menu, by replacing, in the top ``Packages`` drop-down, the ``In Project`` entry by the ``My Assets`` one. After having selected an asset, use the ``Download`` button at the bottom-right of the screen.

Then, to gain access to such downloaded assets, of course the simplest approach is to use the Unity editor; this is done by creating a project (ex: ``MyProject``), selecting the aforementioned menu option (just above), then clicking on ``Import`` and selecting the relevant content that will end up in clear form in your project, i.e. in the UNIX filesystem with their actual name and content, for example in ``MyProject/Assets/CorrespondingAssetProvider/AssetName``. We experienced reproducible freezes when importing resources.

Yet such Unity packages, once downloaded (whether or not they have been imported in projects afterwards) are files stored typically in the ``~/.local/share/unity3d/Asset Store-5.x`` directory and whose extension is ``.unitypackage``.

Such files are actually ``.tar.gz`` archives, and thus their content can be listed thanks to:

.. code:: bash

 $ tar tvzf Foobar.unitypackage

Inside such archives, each individual package resource is located in a directory whose name is probably akin to the checksum of this resource (ex: ``167e85f3d750117459ff6199b79166fd``) [#]_; such directory generally contains at least 3 files:

- ``asset``: the resource itself, renamed to that unique checksum name, yet containing its exact original content (ex: the one of a Targa image)
- ``asset.meta``: the metadata about that asset (file format, identifier, timestamp, type-specific settings, etc.), as an ASCII, YAML-like, text
- ``pathname``: the path of that asset in the package "virtual" tree (ex: ``Assets/Foo/Textures/baz.tga``)

When applicable, a ``preview.png`` file may also exist.

.. [#] Yet no checksum tool among ``md5sum``, ``sha1sum``, ``sha256sum``, ``sha512sum``, ``shasum``, ``sha224sum``, ``sha384sum`` seems to correspond; it must a be a different, possibly custom, checksum.


Some types of content are Unity-specific and thus may not transpose (at least directly) to another game engine. This is the case for example for materials or prefabs (whose file format is relatively simple, based on `YAML <https://en.wikipedia.org/wiki/YAML>`_ 1.1).

Tools like `AssetStudio <https://github.com/Perfare/AssetStudio>`_ (probably Windows-only) strive to automate most of the process of exploring, extracting and exporting Unity assets.

Meshes are typically in the `FBX <https://en.wikipedia.org/wiki/FBX>`_ (proprietary) file format, that can nevertheless be imported in Blender_ and converted to other file formats (ex: gltF 2.0); see `blender import`_ and `blender convert`_ for that.



-------
3D Data
-------


File Formats
============

They are designed to store 3D content (scenes, nodes, vertices, normals, meshes, textures, materials, animations, skins, cameras, lights, etc.).



glTF
----

We prefer to rely on the open, well-specified, modern `glTF 2.0 format <https://en.wikipedia.org/wiki/GlTF>`_ in order to perform import/export operations.

It comes in two forms:

- either as ``*.gltf`` when JSON-based, possibly embedding the actual data (vertices, normals, textures, etc.) as ASCII `base64-encoded <https://en.wikipedia.org/wiki/Base64>`_ content, or referencing external files

- or as ``*.glb`` when binary; this is the most compact form, and the one that we recommend especially

See also the `glTF 2.0 quick reference guide <https://www.khronos.org/files/gltf20-reference-guide.pdf>`_, the `related section of Godot <https://docs.godotengine.org/en/stable/getting_started/workflow/assets/importing_scenes.html>`_ and `this standard viewer of predefined glTF samples <https://github.khronos.org/glTF-Sample-Viewer-Release/>`_.

This (generic) `online glTF viewer <https://gltf-viewer.donmccurdy.com/>`_ proved lightweight and convenient notably because it displays errors, warnings and information regarding the glTF data that it decodes.



Collada
-------

The second best choice that we see is `Collada <https://en.wikipedia.org/wiki/COLLADA>`_ (``*.dae`` files), an XML-based counterpart (open as well, yet older and with less validating facilities) to glTF.


.. comment Wings3D https://github.com/bjorng/wings/blob/master/plugins_src/import_export/wpc_collada.erl)



FBX, OBJ, etc.
--------------

Often, assets can be found as `FBX <https://en.wikipedia.org/wiki/FBX>`_ of `OBJ <https://en.wikipedia.org/wiki/Wavefront_.obj_file>`_ files and thus may have to be converted (typically to glTF), which is never a riskless task. FBX comes in two flavours: text-based (ASCII) or binary, see `this retro-specification <https://code.blender.org/2013/08/fbx-binary-file-format-specification/>`_ for more information.


In General
----------

Refer to `blender import`_ in order to handle the most common 3D file formats, and the next section about conversions.

The ``file`` command is able to report the version of at least some formats; for example:

.. code:: bash

 # Means FBX 7.3:
 $ file foobar.fbx
 foobar.fbx: Kaydara FBX model, version 7300


Too often, some tool will not be able to load a file and will fail to properly report why. When suspecting that a binary file (ex: a FBX one) references external content either missing or in an unsupported format (ex: PSD or TIFF?), one may peek at their content without any dedicated tool, directly from a terminal, like in:

.. code:: bash

 $ strings my_asset.fbx | sort | uniq | grep '\.'

This should list, among other elements, the paths that such a binary file is embedding.



.. _`format conversions`:


Conversions
===========

Due to the larger number of 3D file formats and the role of commercial software, interoperability regarding 3D content is poor and depends on many versions (of tools and formats).


Recommended Option: Relying on Blender
--------------------------------------

Using `blender import`_ is the primary solution that we see: a content, once imported in Blender, can be saved in any of the supported formats.

Yet this operation may fail, for example on "older" FBX files, whose FBX version (ex: 6.1) is not supported by Blender ("*Version 6100 unsupported, must be 7100 or later*") or by other tools such as Godot. See also the `Media Formats <https://docs.blender.org/manual/en/latest/files/media/index.html>`_ supported by Blender.


.. _`autodesk-converter`:


Workaround #1: Using Autodesk FBX Converter
-------------------------------------------

The simpler approach seems to download the (free) `Autodesk FBX Converter <https://images.autodesk.com/adsk/files/fbx20133_converter_win_x64.exe>`_ and to use `wine <GNULinux.html#wine>`_ to run it on GNU/Linux. Just install then this converter with: ``wine fbx20133_converter_win_x64.exe``.

A convenient alias (based on default settings, typically to be put in one's ``~/.bashrc``) can then be defined to run it:

.. code:: bash

 $ alias fbx-converter-ui="$HOME/.wine/drive_c/Program\ Files/Autodesk/FBX/FBX\ Converter/2013.3/FBXConverterUI.exe 2>/dev/null &"

Conversions may take place from, for example, FBX 6.1 (also: 3DS, DAE, DXF, OBJ) to a FBX version in: 2006, 2009, 2010, 2011, 2013 (i.e. 7.3 - of course the most interesting one here), but also DXF, OBJ and Collada, with various settings (embedded media, binary/ASCII mode, etc.).

An even better option is to use directly the command-line tool ``bin/FbxConverter.exe``, which the previous user interface actually executes. Use its ``/?`` option to get help, with interesting information.

For example, to update a file in a presumably older FBX into a 7.3 one (that Blender can import):

.. code:: bash

 $ cd ~/.wine/drive_c/Program\ Files/Autodesk/FBX/FBX\ Converter/2013.3/bin
 $ FbxConverter.exe My-legacy.FBX newer.fbx /v /sffFBX /dffFBX /e /f201300

We devised the `update-fbx.sh <https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/update-fbx.sh>`_ script to automate such an in-place FBX update.

Unfortunately, at least on one FBX sample taken from a Unity package, if the mesh could be imported in Blender, textures and materials were not (having checked ``Embed media`` in the converter or not).


Workaround #2: Relying on Unity
-------------------------------

Here the principle is to import a content in Unity (the same could probably be done with Godot), and to export it from there.

Unity does not allow to export for example FBX natively, however a package for that is provided. It shall be installed first, once per project.

One shall select in the menu ``Window -> Package Manager``, ensure that the entry ``Packages:`` points to ``Unity Registry``, and search for ``FBX Exporter``, then install it (bottom right button).

Afterwards, in the ``GameObject`` menu, an ``Export to FBX`` option will be available. Select the ``Binary`` export format (not ``ASCII``) if wanting to be compliant with Blender.




Samples
=======

Here are a few samples of 3D content (useful for testing):

- `glTF <https://github.com/KhronosGroup/glTF-Sample-Models>`_, notably `glTF 2.0 <https://github.com/KhronosGroup/glTF-Sample-Models/tree/master/2.0>`_; direct: `.gltf Buggy example <https://github.com/KhronosGroup/glTF-Sample-Models/raw/master/2.0/Buggy/glTF-Embedded/Buggy.gltf>`_, `.glb Fish example <https://github.com/KhronosGroup/glTF-Sample-Models/raw/master/2.0/BarramundiFish/glTF-Binary/BarramundiFish.glb>`_ (also: a `simple cube <http://paulbourke.net/dataformats/glTF/cube.txt>`_)
- `DAE <https://github.com/assimp/assimp/tree/master/test/models/Collada>`_; direct: `Duck example <https://github.com/assimp/assimp/raw/master/test/models/Collada/duck.dae>`_ (also: a `simple cube <https://gist.github.com/wtsnz/bfa11c40e04594b260255b5dc7956f26>`_)
- `FBX <https://free3d.com/dl-files.php?p=5671208f26be8b5e7b8b4567&f=4>`_; direct: `Stylized character <https://github.com/armory3d/armorpaint_samples/raw/master/sample.fbx>`_
- `OBJ <https://free3d.com/dl-files.php?p=51a50c9b46e0daad6a99bb49&f=0>`_
- `IFC <https://github.com/andrewisen/bim-whale-ifc-samples>`_; direct: `Basic house <https://github.com/andrewisen/bim-whale-ifc-samples/raw/main/BasicHouse/IFC/BasicHouse.ifc>`_ (requires the `BlenderBIM <https://blenderbim.org/download.html>`_ add-on for BIM support in Blender)



Asset Providers
===============

Usually, for one's creation, much multimedia artwork has to be secured: typically graphical assets (ex: 2D/3D geometries, animations, textures) and/or audio ones (ex: music, sounds, speech syntheses, special effects).

Instead of creating such content by oneself (not enough time/interest/skill?), it may be more relevant to rely on specialised third-parties.

**Hiring a professional or a freelance** is then an option. This is of course relatively expensive, involves more efforts (to define requirements and review the results), longer, but it is to provide exactly the artwork that one would like.

Another option is to rely on specialised third-party providers that **sell non-exclusive licences for the content they offer**.

These providers can be either direct **content producers** (companies with staffs of modellers), or **asset aggregators** (marketplaces which federate the offers of many producers of any size) that are often created in link to a given multimedia engine. An interesting point is that assets purchased in these stores generally can be used in any technical context, hence are not meant to be bound to the corresponding engine.

Nowadays, much content is available, in terms of theme/setting (ex: Medieval, Science-Fiction, etc.), of nature (ex: characters, environments, vehicles, etc.), etc. and the overall quality/price ratio is rather good.

The main advantages of these marketplaces is that:

- they favor the competition between content providers: the clients can easily compare assets and share their opinion about them
- they generalised simple, standard, unobtrusive licensing terms; ex: royalty free, allowing content to be used as they are or in a modified form, not limited by types of usage, number of distributed copies, duration of use, number of countries addressed, etc.; the general rule is that much freedom is left to the asset purchasers provided that they use for their own projects (rather than for example selling the artwork as they are)

The main content aggregators that we spotted are (roughly by decreasing order of interest, based on our limited experience):

- the `Unity Asset Store <https://assetstore.unity.com/>`_, already discussed in the `Unity Assets`_ section; websites like `this one <https://www.gameassetdeals.com/>`_ allow to track the significant discounts that are regularly made on assets
- the `UE Marketplace <https://www.unrealengine.com/marketplace/en-US/store>`_, i.e. the store associated to the Unreal Engine; in terms of licensing and uses:

  - `this article <https://marketplacehelp.epicgames.com/s/article/What-is-the-customer-getting-when-they-purchase-my-product?language=en_US>`_ states that *When customers purchase Marketplace products, they get a non-exclusive, worldwide, perpetual license to download, use, copy, post, modify, promote, license, sell, publicly perform, publicly display, digitally perform, distribute, or transmit your productâ€™s content for personal, promotional, and/or commercial purposes. Distribution of products via the Marketplace is not a sale of the content but the granting of digital rights to the customer.*
  - `this one <https://marketplacehelp.epicgames.com/s/article/Can-I-use-these-products-in-other-gaming-engines-like-Source-or-Unity?language=en_US>`_ states that *Any Marketplace products that have not been created by Epic Games can be used in other engines unless otherwise specified.*
  - `this one <https://marketplacehelp.epicgames.com/s/article/What-can-a-customer-do-with-my-product?language=en_US>`_ states that *All products sold on the Marketplace are licensed to the customer (who may be either an individual or company) for the lifetime right to use the content in developing an unlimited number of products and in shipping those products. The customer is also licensed to make the content available to employees and contractors for the sole purpose of contributing to products controlled by the customer.*
- `itch.io <https://itch.io/game-assets>`_
- `Turbosquid <https://www.turbosquid.com/Search/3D-Models>`_
- `Free3D <https://free3d.com/3d-models/>`_
- `CGtrader <https://www.cgtrader.com/>`_
- `ArtStation <https://www.artstation.com/marketplace/game-dev/assets>`_
- `Sketchfab <https://sketchfab.com/tags/asset-store>`_
- `3DRT <https://3drt.com/store/>`_
- `Reallusion <https://marketplace.reallusion.com/>`_
- `Arteria3D <https://arteria3d.myshopify.com/>`_
- the `GameDev Market <https://www.gamedevmarket.net/>`_ (GDM)
- the `Game Creator Store <https://tgcstore.net/>`_

.. not interesting enough - the `Construct <https://www.construct.net/en/game-assets>`_ Game Asset Store / Scirra Store

Many asset providers organise interesting discount offers (at least -50% on a selection of assets, sometimes even more for limited quantities) for the Black Friday (hence end of November) or for Christmas (hence mid-December till the first days of January).



------------------
Modelling Software
------------------


Blender
=======

Blender is a very powerful `open-source 3D toolset <https://en.wikipedia.org/wiki/Blender_(software)>`_.

Blender (version 3.0.0) can import FBX files of version at least 7.1 ("7100"). See for that our section regarding `format conversions`_.


.. _`blender import`:

.. _`blender convert`:

We recommend the use our `Blender scripts <http://hull.esperide.org#blender>`_ in order to:

- import conveniently various file formats in Blender, with ``blender-import.sh``
- convert directly on the command-line various file formats (still thanks to a non-interactive Blender), with ``blender-convert.sh``




Wings3D
=======

`Wings3D <https://en.wikipedia.org/wiki/Wings_3D>`_ is a nice, Erlang-based, free software subdivision modeler.

It can be installed on Arch Linux, from the AUR, as ``wings3d``.




-----------
Other Tools
-----------


Draco
=====

`Draco <https://google.github.io/draco/>`_ is an open-source library for compressing and decompressing 3D geometric meshes and point clouds.

It is intended to improve the storage and transmission of 3D graphics; it can be used `with glTF <https://github.com/google/draco#gltf-transcoding-tool>`_, with Blender,  with `Compressonator <https://github.com/GPUOpen-Tools/Compressonator>`_, or `separately <https://aur.archlinux.org/packages/draco-git/>`_.

A ``draco`` AUR package exists, and results notably in creating the ``/usr/lib/libdraco.so`` shared library file.


Even once this package is installed, when Blender exports a mesh, a message like the following is displayed:

.. code:: bash

 '/usr/bin/3.0/python/lib/python3.10/site-packages/libextern_draco.so' does
 not exist, draco mesh compression not available, please add it or create
 environment variable BLENDER_EXTERN_DRACO_LIBRARY_PATH pointing to the folder


Setting the environment prior to running Blender is necessary (and done by our ``blender-*.sh`` scripts:

.. code:: bash

 $ export BLENDER_EXTERN_DRACO_LIBRARY_PATH=/usr/lib

but not sufficient, as the built library does not bear the expected name.

So, as root, one shall fix that once for all:

.. code:: bash

 $ cd /usr/lib
 $ ln -s libdraco.so libextern_draco.so


Then the log message will become:

.. code:: bash

 '/usr/lib/libextern_draco.so' exists, draco mesh compression is available



F3D
===

`f3d <https://github.com/f3d-app/f3d>`_ (installable from the AUR) is a fast and minimalist VTK-based 3D viewer.

Such a viewer is especially interesting to investigate whether a tool failed to properly export a content or whether it is the next tool that actually failed to properly import, and to gain another chance to have relevant error messages.




-------------
OpenGL Corner
-------------


Conventions
===========

Code snippets will corresponds to the OpenGL/GLU APIs as they are exposed in Erlang, in the `gl <https://www.erlang.org/doc/man/gl.html>`_ and `glu <https://www.erlang.org/doc/man/glu.html>`_ modules respectively.

These translate easily for instance in the vanilla C GL/GLU implementations. As an example, `gl:ortho/6 <https://www.erlang.org/doc/man/gl.html#ortho-6>`_ (``6`` designating here the arity of that function, i.e. the number of the arguments that it takes) corresponds to its C counterpart, `glOrtho <https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/glOrtho.xml>`_.

The reference pages for OpenGL (in version 2.1) can be `browsed here <https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/>`_.

The mentioned tests will be `Ceylan-Myriad <http://myriad.esperide.org>`_ ones, typically located `here <https://github.com/Olivier-Boudeville/Ceylan-Myriad/tree/master/test/user-interface/graphical>`_.



Basics
------

- OpenGL is a **software interface to graphics hardware**, i.e. an API of around 150 functions (version 1.1)
- OpenGL concentrates on **hardware-independent 2D/3D rendering**; no commands for performing window-related tasks or obtaining user input are included; for example frame buffer configuration is done outside of OpenGL, in conjunction with the windowing system
- OpenGL offers only **low-level primitives** organised through a `pipeline <https://www.glprogramming.com/blue/ch02.html#id57691>`_ in which vertices are assembled into primitives, then to fragments, and finally to pixels in the frame buffer; as such OpenGL is a building-block for higher-level engines (ex: like Godot_)
- OpenGL is a **procedural** (function-based, not object-oriented) **state machine** comprising a larger number of variables defined within a given OpenGL state (named *OpenGL context*; comprising vertex coordinates, textures, frame buffer, etc.); said otherwise, relatively to an OpenGL context (which is often implicit), all OpenGL state variables behave like global variables; when a parameter is set, it applies and lasts as long as it is not modified; the effect of an OpenGL command may vary depending on whether certain modes are enabled (i.e. whether some state variables are set)
- so the **currently processed element** (ex: a vertex) **inherits (implicitly) the current settings of the context** (ex: color, normal, texture coordinate, etc.); this is the only reasonable mode of operation, knowing that a host of parameters apply when performing a rendering operation (specifying all these parameters would not be a realistic option); as a result, any specific parameter shall be set first (prior to triggering such an operation), and is to last afterwards (being "implicitly inherited"), until possibly being reassigned in some future
- OpenGL respects a **client/server execution model**: an application (a specific client, running on a CPU) issues commands to a rendering server (on the same host or not - see GLX; generally the server can be seen as running on a local graphic card), that executes them **sequentially and in-order**; as such, most of the calls performed by user programs are **asynchronous**: through OpenGL they are triggered by the program and return almost immediately, whereas they have not been executed yet; they have just be queued; indeed OpenGL implementations are almost always pipelined, so the rendering must be thought as primarily taking place in a background process; additional facilities like *Display Lists* allow to pipeline operations (as opposed to the default *immediate mode*), which are accumulated for processing at a later time
- state variables are mostly server-side, yet some of them are client-side; in both cases, they can be gathered in *attribute groups*, which can be pushed on, and popped from, their respective server or client attribute stacks
- OpenGL manages two types of data, handled by mostly different paths of its rendering pipeline yet that are ultimately integrated in the framebuffer through fragment-yielding rasterization:

  - geometric data (vertices, lines, and polygons)
  - pixel data (pixels, images, and bitmaps)

- vertices and normals are transformed by the **model-view** and **projection** matrices (that can be each set and transformed on a stack of their own), before being used to produce an image in the frame buffer; texture coordinates are transformed by the **texture** matrix
- textures may reside in the main, general-purpose, client, **CPU-side memory** (large and slow to access for the rendering) and/or in any auxiliary, dedicated, server-side **GPU memory** (more constrained, hence prioritized thanks to *texture objects*; and high-performance, rendering-wise)
- OpenGL has to apply any kind of transformation, linear (ex: rotation, scaling) or not (ex: translation, perspective) to geometries, for example in order to perform referential changes or rendering; each of these transformations can be represented as a 4x4 `homogeneous matrix <https://en.wikipedia.org/wiki/Homogeneous_coordinates>`_, with floating-point (homogeneous) coordinates [#]_; a series of transformations can then simply be represented as a single of such matrices, corresponding to the product of the involved transformation matrices


.. [#] So a 3D point is specified based on 4 coordinates: :math:`P = \begin{pmatrix} x \\ y \\ z \\ w \end{pmatrix}`, with ``w`` being usually equal to ``1.0`` (otherwise the point can be normalised by dividing each of its coordinates by ``w``, provided of course ``w`` is not null).

	   If ``w`` is null, then these coordinates do not specify a point but a direction.

- while this will not change anything regarding the actual OpenGL library and the computations that it performs, the conventions adopted by the OpenGL *documentation* regarding matrices are the following ones:

  - their `in-memory representation <https://www.opengl.org//archives/resources/faq/technical/transformations.htm>`_ is `column-major order <https://en.wikipedia.org/wiki/Row-_and_column-major_order>`_ (even if it is unusual, at least in C; this corresponds to Fortran-like conventions), meaning that it enumerates their coordinates first per column rather than per row (and for them a vector is a *row* of coordinates), whereas tools following the row-major counterpart order, `like Myriad <http://myriad.esperide.org/#matrix-conventions>`_ do the opposite (and vectors are *columns* of coordinates); more clearly, a matrix like :math:`M = \begin{bmatrix} a11 & a12 & ... & a1n \\ a21 & a22 & ... & a2n \\ ... & ... & ... & ... \\ am1 & am2 & ... & amn \\ \end{bmatrix}`

	- will be stored with row-major conventions (ex: Myriad) as: ``[ [a11, a12, ... a1n], [a21, a22, ... a2n], ..., [am1, am2, ... amn] ]``
	- whereas, with the conventions discussed, OpenGL will expect it to be stored in-memory in this order: ``a11, a21, ..., am1, a21, a22, ..., am2, ..., a1n, a2n, ..., amn``, i.e. as the transpose of the previous matrix

  - these `OpenGL storage conventions <http://steve.hollasch.net/cgindex/math/matrix/column-vec.html>`_ do not tell how matrices are to be multiplied (knowing of course that the matrix product is not commutative); if following the aforementioned OpenGL *documentation* conventions, one should consider that OpenGL relies on the usual multiplication order, that is **post-multiplication**, i.e. *multiplication on the right*; this means that, if applying on a given matrix :math:`M` a transformation :math:`O` (ex: rotation, translation, scaling, etc.) represented by a matrix :math:`M_O`, the resulting matrix will be :math:`M' = M.M_O` (and not :math:`M' = M_O.M`); a series of operations :math:`O_1`, then :math:`O_2`, ..., then :math:`O_n` will therefore translate to a matrix :math:`M' = M_{O1}.M_{O2}.[...].M_{On}`; applying a vector :math:`\vec{V}` to a  matrix :math:`M` will result in :math:`\vec{V'} = M.\vec{V}`

  - so when an OpenGL program performs calls like first for a rotation (r), then for a scaling (s) and finally for a translation (t):

  .. code:: C

	glRotatef(90, 0, 1, 0);
	glScalef(1, 10, 1);
	glTranslatef(5,10,5);


  the current matrix :math:`M` ends up being multiplied (on the right) by :math:`M' = M_r.M_s.M_t`; when applied to a vector :math:`\vec{V}`, still multiplying on the right results in :math:`\vec{V'} = M.\vec{V} = M.M_r.M_s.M_t.\vec{V}'`; so the input vector :math:`\vec{V}` is first translated, then the result is scaled, then rotated, then transformed by the previous matrix :math:`M`; as a result: **operations happen in the opposite order of their specification as calls**; said differently: one shall specify the calls corresponding to one's target series of transformations *backwards*

  - considering that the OpenGL storage is done in a surprising column-major order was actually a trick so that OpenGL could rely on the (modern, math-originating) vector-as-column convention while being still compliant with its GL ancestor - which relied on the (now unusual) vector-as-row convention and on *pre-multiplication* (where we would have :math:`M' = M_O.M`); indeed, knowing that, when transposing matrices, :math:`(A.B)^\top = B^\top.A^\top`, one may consider that OpenGL actually always operates on transpose elements, and thus that: (1) matrices are actually specified in row-order and (2) they are multiplied on the left (ex: :math:`M' = M_t.M_s.M_r.M`); note that switching convention does not affect at all the computations, and that the same operations are always performed in reverse call order

- OpenGL can operate on three mutually exclusive **modes**:

  - *rendering*: the default, most common one, discussed here
  - *feedback*: allows to capture the primitives generated by the vertex processing, i.e. to establish the primitives that would be displayed after the transformation and clipping steps; often used in order to resubmit this data multiple times
  - *selection*: determines which primitives would be drawn into some region of a window (like in *feedback* mode), yet based on stacks of only user-specified "names" (so that the actual data of the corresponding primitives is not returned, just their name identifier); a special case of selection is *picking*, allowing to determine what are the primitives rendered at a given point of the viewport (typically the onscreen position of the mouse cursor, to enable corresponding interactions)



Steps for OpenGL Rendering
--------------------------

The usual analogy to describe them is the process of **producing a photography**:

1. a set of elements (3D objects) can be placed (in terms of position and orientation) as wanted in order to compose one's scene of interest (*modelling transformations*, with world coordinates)
2. the photographer may similarly place as wanted his camera (*viewing transformations*, with camera coordinates)
3. the settings of the camera can be adjusted, for example regarding its lens / zoom factor (*projection transformations*, with window coordinates)
4. the snapshots that it takes can be further adapted before being printed, for example in terms of scaling (*viewport transformations*, with screen coordinates)


One can see that the first two steps are reciprocal; for example, moving all objects in a direction or moving the camera in the opposite one is basically the same operation. These two operations, being the two sides of the same coin, can thus be managed by a single matrix, the *model-view* one.

Finally, as mentioned, in OpenGL, operations are to be defined in reverse order. If naming :math:`M_s` the matrix implementing a given step S, the previous process would be implemented by an overall matrix :math:`M = M_4.M_3.M_2.M_1`, so that applying a vector :math:`\vec{V}` to :math:`M` results in :math:`\vec{V'} = M.\vec{V} = M_4.M_3.M_2.M_1.\vec{V} = M_4.(M_3.(M_2.(M_1.\vec{V})))`.



Transformations
---------------

In this context, except notably the projections, most are invertible, and a composition of invertible transformations, in any combination and sequence, is itself invertible.

As mentioned, they can all be expressed as 4x4 homogeneous matrices, and their composition translates into the (orderly) product of their matrices.

Referential transitions are discussed further in this document, in the `3D referentials`_ section.



Translations / Rotations / Scalings / Shearings
...............................................

- the inverse of a **translation** of a vector :math:`\vec{T}` is a translation of vector :math:`\vec{-T}`, thus: :math:`(Mt_\vec{T})^{-1} = Mt_{-\vec{T}}`

- the inverse of a **rotation** of an angle :math:`\theta` along a vector :math:`\vec{U}` is a rotation of an angle :math:`-\theta` along the same vector, thus: :math:`(Mr_(\vec{u},\theta))^{-1} = Mr_(\vec{u},-\theta)`

- the inverse of a **scaling** of a (non-null) factor :math:`f` is a scaling of factor :math:`1/f`, thus: :math:`(Ms_f)^{-1} = Ms_{1/f}`; the same applies for each factor when performing a shear mapping



Reflections
...........

Symmetries with respect to an axis correspond to a scaling factor of :math:`-1` along this axis, and :math:`1` along the other axes.



Affine Transformations
......................


An `affine transformation <https://en.wikipedia.org/wiki/Affine_transformation>`_ designates all geometric transformations that preserve lines and parallelism (but not necessarily distances and angles).

They are compositions of a linear transformation and a translation of their argument.

For them :math:`f(\lambda.x+y) = \lambda.f(x) + f(y)`.


Projections
...........

A projection defines 6 clipping planes (at least 6 additional ones can be defined).

A 3D plane is defined by 4 coordinates (ex: ``(a, b, c, d)``), and a point :math:`P = \begin{pmatrix} x \\ y \\ z \end{pmatrix}` will belong to such a plane iff :math:`a.x + b.y + c.z + d = 0`.

Two kinds of projections are considered: orthographic and perspective.


Orthographic Projections
________________________

Their viewing volume is a parallelepiped, precisely a rectangular cuboid.

With them parallel lines remain parallel; see ``gl:ortho/6`` and ``glu:ortho2D/4``.


Perspective Projections
_______________________

Their viewing volume is a truncated pyramid.

They are defined based on a field of view and an aspect ratio; see ``gl:frustum/6`` and ``glu:perspective/4``.



Viewport Transformations
........................

As for the viewport, it is generally defined with ``gl:viewport/4`` so that its size corresponds to the widget in which rendering will take place.

To avoid distortion, its aspect ratio must be the same as the one of the projection transformation.


Camera
------

The default model-view matrix is an identity; the camera is situated at the origin, points down the negative Z-axis, and has an up-vector of ``(0, 1, 0)``.

With Z-up conventions (like in MyriadGUI ones), this corresponds to a camera pointing downward.

Calling ``glu:lookAt/9`` allows to set arbitrarily one's camera (or eye) position and orientation.

In order to switch from (OpenGL) Y-up conventions to Z-up ones, another option is to rotate the initial (identity) model-view matrix along the X axis of an angle of :math:`-\pi/2`, or to (post-)multiply the model-view matrix with:

.. math::

 M_{camera} = P_{zup{\rightarrow}yup} = \begin{bmatrix}
		1 &  0 & 0 & 0 \\
		0 &  0 & 1 & 0 \\
		0 & -1 & 0 & 0 \\
		0 &   0 &   0 &  1 \\
	 \end{bmatrix}


For example, if we want that this camera sees, in (Z-up) MyriadGUI referential, a point ``P`` at coordinates :math:`P_{zup}=\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}` (thus a point in its Y axis), its coordinates in the base OpenGL (Y-up) referential must be :math:`P_{yup} = P_{zup{\rightarrow}yup}.P_{zup} = \begin{bmatrix} 0 \\ 0 \\ -1 \end{bmatrix}` ; refer to the `Computing Transition Matrices`_ section for more information.


Mini OpenGL Glossary
--------------------

Terms that are more or less specific to OpenGL:

- ``Accumulation buffer``: a buffer that may be used for scene antialiasing; the scene is rendered several times, each time jittered less than one pixel, and the images are accumulated and then averaged
- ``Alpha Test``: to reject fragments based on their alpha coordinate; useful to reduce the number of fragments rendered through transparent surfaces
- ``Context``: a rendering context corresponds to the OpenGL state and the connection between OpenGL and the system; in order to perform rendering, a suitable context must be current (i.e. bound, active for the OpenGL commands); it is possible to have multiple rendering contexts share buffer data and textures, which is specially useful when the application use multiple threads for updating data into the memory of the graphics card
- ``Display list``: a series of OpenGL commands, identified by an integer, to be stored (server-side) for subsequent execution; it is defined so that it can be sent and processed more efficiently, and probably multiple times, by the graphic card (compared to doing the same in immediate mode)
- (pixel) ``fragment``: two-dimensional description of elements (point, line segment, or polygon) produced by the rasterization step, before being stored as pixels in the frame buffer; also defined as: "a point and its associated information"; a fragment translates to a pixel after a process involving in turn: texture mapping, fog effect, antialiasing, tests (scissor, alpha, stencil, depth), blending, dithering, and logical operations on fragments (and, or, xor, not, etc.)
- ``Evaluator``: the part of the pipeline to perform polynomial mapping (basis functions) and transform higher-level primitives (such as NURBS) into actual ones (vertices, normals, texture coordinates and colors)
- ``Frame buffer``: the "server-side" pixel buffer, filled, after rasterization took place, by combinations (notably blending) of the selected fragments; it is actually made of a set of logical buffers of bitplanes: the color (itself comprising multiple buffers), depth (for hidden-surface removal), accumulation, and stencil buffers
- ``GL``: *Graphics Library* (also a shorthand for *OpenGL*)
- ``GLU``: *OpenGL Utility Library*, a standard part of every OpenGL implementation, providing auxiliary features (ex:image scaling, automatic mipmapping, setting up matrices for specific viewing orientations and projections, performing polygon tessellation, rendering surfaces, supporting quadrics routines that create spheres, cylinders, cones, etc.); see `this page <https://www.glprogramming.com/blue/ch02.html#id24847>`_ for more information
- ``GLUT``, *OpenGL Utility Toolkit*, a window system-independent toolkit hiding the complexities of differing window system APIs and more complicated three-dimensional objects such as a sphere, a torus, and a teapot; its main interest was when learning OpenGL, nowadays is less used
- ``GLX``: the X extension of the OpenGL interface, i.e. a solution to integrate OpenGL to X servers; see `this page <https://www.glprogramming.com/blue/ch02.html#id86751>`_ for more information
- ``Pixel``: *Picture Element*
- ``Primitive``: points, lines, polygons, images, and bitmaps
- (geometric) ``Primitives``: they are (exactly) points, lines, and polygons
- ``Rasterization``: the process by which a primitive is converted to a two-dimensional image
- ``Scissor Test``: an arbitrary screen-aligned rectangle outside of which fragments will be discarded; useful to clear or update only a part of the viewport
- ``Stencil Test``: conditionally discards a fragment based on the outcome of a selected comparison between the value in the stencil buffer and a reference value; useful to perform non-rectangular clipping
- ``Texel``: *Texture Element* ; it corresponds to a ``(s,t)`` pair of coordinates in ``[0,1]`` designating a point in a texture
- ``Vertex Array``: these in-memory client-side arrays may aggregate 6 types of data (vertex coordinates, RGBA colors, color indices, surface normals, texture coordinates, polygon edge flags), possibly interleaved; such arrays allow to reduce the number of calls to OpenGL functions, and also to share elements (ex: vertices pertaining to multiple faces should preferably be defined only once); in a non-networked setting, the GPU just dereferences the corresponding pointers

Refer to the `description of the pipeline <https://www.glprogramming.com/blue/ch02.html#id57691>`_ for further details.


Referentials
============


Referentials In 2D
------------------

A popular convention, for example detailed in `this section <https://www.glprogramming.com/red/chapter02.html#name10>`_ of the Red book, is to consider that the ordinates increase when going from the *bottom of the viewport to its top*; then for example the on-screen lower-left corner of the OpenGL canvas is ``(0,0)``, and its upper-right corner is ``(Width,Height)``.

As for us, we prefer the `MyriadGUI 2D conventions <https://myriad.esperide.org/#2d-referential>`_, in which ordinates increase when going from the *top of the viewport to its bottom*, as depicted in the following figure:

:raw-html:`<center><img src="myriad-2D-referential.png" id="responsive-image-xsmall"></img></center>`
:raw-latex:`\begin{figure}[h] \centering \includegraphics[scale=0.5]{myriad-2D-referential} \end{figure}`

Such a setting can be obtained thanks to:

.. code:: erlang

 gl:matrixMode( ?GL_PROJECTION ),
 gl:loadIdentity(),

 % Like glu:ortho2D/4:
 gl:ortho( _Left=0.0, _Right=float( CanvasWidth ),
   _Bottom=float( CanvasHeight ), _Top=0.0, _Near=-1.0, _Far=1.0 )

In this case, the viewport can be addressed like a **usual (2D) framebuffer** (like provided by any classical 2D backend such as SDL) obeying the coordinate system just described: if the width of the OpenGL canvas is 800 pixels and its height is 600 pixels, then its top-left on-screen corner is ``(0,0)`` and its bottom-right one is ``(799,599)``, and any pixel-level operation can be directly performed there "as usual". One may refer to ``gui_opengl_2D_test.erl`` for a full example thereof, in which line-based letters are drawn to demonstrate these conventions.

Each time the OpenGL canvas is resized, this projection matrix will have to be updated, with the same procedure yet based on the new dimensions.

Another option - still with axes respecting the MyriadGUI 2D conventions - is to operate this time based on **normalised, definition-independent coordinates**, ranging in ``[0.0, 1.0]``, like in:

.. code:: erlang

 gl:matrixMode( ?GL_PROJECTION ),
 gl:loadIdentity(),

 gl:ortho( _Left=0.0, _Right=1.0, _Bottom=1.0, _Top=0.0, _Near=-1.0,
   _Far=1.0 )


Using "stable", device-independent floats instead of integers directly accounting for pixels may be more convenient. For example a resizing of the viewport will then not require an update of the projection matrix. One may refer to ``gui_opengl_minimal_test.erl`` for a full example thereof.



.. _`3D referentials`:

Referentials In 3D
------------------


We will rely here as well on the MyriadGUI conventions, `this time for 3D <https://myriad.esperide.org/#3d-referential>`_ (not taking specifically time into account here):

:raw-html:`<center><img src="myriad-space-time-referential.png" id="responsive-image-tiny"></img></center>`
:raw-latex:`\begin{figure}[h] \centering \includegraphics[scale=0.6]{myriad-space-time-referential.png} \end{figure}`

These are thus Z-up conventions (the Z axis being vertical and designating altitudes), like modelling software such as Blender.



A Tree of Referentials
----------------------

In the general case, either in 2D or (more often of interest here) in 3D, a given scene (a model) is made of a set of elements (ex: the model of a street may comprise a car, two bikes, a few people) that will have to be rendered from a given viewpoint (ex: a window on the second floor of a given building) onto the (flat) user screen (with suitable clipping, perspective division and projection on the viewport). Let's start from the intended result and unwind the process.

The rendering objective requires to have ultimately one's scene transformed as a whole in eyes coordinates (to obtain coordinates along the aforementioned 2D screen referential, along the X and Y axes - the Z one serving to sort out depth, as per our conventions).

For that, a prerequisite is to have the target scene correctly composed, with all its elements defined in the same (scene-global) space, in their respective position and orientation (then only the viewpoint, i.e. the virtual camera, can take into account the scene as a whole, to transform it to eye coordinates).

As each individual type of model (ex: a bike model) is natively defined in an abstract, local referential (an orthonormal basis) of its own, each actual model instance (ex: the first bike, the second bike) has to be specifically placed in the referential of the overall scene. This placement is either directly defined in that target space (ex: bike A is at this absolute position and orientation in the scene global referential) or relatively to a *series* of parent referentials (ex: this character rides bike B - and thus is defined relatively to it, knowing that the bike is placed relatively to the car, and that the car itself is placed relatively to the scene).

So in the general case, referentials are nested (recursively defined relatively to their parent) and form a tree [#]_ whose root corresponds to the referential of the overall scene, like in:

:raw-html:`<center><img src="referential-tree.png" id="responsive-image-small"></img></center>`
:raw-latex:`\begin{figure}[h] \centering \includegraphics[scale=0.6]{referential-tree.png} \end{figure}`


.. [#] This is actually named a *scene graph* rather than a *scene tree*, as if we consider the leaves of that "tree" to contain actual geometries (ex: of an abstract bike), as soon as a given geometry is instantiated more than once (ex: if having 2 of such bikes in the scene), this geometry will have multiple parents and thus the corresponding scene will be a graph.

	   As for us, we consider *referential trees* (no geometry involved) - a given 3D object being possibly associated to (1) a referential and (2) a geometry (independently).


A series of model transformations has thus to be operated in order to express all models in the scene referential::

 (local referential of model Rf) -> (parent referential Rd) -> (...) -> (Ra) -> (scene referential Rs)

For example the hand of a character may be defined in :math:`R_h`, itself defined relatively to its associated forearm in :math:`R_f` up to the overall referential :math:`R_a` of that character, defined relatively to the referential of the whole scene, :math:`R_s`. This referential may have no explicit parent defined, meaning implicitly that it is defined in the canonical, global referential.

Once the **model** is expressed as a whole in the scene-global referential, the next transformations have to be conducted : **view** and projection. The view transformation involves at least an extra referential, the one of the camera in charge of the rendering, which is :math:`R_c`, possibly defined relatively to :math:`R_s`.

So a geometry (ex: a part of the hand, defined in :math:`R_f`) has been transformed upward in the referential tree in order to be expressed in the common, "global" scene referential :math:`R_s`, before being transformed last in the camera one, :math:`R_c`.


In practice, all these operations can be done thanks to the multiplication of homogeneous 4x4 matrices, each able to express any combination of rotations, scalings/reflections/shearings, translations, which thus include the transformation of one referential into another. Their product can be computed once, and then applying a vector (ex: corresponding to a vertex) to the resulting matrix allows to perform in one go the full composition thereof, encoding all model-view transformations and even the projection as well.

Noting :math:`P_{a{\rightarrow}b}` the transition matrix transforming a vector :math:`\vec{V_a}` expressed in :math:`R_a` into its representation :math:`\vec{V_b}` in :math:`R_b`, we have:

.. math::

  \vec{V_b} = P_{a{\rightarrow}b}.\vec{V_a}


Thus, to express the geometry of said hand (natively defined in :math:`R_h`) in camera space (hence in :math:`R_c`), the following composition of referential changes [#]_ shall be applied:

.. math::

  P_{h{\rightarrow}c} = P_{s{\rightarrow}c}.P_{a{\rightarrow}s}.P_{f{\rightarrow}a}.P_{h{\rightarrow}f}.


.. [#] Thus transformation matrices, knowing that the product of such matrices is in turn a transformation matrix.

So a whole series of transformations can be done by applying a single matrix - whose coordinates are now to be determined.


Computing Transition Matrices
-----------------------------


For that, let's consider an homogeneous 4x4 matrix is in the form of:

.. math::
 M = \begin{bmatrix}
		r_{11} & r_{12} & r_{13} & t_1 \\
		r_{21} & r_{22} & r_{23} & t_2 \\
		r_{31} & r_{32} & r_{33} & t_3 \\
		  0 &   0 &   0 &  1 \\
	 \end{bmatrix}

It can be interpreted as a matrix comprising two blocks of interest, :math:`R` and :math:`\vec{T}`:

.. math::
 P_{1\rightarrow2}
	 = \begin{bmatrix}
		R & \vec{T} \\
		0 &  1      \\
	   \end{bmatrix}

with:


- :math:`\matrix{R}`, which accounts for a 3D rotation submatrix:

.. math::
 R = \begin{bmatrix}
		r_{11} & r_{12} & r_{13} \\
		r_{21} & r_{22} & r_{23} \\
		r_{31} & r_{32} & r_{33} \\
	 \end{bmatrix}

- :math:`\vec{T}`, which accounts for a 3D translation vector:

:math:`\vec{T} = \begin{bmatrix} t1 \\ t2 \\ t3 \end{bmatrix}`

Applying a (4x4 homogeneous) point :math:`P = \begin{Bmatrix} x \\ y \\ z \\ 1 \end{Bmatrix}` to :math:`M` yields :math:`P' = M.P` where :math:`P'` corresponds to `P` once it has been (1) rotated by :math:`\matrix{R}` and then (2) translated by :math:`\vec{T}` (order matters).


Let's consider now:

:raw-html:`<center><img src="change-of-referential.png" id="responsive-image-small"></img></center>`
:raw-latex:`\begin{figure}[h] \centering \includegraphics[scale=0.7]{change-of-referential.png} \end{figure}`


- two referentials (defined as orthonormal bases), :math:`R_1` and :math:`R_2`; :math:`R_2` may for example be defined relatively to :math:`R_1`; for a given point or vector :math:`U`, :math:`U_1` will designate its coordinates in :math:`R_1` (and :math:`U_2` its coordinates in :math:`R_2`)
- :math:`P_{2\rightarrow1}` the (homogeneous 4x4) `transition matrix <https://en.wikipedia.org/wiki/Change_of_basis>`_ from :math:`R_2` to :math:`R_1`, specified first by blocks then by coordinates as:

.. math::
 P_{2\rightarrow1}
	 = \begin{bmatrix}
		R  & \vec{T} \\
		0  &       1 \\
	   \end{bmatrix}

	 = \begin{bmatrix}
		r_{11} & r_{12} & r_{13} & t_1 \\
		r_{21} & r_{22} & r_{23} & t_2 \\
		r_{31} & r_{32} & r_{33} & t_3 \\
		  0 &   0 &   0 &  1 \\
	 \end{bmatrix}

- any (4D) point :math:`P`, whose coordinates are :math:`P_1` in :math:`R_1`, and :math:`P_2` in :math:`R_2`

The objective is to determine :math:`P_{2\rightarrow1}`, i.e. :math:`R` and :math:`\vec{T}`.

By definition of a transition matrix, for any point :math:`P`, we have: :math:`P_1 = P_{2\rightarrow1}.P_2 \qquad (1)`

Let's study :math:`P_{2\rightarrow1}` by first choosing a point :math:`P` equal to the origin of :math:`R_2` (shown as ``Ob`` in the figure).

By design, in homogeneous coordinates, :math:`P_2 = Ob_2 = \begin{Bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{Bmatrix}` and applying it on :math:`(1)` gives us: :math:`P_1 = Ob_1 = \begin{Bmatrix} t1 \\ t2 \\ t3 \\ 1 \end{Bmatrix}`.

So if :math:`Ob_1 = \begin{Bmatrix} XOb_1 \\ YOb_1 \\ ZOb_1 \\ 1 \end{Bmatrix}`, we have: :math:`\vec{T} = \vec{T_{2\rightarrow1}} = \begin{bmatrix} XOb_1 \\ YOb_1 \\ ZOb_1 \end{bmatrix}`.

Let's now determine the :math:`r_{xy}` coordinates.

Let :math:`R_{2\rightarrow1}` be the (3x3) rotation matrix transforming any vector expressed in :math:`R_2` in its representation in :math:`R_1`: for any (3D) vector :math:`\vec{V}`, we have :math:`\vec{V_1} = R_{2\rightarrow1}.\vec{V_2}  \qquad (2)`

(we are dealing with vectors, not points, hence the origins are not involved here).

By choosing :math:`\vec{V}` equal to the :math:`\vec{Ib}` (abscissa) axis of :math:`R_2` (shown as ``Ib`` in the figure), we have :math:`\vec{Ib_1} = R_{2\rightarrow1}.\vec{Ib_2}`

Knowing that by design :math:`\vec{Ib_2} = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}`, :math:`(2)` gives us:

.. math::

 \vec{Ib_1} = \begin{bmatrix} r_{11} \\ r_{21} \\ r_{31} \end{bmatrix}
		   = \begin{bmatrix} XIb_{1} \\ YIb_{1} \\ ZIb_{1} \end{bmatrix}

So the first column of the :math:`R` matrix is :math:`\vec{Ib_1}` , i.e. the first axis of :math:`R_2` as expressed in :math:`R_1`.

Using in the same way the two other axes of :math:`R_2` (shown as ``Jb`` and ``Kb`` in the figure), we see that:

.. math::

 R = R_{2\rightarrow1}

   = \begin{bmatrix}
		XIb_{1} & XJb_{1} & XKb_{1} \\
		YIb_{1} & YJb_{1} & YKb_{1} \\
		ZIb_{1} & ZJb_{1} & ZKb_{1} \\
	 \end{bmatrix}


.. Note::

 So finally the transition matrix from :math:`R_2` to :math:`R_1` is:

 .. math::
  P_{2\rightarrow1}
	 = \begin{bmatrix}
		R_{2\rightarrow1}  & \vec{T_{2\rightarrow1}} \\
		0  &       1 \\
	   \end{bmatrix}
	 = \begin{bmatrix}
		XIb_1 & XJb_1 & XKb_1 & XOb_1 \\
		YIb_1 & YJb_1 & YKb_1 & YOb_1 \\
		ZIb_1 & ZJb_1 & ZKb_1 & ZOb_1 \\
			0 &     0 &     0 &     1 \\
	   \end{bmatrix}

 where:

 - :math:`R_{2\rightarrow1}` is the 3x3 rotation matrix converting vectors of :math:`R_2` in :math:`R_1`, i.e. whose columns are the axes of :math:`R_2` expressed in :math:`R_1`
 - :math:`\vec{T_{1\rightarrow2}} = Ob_1` is the 3D vector of the coordinates of the origin of :math:`R_2` as expressed in :math:`R_1`

 This also corresponds to a matrix obtained by describing the :math:`R_2` referential in :math:`R_1`, by listing first the three (4D) vector axes of :math:`R_2` then its (4D) origin, i.e. :math:`P_{2\rightarrow1} = \begin{bmatrix} \vec{Ib_1} && \vec{Jb_1} && \vec{Kb_1} && Ob_1 \end{bmatrix}`.


As a result, from the definition of a tree of referentials, we are able to compute the transition matrix transforming the representation of a vector expressed in any of them to its representation in any of the other referentials.

For that, like in the case of the scene-to-camera transformation, transition matrices may have to be inversed, knowing that :math:`(P_{2\rightarrow1})^{-1} = P_{1\rightarrow2}` (since by definition :math:`P_{2\rightarrow1}.P_{1\rightarrow2} = Id`).

A special case of interest is, for the sake of rendering, to transform, through that tree, a local referential in which a geometry is defined into the one of the camera, defining where it is positioned and aimed [#]_; in OpenGL parlance, this corresponds to the *model-view* matrix (for "modelling and viewing transformations") that we designate here as :math:`M_{mv}` and which corresponds to :math:`P_{local{\rightarrow}camera}`.

.. [#] ``gluLookAt`` can define such a viewing transformation matrix, when given (1) the position of the camera, (2) a point at which it shall look, and (3) a vector specifying its up direction (i.e. where is the upward direction for the camera - as otherwise all directions orthogonal to its line of sight defined by (1) and (2) could be chosen).



Taking into account the last rendering step, the *projection* (comprising clipping, projection division and viewport transformation), which can be implemented as well thanks to a 4x4 matrix designated here as :math:`M_p`, we see that a single combined overall matrix :math:`M_o = M_p.M_{mv}` is sufficient [#]_ to convey in one go all transformations that shall be applied to a given geometry for its rendering.

.. [#] In practice, for more flexibility, in OpenGL the management of the viewport, of the projection and of the model-view transformations is done separately (for example, respectively, with: ``glViewport``, ``glMatrixMode(GL_MODEL-VIEW)`` and ``glMatrixMode(GL_PROJECTION)``; so there is a matrix stack corresponding to ``GL_MODEL-VIEW`` and another one to ``GL_PROJECTION``).



More Advanced Topics
====================


Shadows
-------

Determining the shadow of an arbitrary object on an arbitrary plane (representing typically the ground - or other objects) from an arbitrary light source (possibly at infinity) corresponds to performing a specific **projection**. For that, a relevant 4x4 (based on homogeneous coordinates) matrix (singular, i.e. non-invertible matrix) can be defined.

This matrix can be multiplied with the top of the model-view matrix stack, before drawing the object of interest in the shadow color (a shade of black generally).

Refer to `this page <https://www.glprogramming.com/red/chapter14.html#name15>`_ for more information.



Sources of Information
======================

The reference pages for the various versions of OpenGL are `available on the Khronos official website <https://www.khronos.org/registry/OpenGL-Refpages/>`_.

Two very well-written books, strongly recommended, that are still perfectly relevant despite their old age (circa 1996):

- *The Official Guide to Learning OpenGL*: the `OpenGL Red book <https://www.glprogramming.com/red/index.html>`_
- *The OpenGL Reference Manual*: the `OpenGL Blue book <https://www.glprogramming.com/blue/index.html>`_


Other elements of interest:

- FAQ for `OpenGL <https://www.khronos.org/opengl/wiki/FAQ>`_ and `GLUT <https://www.opengl.org/resources/libraries/glut/faq/>`_
- the (archived) `OpenGL FAQ and Troubleshooting Guide <https://www.opengl.org/archives/resources/faq/technical/>`_, containing much valuable information, including regarding `transformations <https://www.opengl.org/archives/resources/faq/technical/transformations.htm>`_
- About `OpenGL Performance <https://www.khronos.org/opengl/wiki/Performance>`_

.. available at https://www.ljll.math.upmc.fr/~frey/cours/Roscoff/OpenGL.pdf
- in French: `Introduction Ã  OpenGL et GLUT <http://interaction.lille.inria.fr/~roussel/>`_, by Nicolas Roussel
- any textbook on linear algebra


.. _`os-support`:

-------------------------------
Operating System Support for 3D
-------------------------------

Benefiting from a proper 2D/3D hardware acceleration on GNU/Linux is unfortunately not always straightforward, and sometimes brittle.


Testing
=======

First, one may check whether such acceleration is already available by running, from the command-line, the ``glxinfo`` executable (to be obtained on Arch Linux thanks to the ``mesa-utils`` package), and hope to see, among the many displayed lines, ``direct rendering: Yes``.

One may also run our `display-opengl-information.sh <https://github.com/Olivier-Boudeville/Ceylan-Hull/blob/master/display-opengl-information.sh>`_ script to report relevant information.

A final validation might be to run the ``glxgears`` executable (still obtained through the ``mesa-utils`` package), and to ensure that a window appears, showing three gears properly rotating.



Troubleshooting
===============

If it is not the case (no direct rendering, or a GLX error being returned - typically involving any ``X Error of failed request:  BadValue`` for a ``X_GLXCreateNewContext``), one should investigate one's configuration (with ``lspci | grep VGA``, ``lsmod``, etc.), update one's video driver on par with the current kernel, reboot, sacrifice a chicken, etc.

If using a NVidia graphic card, consider reading this `Arch Linux wiki page <https://wiki.archlinux.org/title/NVIDIA>`_ first.

In our case, installation could be done with ``pacman -Sy nvidia nvidia-utils`` but requested a reboot.

Despite package dependencies and a not-so-successful attempt of using DKMS in order to link kernel updates with graphic controller updates, too often a proper 3D support was lost, either from the boot or afterwards. Refer to our `software update section <GNULinux.html#software-update>`_ for hints in order to secure the durable use of proper drivers.





------------------------
3D-Related Mini-Glossary
------------------------

- **HDRP**: *High Definition Render Pipeline*, a `high-fidelity scriptable render pipeline <https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@13.1/manual/index.html>`_, made by Unity to target **modern** (Compute Shader compatible) platforms (so HDRP is the high-end counterpart of URP)

- **IK**: *Inverse Kinematics*, the **computation of intermediary joint parameters** so that the end of the kinematic chain is at a given position and orientation; typically, if one wants the hand of a character to grasp the top of a chair, IK is used in order to determine the parameters of the character's wrist, arm, elbow, etc. that may be retained so that the hand is ultimately correctly placed on the chair (`more information <https://en.wikipedia.org/wiki/Inverse_kinematics>`_)

- **Material**: controls the optical properties of an object, i.e. how a 3D object appears on the screen, that is: the color of each point of the object (generally thanks to multiple texture maps, like diffusion, normal, specular, glow, etc.) and how reflective or dull its surface appears; designates, with OpenGL, a set of coefficients that define **how the lighting model interacts with the surface**; in particular, ambient, diffuse, and specular coefficients for each color component (R,G,B) are defined and applied to a surface and effectively multiplied by the amount of light of each kind/color that strikes the surface; a final emmissivity coefficient is then added to each color component so that objects can also be light emitters

- **NURBS**: *Non-Uniform Rational B-Spline*, a mathematical model using `basis splines <https://en.wikipedia.org/wiki/B-spline>`_ (B-splines) that is commonly used in computer graphics for representing **curves and surfaces**, whose shape is determined by control points (`more information <https://en.wikipedia.org/wiki/Non-uniform_rational_B-spline>`_)

- **PBR**: *Physically-Based Rendering* designates approaches to render images in a way that **models the flow of light in the real world**, for example thanks to photogrammetry; many PBR pipelines aim to achieve photorealism; in practice they often rely on the **micro-facet theory**, with specific materials (generally based on texture maps) and shaders (is also called PBS, for *Physically-Based Shading*); PBR is slowly becoming the standard for all materials

- **PSD**: *Photoshop Document*, a `proprietary format for graphics <https://docs.fileformat.com/image/psd/>`_ with layers, masks, etc. used by Adobe Photoshop (a commercial counterpart to `Gimp <https://www.gimp.org/>`_, `Krita <https://krita.org>`_, etc.) often used to store textures that may still be edited as templates by the user - provided they are using Photoshop as well; however, at least to some extent, `Gimp is able to edit PSD files <https://wiki.gimp.org/wiki/PSD_support>`_ and `Krita too <https://docs.krita.org/en/general_concepts/file_formats/file_psd.html>`_

- **Rigging** (or *Skeletal Animation*) consists in **controlling the deformation of a mesh** (a.k.a. a *skin*, the surface of a body) of an articulated object (typically a character) **based on a virtual inner armature** (a hierarchical set of interconnected parts, called *bones*, and collectively forming the skeleton or *rig*) in order to animate that mesh (`more information <https://en.wikipedia.org/wiki/Skeletal_animation>`_)

- **Textures**: bitmaps (images) used to **skin 3D objects**, by defining the color of each point on the surface of the object in terms of texture coordinates; besides such 2D textures, 1D, 3D and 4D ones exist

- **Texture Atlas**: a texture (an image) containing a **set of separate, elementary graphic elements**, meant to be extracted thanks to texture coordinates, akin to a sprite sheet; doing so is useful to reduce the overhead that would be induced by the management of many smaller textures (`more information <https://en.wikipedia.org/wiki/Texture_atlas>`_)

- **URP**: *Universal Render Pipeline*, a prebuilt `scriptable render pipeline <https://docs.unity3d.com/Packages/com.unity.render-pipelines.universal@13.1/manual/>`_, made by Unity that implements workflows across a range of platforms, from mobile to high-end consoles and PC (in practice URP is the low-end counterpart of HDRP)


See also the Wikipedia's `glossary of computer graphics <https://en.wikipedia.org/wiki/Glossary_of_computer_graphics>`_.
